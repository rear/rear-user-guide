[\#2028 Issue](https://github.com/rear/rear/issues/2028) `open`: BTRFS Raid / Multi Disk setup is currently not supported
=========================================================================================================================

**Labels**: `needs sponsorship`, `severe improvement`

#### <img src="https://avatars.githubusercontent.com/u/1926396?u=705546e01ca12110cc5f18b9dbc2ffe1b447cd76&v=4" width="50">[ChojinDSL](https://github.com/ChojinDSL) opened issue at [2019-02-01 16:41](https://github.com/rear/rear/issues/2028):

I've noticed that ReaR doesn't correctly work with a BTRFS Multiple Disk
setup.

E.g. a BTRFS Volume can consist of multiple disks in a variety of
configurations, e.g. single, RAID1, RAID10, RAID5/6, etc..

It seems as if ReaR only creates a single disk BTRFS Volume during
recovery. This could create problem if the backup is larger than a
single disk.

Since BTRFS supports many mixed configurations, e.g. Metadata as RAID1
but Data as RAID10, accurately detecting the original layout might be
tricky.  
However, at the very least it would be very nice if ReaR could detect if
a BTRFS Volume consists of multiple devices and then re-creates the
BTRFS volume with the member devices during recovery.

If you create the BTRFS volume with just a list of devices, then per
default the volume will be created as a "single" volume, but with the
total capacity of all member devices. Since BTRFS supports rebalancing
to migrate from single to RAID1/10/5/6, it would be easy for the user to
rebalance their system back to their original layout, after recovery has
taken place and the system has bootet into the OS.

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2019-02-05 10:04](https://github.com/rear/rear/issues/2028#issuecomment-460579609):

I implemented the current Btrfs support in ReaR and  
I never had a Btrfs setup on multiple disks  
so that I think you are right that currently  
ReaR does not support a Btrfs filesystem that is on more than one
partition.

See  
"Disk layout file syntax" at  
[https://github.com/rear/rear/blob/master/doc/user-guide/06-layout-configuration.adoc](https://github.com/rear/rear/blob/master/doc/user-guide/06-layout-configuration.adoc)  
that reads (excerpt)

    Filesystems

    fs <device> <mountpoint> <filesystem type> [uuid=<uuid>] [label=<label>] [blocksize=<block size(B)>] [<reserved_blocks=<nr of reserved blocks>] [max_mounts=<nr>] [check_interval=<number of days>d] [options=<filesystem options>]

    Btrfs Default SubVolumes

    btrfsdefaultsubvol <device> <mountpoint> <btrfs_subvolume_ID> <btrfs_subvolume_path>

    Btrfs Normal SubVolumes

    btrfsnormalsubvol <device> <mountpoint> <btrfs_subvolume_ID> <btrfs_subvolume_path>

    Btrfs Mounted SubVolumes

    btrfsmountedsubvol <device> <subvolume_mountpoint> <mount_options> <btrfs_subvolume_path>

where all show only `device` but no `devices`.

See also  
[https://github.com/rear/rear/issues/2023](https://github.com/rear/rear/issues/2023)

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2019-02-05 11:43](https://github.com/rear/rear/issues/2028#issuecomment-460607949):

@ChojinDSL  
to get an idea how a Btrfs setup on multiple disks could look like  
could you please post here the output of the command

    lsblk -i -p -o NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,SIZE,MOUNTPOINT

on your original system or systems when you have different kind of them.

Perhaps you may need to specify some more output columns that could be  
of particular interest in case of Btrfs on multiple disks, see
`lsblk -h`  
what output columns are available for the `lsblk` command on your  
particular system.

By the way:  
What Linux distribution and version do you use?  
Cf.  
[https://github.com/rear/rear/blob/master/.github/ISSUE\_TEMPLATE.md](https://github.com/rear/rear/blob/master/.github/ISSUE_TEMPLATE.md)

#### <img src="https://avatars.githubusercontent.com/u/1926396?u=705546e01ca12110cc5f18b9dbc2ffe1b447cd76&v=4" width="50">[ChojinDSL](https://github.com/ChojinDSL) commented at [2019-02-05 15:35](https://github.com/rear/rear/issues/2028#issuecomment-460683215):

@jsmeix Here's the output of lsblk you asked for.

I use Debian Stretch at the moment.

    NAME        KNAME     PKNAME   TRAN TYPE FSTYPE   SIZE MOUNTPOINT
    /dev/sda    /dev/sda           sas  disk          1.7T 
    |-/dev/sda1 /dev/sda1 /dev/sda      part vfat     512M /boot/efi
    |-/dev/sda2 /dev/sda2 /dev/sda      part btrfs    1.5T /
    `-/dev/sda3 /dev/sda3 /dev/sda      part swap   127.7G [SWAP]
    /dev/sdb    /dev/sdb           sas  disk          1.7T 
    |-/dev/sdb1 /dev/sdb1 /dev/sdb      part          512M 
    |-/dev/sdb2 /dev/sdb2 /dev/sdb      part btrfs    1.5T 
    `-/dev/sdb3 /dev/sdb3 /dev/sdb      part swap   127.7G [SWAP]
    /dev/sdc    /dev/sdc           sas  disk          1.7T 
    |-/dev/sdc1 /dev/sdc1 /dev/sdc      part          512M 
    |-/dev/sdc2 /dev/sdc2 /dev/sdc      part btrfs    1.5T 
    `-/dev/sdc3 /dev/sdc3 /dev/sdc      part swap   127.7G [SWAP]
    /dev/sdd    /dev/sdd           sas  disk          1.7T 
    |-/dev/sdd1 /dev/sdd1 /dev/sdd      part          512M 
    |-/dev/sdd2 /dev/sdd2 /dev/sdd      part btrfs    1.5T 
    `-/dev/sdd3 /dev/sdd3 /dev/sdd      part swap   127.7G [SWAP]
    /dev/sde    /dev/sde           sas  disk          1.7T 
    |-/dev/sde1 /dev/sde1 /dev/sde      part          512M 
    |-/dev/sde2 /dev/sde2 /dev/sde      part btrfs    1.5T 
    `-/dev/sde3 /dev/sde3 /dev/sde      part swap   127.7G [SWAP]
    /dev/sdf    /dev/sdf           sas  disk          1.7T 
    |-/dev/sdf1 /dev/sdf1 /dev/sdf      part          512M 
    |-/dev/sdf2 /dev/sdf2 /dev/sdf      part btrfs    1.5T 
    `-/dev/sdf3 /dev/sdf3 /dev/sdf      part swap   127.7G [SWAP]
    /dev/sdg    /dev/sdg           sas  disk          1.7T 
    |-/dev/sdg1 /dev/sdg1 /dev/sdg      part          512M 
    |-/dev/sdg2 /dev/sdg2 /dev/sdg      part btrfs    1.5T 
    `-/dev/sdg3 /dev/sdg3 /dev/sdg      part swap   127.7G [SWAP]
    /dev/sdh    /dev/sdh           sas  disk          1.7T 
    |-/dev/sdh1 /dev/sdh1 /dev/sdh      part          512M 
    |-/dev/sdh2 /dev/sdh2 /dev/sdh      part btrfs    1.5T 
    `-/dev/sdh3 /dev/sdh3 /dev/sdh      part swap   127.7G [SWAP]

#### <img src="https://avatars.githubusercontent.com/u/1926396?u=705546e01ca12110cc5f18b9dbc2ffe1b447cd76&v=4" width="50">[ChojinDSL](https://github.com/ChojinDSL) commented at [2019-02-12 10:04](https://github.com/rear/rear/issues/2028#issuecomment-462696494):

BTRFS is a bit unusual since it's so flexible and allows for very
unusual setups.  
It's probably easier to get information about the underlying BTRFS setup
using some of BTRFS's own tools.

e..g

    #############
    btrfs fi show

    Label: 'ROOT'  uuid: 69a8d230-fe68-4504-bb14-1742acdb8967
            Total devices 8 FS bytes used 2.23GiB
            devid    1 size 1.51TiB used 1.27GiB path /dev/sda2
            devid    2 size 1.51TiB used 1.27GiB path /dev/sdb2
            devid    3 size 1.51TiB used 1.27GiB path /dev/sdc2
            devid    4 size 1.51TiB used 1.27GiB path /dev/sdd2
            devid    5 size 1.51TiB used 1.27GiB path /dev/sde2
            devid    6 size 1.51TiB used 1.27GiB path /dev/sdf2
            devid    7 size 1.51TiB used 1.27GiB path /dev/sdg2
            devid    8 size 1.51TiB used 1.27GiB path /dev/sdh2

    ###############
    btrfs fi usage /

    Overall:
        Device size:                  12.10TiB
        Device allocated:             10.12GiB
        Device unallocated:           12.09TiB
        Device missing:                  0.00B
        Used:                          4.47GiB
        Free (estimated):              6.05TiB      (min: 6.05TiB)
        Data ratio:                       2.00
        Metadata ratio:                   2.00
        Global reserve:               16.00MiB      (used: 0.00B)

    Data,RAID10: Size:4.00GiB, Used:2.16GiB
       /dev/sda2     512.00MiB
       /dev/sdb2     512.00MiB
       /dev/sdc2     512.00MiB
       /dev/sdd2     512.00MiB
       /dev/sde2     512.00MiB
       /dev/sdf2     512.00MiB
       /dev/sdg2     512.00MiB
       /dev/sdh2     512.00MiB

    Metadata,RAID10: Size:1.00GiB, Used:71.77MiB
       /dev/sda2     128.00MiB
       /dev/sdb2     128.00MiB
       /dev/sdc2     128.00MiB
       /dev/sdd2     128.00MiB
       /dev/sde2     128.00MiB
       /dev/sdf2     128.00MiB
       /dev/sdg2     128.00MiB
       /dev/sdh2     128.00MiB

    System,RAID10: Size:64.00MiB, Used:16.00KiB
       /dev/sda2       8.00MiB
       /dev/sdb2       8.00MiB
       /dev/sdc2       8.00MiB
       /dev/sdd2       8.00MiB
       /dev/sde2       8.00MiB
       /dev/sdf2       8.00MiB
       /dev/sdg2       8.00MiB
       /dev/sdh2       8.00MiB

    Unallocated:
       /dev/sda2       1.51TiB
       /dev/sdb2       1.51TiB
       /dev/sdc2       1.51TiB
       /dev/sdd2       1.51TiB
       /dev/sde2       1.51TiB
       /dev/sdf2       1.51TiB
       /dev/sdg2       1.51TiB
       /dev/sdh2       1.51TiB

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2019-02-13 13:10](https://github.com/rear/rear/issues/2028#issuecomment-463193378):

@ChojinDSL  
I know Btrfs "is a bit unusual" (polite wording ;-)

Btrfs' features just break traditional assumptions  
how a stack of storage objects is usually organized  
(like disks =&gt; partitions =&gt; filesystems =&gt; mountpoints).

You may have a look at  
[https://github.com/rear/rear/pull/1603\#issuecomment-347839823](https://github.com/rear/rear/pull/1603#issuecomment-347839823)  
and  
[https://github.com/rear/rear/pull/1603\#issuecomment-347860869](https://github.com/rear/rear/pull/1603#issuecomment-347860869)  
and follow the links therein.

I fear implementing support for Btrfs setup on multiple disks  
may require that the whole disk layout code in ReaR needs  
to be fundamentally changed, enhanced, and overhauled.  
On the other hand  
[https://github.com/rear/rear/issues/2023\#issuecomment-456764118](https://github.com/rear/rear/issues/2023#issuecomment-456764118)  
indicates that perhaps it could be even easier than it looks like.

#### <img src="https://avatars.githubusercontent.com/in/15368?v=4" width="50">[github-actions](https://github.com/apps/github-actions) commented at [2020-06-28 01:33](https://github.com/rear/rear/issues/2028#issuecomment-650665291):

Stale issue message

#### <img src="https://avatars.githubusercontent.com/u/101384?v=4" width="50">[schlomo](https://github.com/schlomo) commented at [2024-12-13 07:18](https://github.com/rear/rear/issues/2028#issuecomment-2540742272):

I guess we'll have to come back to this issue eventually and probably
treat BTRFS more like LVM and RAID and not just like another filesystem.
If we move BTRFS to the LVM / RAID layer then we could treat it as a
NOOP in the filesystem creation stage.

I'd like to reopen this and mark it as waiting for sponsor, WDYT
@rear/contributors ?

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2024-12-13 12:31](https://github.com/rear/rear/issues/2028#issuecomment-2541347386):

I reopened it as a "severe improvement"  
with target milestone "ReaR 3.1"  
because (as far as I understand it) "ReaR 3.0"  
is primarily intended to deprecate old features soon  
so "ReaR 3.0" is intended to be relaeased  
"relatively soon" after "Rear 2.8"  
so implementing big things which take longer time  
cannot be done for "ReaR 3.0".

------------------------------------------------------------------------

\[Export of Github issue for
[rear/rear](https://github.com/rear/rear).\]
