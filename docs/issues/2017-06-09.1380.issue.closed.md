[\#1380 Issue](https://github.com/rear/rear/issues/1380) `closed`: ReaR recovery fails when the OS contains a Thin Pool/Volume
==============================================================================================================================

**Labels**: `enhancement`, `fixed / solved / done`

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) opened issue at [2017-06-09 15:11](https://github.com/rear/rear/issues/1380):

-   rear version (/usr/sbin/rear -V): 1.17.2\_3 (and 2.0)
-   OS version (cat /etc/rear/os.conf or lsb\_release -a): RHEL 7.3
-   rear configuration files (cat /etc/rear/site.conf or cat
    /etc/rear/local.conf): BACKUP=NETFS
-   Are you using legacy BIOS or UEFI boot? no
-   Brief description of the issue:  
    When using ReaR, the recovery process of a system which has a VG
    which contains a Thin Pool/Volume fails and the system is no longer
    recoverable. This has a high impact because ReaR will not be able to
    restore the system back to an operational state. The location of the
    Thin Pool is independent of the VG which contains it, that is, it
    does not matter if the Thin Pool is contained in the rootvg or in an
    independent VG.
-   Work-around, if any: see RH bug report
    [https://bugzilla.redhat.com/show\_bug.cgi?id=1450667](https://bugzilla.redhat.com/show_bug.cgi?id=1450667)

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2017-07-19 15:07](https://github.com/rear/rear/issues/1380#issuecomment-316417452):

post-pone to release 2.3

#### <img src="https://avatars.githubusercontent.com/u/16332741?v=4" width="50">[jmazanek](https://github.com/jmazanek) commented at [2017-09-04 13:16](https://github.com/rear/rear/issues/1380#issuecomment-326961209):

With the rear-2.00 the system recovery works, but the thin pool is not
preserved.  
Here are the details of the testing we did:

Details of a new reproducer in my lab using the latest version of ReaR:

Version installed: rear-2.00-2.el7.x86\_64  
Hypervisor: ofamera-devel.usersys.redhat.com  
Original machine: fvm-rhel-7-3-34 &lt;-- Executed 'rear mkbackup'  
Recovery machine: fvm-rhel-7-3-38 &lt;-- Executed 'rear recover'  
NFS backup server: fvm-rhel-7-3-44  
User: root  
Pass: testtest

------------------------------------------------------------------------

\*\*\* BACKUP TEST \*\*\*

------------------------------------------------------------------------

RESULT: Backup taken successfully. ISO + backup.tar.gz were sent to the
NFS server

-&gt; Original system (fvm-rhel-7-3-34):

\[root@fvm-rhel-7-3-34 ~\]\# rear -d -v mkbackup  
Relax-and-Recover 2.00 / Git  
Using log file: /var/log/rear/rear-fvm-rhel-7-3-34.log  
Using backup archive 'backup.tar.gz'  
Creating disk layout  
Creating root filesystem layout  
Copying logfile /var/log/rear/rear-fvm-rhel-7-3-34.log into initramfs as
'/tmp/rear-fvm-rhel-7-3-34-partial-2017-08-21T10:14:10+0200.log'  
Copying files and directories  
Copying binaries and libraries  
Copying kernel modules  
Creating initramfs  
Making ISO image  
Wrote ISO image: /var/lib/rear/output/rear-fvm-rhel-7-3-34.iso (134M)  
Copying resulting files to nfs location  
Saving /var/log/rear/rear-fvm-rhel-7-3-34.log as
rear-fvm-rhel-7-3-34.log to nfs location  
Creating tar archive
'/tmp/rear.WaTt8XedE2CpdJ3/outputfs/fvm-rhel-7-3-34/backup.tar.gz'  
Archived 850 MiB \[avg 3349 KiB/sec\] OK  
Archived 850 MiB in 261 seconds \[avg 3336 KiB/sec\]  
You should also rm -Rf /tmp/rear.WaTt8XedE2CpdJ3  
\[root@fvm-rhel-7-3-34 ~\]\# lvs  
LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert  
root\_lv r7vg -wi-ao---- 4.88g  
swap\_lv r7vg -wi-ao---- 256.00m  
lv\_thin vg\_thin Vwi-a-tz-- 1.00g lv\_thinpool 0.00  
lv\_thinpool vg\_thin twi-aotz-- 92.00m 0.00 0.98

-&gt; NFS backup server (fvm-rhel-7-3-44):

\[root@fvm-rhel-7-3-44 ~\]\# ls -l /media/backups/fvm-rhel-7-3-34/  
total 1010332  
-rw-------. 1 nfsnobody nfsnobody 2252128 Aug 21 10:20 backup.log  
-rw-------. 1 nfsnobody nfsnobody 891757428 Aug 21 10:20 backup.tar.gz  
-rw-------. 1 nfsnobody nfsnobody 202 Aug 21 10:16 README  
-rw-------. 1 nfsnobody nfsnobody 140369920 Aug 21 10:15
rear-fvm-rhel-7-3-34.iso  
-rw-------. 1 nfsnobody nfsnobody 183744 Aug 21 10:16
rear-fvm-rhel-7-3-34.log  
-rw-------. 1 nfsnobody nfsnobody 0 Aug 21 10:20 selinux.autorelabel  
-rw-------. 1 nfsnobody nfsnobody 273 Aug 21 10:16 VERSION

------------------------------------------------------------------------

\*\*\* RECOVERY TEST \*\*\*

------------------------------------------------------------------------

RESULT: It recovered the system (it was able to boot afterwards) but
only the OS itself (root VG/LVs), not the LVM Thin Pool/Volumes in the
second disk

-&gt; Original system (fvm-rhel-7-3-34):

\[jserrano@ofamera-devel ~\]$ fast-vm ssh 34  
\[inf\] checking the 192.168.33.34 for active SSH connection (ctrl+c to
interrupt)  
\[inf\]  
SSH ready  
Warning: Permanently added '192.168.33.34' (ECDSA) to the list of known
hosts.

System is booting up. See pam\_nologin(8)  
Last login: Mon Aug 21 12:35:16 2017 from gateway

\[root@fvm-rhel-7-3-34 ~\]\# lvs  
LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert  
root\_lv r7vg -wi-ao---- 4.88g  
swap\_lv r7vg -wi-ao---- 256.00m  
lv\_thin vg\_thin Vwi-a-tz-- 1.00g lv\_thinpool 0.00  
lv\_thinpool vg\_thin twi-aotz-- 92.00m 0.00 0.98  
\[root@fvm-rhel-7-3-34 ~\]\#  
\[root@fvm-rhel-7-3-34 ~\]\# lsblk  
NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT  
sda 8:0 0 6G 0 disk  
├─sda1 8:1 0 500M 0 part /boot  
└─sda2 8:2 0 5.5G 0 part  
├─r7vg-root\_lv 253:0 0 4.9G 0 lvm /  
└─r7vg-swap\_lv 253:1 0 256M 0 lvm \[SWAP\]  
sdb 8:16 0 102.4M 0 disk  
├─vg\_thin-lv\_thinpool\_tmeta 253:2 0 4M 0 lvm  
│ └─vg\_thin-lv\_thinpool-tpool 253:4 0 92M 0 lvm  
│ ├─vg\_thin-lv\_thinpool 253:5 0 92M 0 lvm  
│ └─vg\_thin-lv\_thin 253:6 0 1G 0 lvm  
└─vg\_thin-lv\_thinpool\_tdata 253:3 0 92M 0 lvm  
└─vg\_thin-lv\_thinpool-tpool 253:4 0 92M 0 lvm  
├─vg\_thin-lv\_thinpool 253:5 0 92M 0 lvm  
└─vg\_thin-lv\_thin 253:6 0 1G 0 lvm  
sr0 11:0 1 1024M 0 rom

-&gt; Recovery machine (fvm-rhel-7-3-38) -after 'rear recover'-:

\[jserrano@ofamera-devel ~\]$ fast-vm ssh 38  
\[inf\] checking the 192.168.33.38 for active SSH connection (ctrl+c to
interrupt)  
\[inf\]  
SSH ready  
Warning: Permanently added '192.168.33.38' (ECDSA) to the list of known
hosts.  
Last login: Mon Aug 21 12:26:46 2017

\[root@fvm-rhel-7-3-34 ~\]\# lvs  
LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert  
root\_lv r7vg -wi-ao---- 4.88g  
swap\_lv r7vg -wi-ao---- 256.00m

\[root@fvm-rhel-7-3-34 ~\]\# lsblk  
NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT  
sda 8:0 0 6G 0 disk  
├─sda1 8:1 0 500M 0 part /boot  
└─sda2 8:2 0 5.5G 0 part  
├─r7vg-root\_lv 253:0 0 4.9G 0 lvm /  
└─r7vg-swap\_lv 253:1 0 256M 0 lvm \[SWAP\]  
sdb 8:16 0 102.4M 0 disk

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2017-10-31 16:05](https://github.com/rear/rear/issues/1380#issuecomment-340812057):

@jmazanek Thank you for your comments (it is also part of the RH BZ
report). As I wrote in the BZ we should start with a prep script to
capture the required binaries in the rescue image. Afterwards it will be
easier to add the missing pieces

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2017-11-27 16:47](https://github.com/rear/rear/issues/1380#issuecomment-347243751):

We are very sorry but we will postpone this for a later release

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2018-05-15 06:59](https://github.com/rear/rear/issues/1380#issuecomment-389063768):

@rmetrich Are you able to assist us with this issue? Is was originally
reported via RedHat. Would be nice if it could be added for ReaR v2.5?

#### <img src="https://avatars.githubusercontent.com/u/1163635?u=36b5e32e1dd55f1ce77cad431a5683fce40a7934&v=4" width="50">[rmetrich](https://github.com/rmetrich) commented at [2018-05-15 07:11](https://github.com/rear/rear/issues/1380#issuecomment-389066611):

@gdha Hello, I will assist, but for now we do not have a fix on the RH
side as well. I need to sync with LVM specialists to have that move
forward.  
It's in my TODO now :-)

#### <img src="https://avatars.githubusercontent.com/u/1163635?u=36b5e32e1dd55f1ce77cad431a5683fce40a7934&v=4" width="50">[rmetrich](https://github.com/rmetrich) commented at [2018-05-16 14:56](https://github.com/rear/rear/issues/1380#issuecomment-389549470):

@gdha See above pull request

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2018-09-19 13:25](https://github.com/rear/rear/issues/1380#issuecomment-422802295):

as it is part of ReaR 2.4 already this one can be closed - thanks to
Renaud @rmetrich

------------------------------------------------------------------------

\[Export of Github issue for
[rear/rear](https://github.com/rear/rear).\]
