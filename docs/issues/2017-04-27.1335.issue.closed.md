[\#1335 Issue](https://github.com/rear/rear/issues/1335) `closed`: ReaR PXE setup for SLES11 to boot HP ProLiant with UEFI
==========================================================================================================================

**Labels**: `support / question`, `fixed / solved / done`

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) opened issue at [2017-04-27 17:40](https://github.com/rear/rear/issues/1335):

#### Relax-and-Recover (ReaR) Issue

Can someone please help me configure rear for DR with PXE. Idea is to
store rear rescue image to PXE server, and in event of disaster, recover
via pxe boot. Sharing of local.conf configuration for this setup will be
highly appreciated.

-   rear version  
    Relax-and-Recover 2.00 / Git
-   OS version  
    SLES 11 SP4

Thanks

#### <img src="https://avatars.githubusercontent.com/u/5380209?u=163f1571e6b9c9c7df94e2c6ca152b0a7406b52d&v=4" width="50">[didacog](https://github.com/didacog) commented at [2017-04-27 18:02](https://github.com/rear/rear/issues/1335#issuecomment-297792758):

Hi,

Maybe you can take a look at DRLM ([www.drlm.org](http://www.drlm.org))
to manage your PXE rear setup with central managent of rear configs,
scheduling and more... ;)

Regards,

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-27 18:05](https://github.com/rear/rear/issues/1335#issuecomment-297793362):

@didacog you was the first thing on my mind when I've read subject of
this issue :-)

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-27 18:14](https://github.com/rear/rear/issues/1335#issuecomment-297795728):

@SuneelOad I've found
[this](https://github.com/rear/rear/blob/16d55433c5e5c1ccc3d7d54f8e096fd8b0b74c2d/usr/share/rear/conf/examples/PXE-booting-example-with-URL-style.conf).

Maybe it helps.

V.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-04-27 22:05](https://github.com/rear/rear/issues/1335#issuecomment-297852350):

@gozora: thanks for sharing, that helped in creating rescue image on PXE
server. But I still can not see rescue image in pxe boot options. Here
is local.conf:

OUTPUT=PXE  
OUTPUT\_PREFIX\_PXE=$HOSTNAME  
BACKUP=NETFS  
BACKUP\_URL=nfs://x.x.x.x/opt/rear  
PXE\_TFTP\_URL=[http://x.x.x.x/tftpboot](http://x.x.x.x/tftpboot)  
PXE\_CONFIG\_URL=[http://x.x.x.x/tftpboot/pxelinux.cfg](http://x.x.x.x/tftpboot/pxelinux.cfg)

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2017-04-28 10:10](https://github.com/rear/rear/issues/1335#issuecomment-297961554):

@SuneelOad You should check the PXE config files at
[http://10.48.187.202/tftpboot/pxelinux.cfg](http://10.48.187.202/tftpboot/pxelinux.cfg)
location.  
Was the upload successful of the config files? Check the rear log to be
sure.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-04-28 15:38](https://github.com/rear/rear/issues/1335#issuecomment-298031814):

@gdha PXE config files were not uploading at
[http://x.x.x.x/tftpboot/pxelinux.cfg](http://x.x.x.x/tftpboot/pxelinux.cfg),
although in logs it says "Created pxelinux config 'rear-xxxx' and
symlinks for IP adresses in
[http://x.x.x.x/tftpboot/pxelinux.cfg](http://x.x.x.x/tftpboot/pxelinux.cfg)".  
But when I am changing it to nfs share at:  
PXE\_TFTP\_URL=nfs://x.x.x.x/opt/rear/tftpboot  
PXE\_CONFIG\_URL=nfs://x.x.x.x/opt/rear/tftpboot/pxelinux.cfg  
then config files are creating but even then I still can not see rescue
image in pxe boot options.

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-28 17:05](https://github.com/rear/rear/issues/1335#issuecomment-298053117):

Maybe I got it all wrong (I never used ReaR with PXE), but is "rescue
image" created with PXE at all?  
Shouldn't PXE just provide initrd and kernel for client booting?

V.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-04-28 17:17](https://github.com/rear/rear/issues/1335#issuecomment-298055876):

@gozora you are right, PXE is just providing initrd and kernel for
client booting.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-04-28 20:45](https://github.com/rear/rear/issues/1335#issuecomment-298102377):

I am able to boot from PXE, now rear recover is failing with following
error:  
ERROR: Mount command 'Mount -v -t nfs -o rw,noatime x.x.x.x:/opt/rear
/tmp/rear.vBU7wCBHSxHI51f/outputfs failed.  
Also, i can not ping to nfs server, looks like network is not working,
but i can boot via PXE (network works in this case) . Any help please!

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-28 21:09](https://github.com/rear/rear/issues/1335#issuecomment-298107403):

Again just a guess, 'ifconfig &lt;dev\_name&gt; inet &lt;ipaddress&gt;
netmask 255.0.0.0`; `rear recover\`

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-04-28 21:16](https://github.com/rear/rear/issues/1335#issuecomment-298108666):

Thanks @gozora that didnt help.  
forgot to mention, I am trying to create rescue image for physical
server (successful) and then PXE booting to Virtual machine (physical to
virtual migration), and PXE booting is also working but while recover it
shows network unreachable, i guess this is some kind of driver issue.
But how to fix it, any help!

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-28 21:21](https://github.com/rear/rear/issues/1335#issuecomment-298109600):

Do you see some network interfaces in `ifconfig -a` output?

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-04-28 21:24](https://github.com/rear/rear/issues/1335#issuecomment-298110240):

yes, it say UP. But i cannot even ping to gateway.

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-28 21:27](https://github.com/rear/rear/issues/1335#issuecomment-298110780):

Can you paste output here?

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-04-28 21:47](https://github.com/rear/rear/issues/1335#issuecomment-298114325):

please see here:  
![rear-eth](https://cloud.githubusercontent.com/assets/28111434/25548493/7e95f6dc-2c21-11e7-9600-97b9a245c87c.png)

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-28 21:54](https://github.com/rear/rear/issues/1335#issuecomment-298115528):

Ok try, ifconfig eth6 inet &lt;ipaddress&gt; netmask 255.0.0.0; rear
recover

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-04-28 22:03](https://github.com/rear/rear/issues/1335#issuecomment-298117125):

Thinking of it, you might really have drivers missing when
migrating...  
Try to search ReaR issues for "howto include modules" to recovery
system.

#### <img src="https://avatars.githubusercontent.com/u/101384?v=4" width="50">[schlomo](https://github.com/schlomo) commented at [2017-05-01 13:58](https://github.com/rear/rear/issues/1335#issuecomment-298337709):

I would be surprised at a driver problem as you actually see a NIC in
the VM. Do you use DHCP on the physical server? If so then maybe there
was an issue picking that up. To check try to add `USE_DHCLIENT=y` and
create a new rescue system to force the rescue system to use DHCP.

I would also expect the rescue system to take you through the network
reconfiguration where you would have to choose the network card.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-01 21:46](https://github.com/rear/rear/issues/1335#issuecomment-298441397):

@gozora "ifconfig eth6 inet <ipaddress> netmask 255.0.0.0; rear recover"
solved network issue and recover is successfully finished, but after
reboot system is not booting up (error: OS not found). I checked BIOS
setting and changed it local disk, even that didnt solve the issue. Any
suggestion, anyone please? pasting error below:  
![image](https://cloud.githubusercontent.com/assets/28111434/25596207/ee57c650-2e7c-11e7-8946-24c06bb4abe7.png)

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-02 00:03](https://github.com/rear/rear/issues/1335#issuecomment-298464238):

and here is error message if i am trying recover on same physical
server:  
![image](https://cloud.githubusercontent.com/assets/28111434/25599308/0880c6b8-2e90-11e7-98b2-485502b585b1.png)

any help...

#### <img src="https://avatars.githubusercontent.com/u/946581?u=6c08f02ac67727afa178cbb7dc926c0b7e3d862d&v=4" width="50">[icebal](https://github.com/icebal) commented at [2017-05-05 21:00](https://github.com/rear/rear/issues/1335#issuecomment-299574461):

See issue \#214 on this. SLES has a patched version of mkisofs and
causes issues with uefo. The current solution is located at this link:
[http://www.it3.be/2015/10/27/uefi-iso-boot-with-ebiso/](http://www.it3.be/2015/10/27/uefi-iso-boot-with-ebiso/)

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2017-05-09 11:31](https://github.com/rear/rear/issues/1335#issuecomment-300136278):

@SuneelOad Are your questions answered?

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-10 19:53](https://github.com/rear/rear/issues/1335#issuecomment-300594074):

@gdha nope, still trying to solve the issue :(

#### <img src="https://avatars.githubusercontent.com/u/946581?u=6c08f02ac67727afa178cbb7dc926c0b7e3d862d&v=4" width="50">[icebal](https://github.com/icebal) commented at [2017-05-11 00:15](https://github.com/rear/rear/issues/1335#issuecomment-300647267):

@SuneelOad you can also try with installing xorriso and run rear
mkbackup -v and see if it is throwing the flag USING\_EFI\_BOOTLOADER=1.
if it is, it is creating a efi compatible disk. if it is not, you can
set it manually in the config.  
edit - this is for ISO, not PXE like you are trying, my bad....

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-12 16:42](https://github.com/rear/rear/issues/1335#issuecomment-301126883):

After running rear -v recover i am getting this error:  
![image](https://cloud.githubusercontent.com/assets/28111434/26007896/4f41540e-36f7-11e7-98c8-37bd77bbf6dd.png)

Any help, Please!

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-05-12 17:06](https://github.com/rear/rear/issues/1335#issuecomment-301132444):

Hello @SuneelOad,

2 things ...

1.  In my copy of ReaR (cloned from upstream) I have
    *220\_install\_elilo.sh* instead of yours
    **620\_install\_elilo.sh**, did you somehow modify your copy of ReaR
    ?

2.  Do you have file called */sbin/elilo* on your original system?

V.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-12 17:10](https://github.com/rear/rear/issues/1335#issuecomment-301133260):

Hi @gozora:

1.  I got rear from git: git clone
    [https://github.com/rear/rear.git](https://github.com/rear/rear.git),
    and i didn't modified anything other than local.conf file.
2.  yes, I have /sbin/elilo in my original HP Proliant server running
    SLES 11.4

Thanks

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-12 23:02](https://github.com/rear/rear/issues/1335#issuecomment-301204583):

Does REAR work with PXE ( HP proliant running sles 11.x) , anyone tried?

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-13 00:02](https://github.com/rear/rear/issues/1335#issuecomment-301210866):

tried to restore on same server but still getting same error while rear
recover, as above : "Error: could not find elilo executables". Pasting
local.conf again:

OUTPUT=PXE  
OUTPUT\_PREFIX\_PXE=$HOSTNAME  
BACKUP=NETFS  
BACKUP\_URL=nfs://x.x.x.x/opt/rear  
PXE\_TFTP\_URL=nfs://x.x.x.x/tftpboot  
PXE\_CONFIG\_URL=nfs://x.x.x.x/tftpboot/pxelinux.cfg  
ISO\_MKISOFS\_BIN=/usr/bin/ebiso  
USE\_DHCLIENT=y

Any help!

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2017-05-13 05:54](https://github.com/rear/rear/issues/1335#issuecomment-301227615):

@SuneelOad I wouldn't know why PXE booting wouldn't work on HPE Proliant
systems. The rear config looks OK to me, and I guess that PXE booting
works? Or am I wrong?

Could you paste the output of `head /var/lib/rear/recovery/*` ?

You could run once `rear -dDv mkrescue` and verify the rear log to see
whether the **elilo** executable was copied to the rescue image, and to
double check you can do a `find /tmp/rear.xxxx -name elilo` (replace the
xxxx with what you see in the rear output at the end)

#### <img src="https://avatars.githubusercontent.com/u/4497476?v=4" width="50">[razorfish-sl](https://github.com/razorfish-sl) commented at [2017-05-13 22:23](https://github.com/rear/rear/issues/1335#issuecomment-301278489):

you may need more information.  
WHICH proliant & WHICH gen.  
I'm having issues with proliant now........ not even got as far as you.

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2017-05-15 09:21](https://github.com/rear/rear/issues/1335#issuecomment-301422198):

@gozora  
regarding things like  
220\_install\_elilo.sh versus 620\_install\_elilo.sh  
see
[https://github.com/rear/rear/issues/1331](https://github.com/rear/rear/issues/1331)  
and
[https://github.com/rear/rear/pull/1323](https://github.com/rear/rear/pull/1323)
therein  
[https://github.com/rear/rear/pull/1323\#issuecomment-298067993](https://github.com/rear/rear/pull/1323#issuecomment-298067993)  
and the matching commit  
[https://github.com/rear/rear/pull/1323/commits/968a6bcea58e7687f9b56774b1bf06cbb8ca00b1](https://github.com/rear/rear/pull/1323/commits/968a6bcea58e7687f9b56774b1bf06cbb8ca00b1)

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-05-15 10:27](https://github.com/rear/rear/issues/1335#issuecomment-301436949):

@jsmeix, Yes stupid me did not read message after `git pull` so I
thought that I'm working with most recent version ...

    You asked to pull from the remote 'rear', but did not specify
    a branch. Because this is not the default configured remote
    for your current branch, you must specify a branch on the command line.

Thanks!

V.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-15 23:13](https://github.com/rear/rear/issues/1335#issuecomment-301630756):

Thank you all for your help, I can now restore and server is working
fine after restore :) only change i made was to download rear packages
from
[http://download.opensuse.org/repositories/Archiving:/Backup:/Rear/SLE\_12\_SP1/x86\_64/](http://download.opensuse.org/repositories/Archiving:/Backup:/Rear/SLE_12_SP1/x86_64/)
, rather than using git clone.  
So far, I can backup/restore from Physical to Physical (HP Proliant
DL380 G9: P2P) and from Virtual to Virtual (V2V), but I still have
problems in P2V. In this case restore is finished successfully but when
reboots, it says no OS found, any help here is appreciated. Thanks

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2017-05-16 07:23](https://github.com/rear/rear/issues/1335#issuecomment-301698036):

@SuneelOad  
your above  
[https://github.com/rear/rear/issues/1335\#issuecomment-301630756](https://github.com/rear/rear/issues/1335#issuecomment-301630756)  
looks somewhat scaring because it means that  
some older ReaR version works for you while  
the current ReaR GitHub master does no longer work for you  
i.e. it looks like a regression somewhere in the current ReaR.

Under  
[http://download.opensuse.org/repositories/Archiving:/Backup:/Rear/SLE\_12\_SP1/x86\_64/](http://download.opensuse.org/repositories/Archiving:/Backup:/Rear/SLE_12_SP1/x86_64/)  
there is  
ebiso-0.2.5-1.x86\_64.rpm  
plus several ReaR versions  
rear-1.17.2-1.x86\_64.rpm  
rear-1.18-3.x86\_64.rpm  
rear-1.19-2.x86\_64.rpm  
rear-2.00-1.x86\_64.rpm  
Which exact ReaR version does work for you?

Regarding P2P and V2V works while P2V does not work:  
I guess with P2P and V2V you run "rear recover"  
on the same physical or virtual hardware as  
what you used for "rear mkbackup".  
In contrast for P2V you do a system migration  
from some physical hardware where "rear mkbackup" was run  
to some (obviously different) virtual hardware where "rear recover"  
is run.  
In general system migration with ReaR is tricky, cf.  
[https://github.com/rear/rear/issues/1155\#issuecomment-271236931](https://github.com/rear/rear/issues/1155#issuecomment-271236931)

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-16 16:05](https://github.com/rear/rear/issues/1335#issuecomment-301831204):

@jsmeix  
I installed ebiso-0.2.5-1.x86\_64.rpm and rear-2.00-1.x86\_64.rpm, which
worked for me. On physical server I reinstall OS from SLES 11.4 to SLES
12.2 and installed above rpm packages rather than git, and it worked
(P2P).  
On Virtual server (running SLES 11.4) , i didnt do any change other than
installing above rpm packages without git clone, and that worked too
(V2V).  
And thanks for P2V link, I'll give that a try.

Thanks

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-05-16 18:21](https://github.com/rear/rear/issues/1335#issuecomment-301870866):

@jsmeix

> looks somewhat scaring because it means that  
> some older ReaR version works for you while  
> the current ReaR GitHub master does no longer work for you  
> i.e. it looks like a regression somewhere in the current ReaR.

I just successfully finished test recovery of my SLES11 SP3 with latest
upstream commit 8ce891f .  
So I don't think any regression was introduced.

Following configuration was used:

    BACKUP=NETFS     
    OUTPUT=ISO
    BACKUP_URL=nfs://beta/mnt/rear
    OUTPUT_URL=nfs://beta/mnt/rear/iso

    ONLY_INCLUDE_VG=( "vg00" )
    EXCLUDE_BACKUP=( ${EXCLUDE_BACKUP[@]} fs:/crash fs:/usr/sap fs:/oracle )
    BACKUP_PROG_EXCLUDE=( ${BACKUP_PROG_EXCLUDE[@]} '/mnt/*' )
    ISO_MKISOFS_BIN=/usr/bin/ebiso

    EXCLUDE_MD=( $(grep -o -E '^md[0-9]+' /proc/mdstat) ) # exclude all md devices

    GRUB_RESCUE=n
    COPY_AS_IS=( ${COPY_AS_IS[@]} /sbin/sysctl /etc/sysctl.conf /sbin/vconfig /sbin/if* /etc/sysconfig/network /sbin/shutdown.wrap )

@SuneelOad

> So far, I can backup/restore from Physical to Physical (HP Proliant
> DL380 G9: P2P) and from Virtual to Virtual (V2V), but I still have
> problems in P2V. In this case restore is finished successfully but
> when reboots, it says no OS found, any help here is appreciated.

During your P2V recovery, are your source and destination servers using
SAME boot method (UEFI/Legacy boot) ?

V.

#### <img src="https://avatars.githubusercontent.com/u/28111434?v=4" width="50">[sko341](https://github.com/sko341) commented at [2017-05-16 19:53](https://github.com/rear/rear/issues/1335#issuecomment-301896265):

@gozora no both are different boot methods, i.e. physical uses UEFI and
VM is grub.

Thanks,

#### <img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50">[gozora](https://github.com/gozora) commented at [2017-05-16 20:01](https://github.com/rear/rear/issues/1335#issuecomment-301898403):

@SuneelOad

As far as I know, ReaR can't handle restores from UEFI to legacy boot
(grub) and vice versa.  
(@schlomo, @gdha, @jsmeix correct me if I'm wrong)

You'd need to do some manual "magic" to make such migration work ...

V.

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2017-05-17 09:13](https://github.com/rear/rear/issues/1335#issuecomment-302032824):

Changing the bootloader is another "migration" thing  
that cannot work automatically - as far as I can imagine -  
because re-installing the bootloader on the recreated system  
happens after backup restore (during the 'finalize' stage)  
by using the restored bootloader config files from the backup  
to that changing the bootloader on the recreated system  
requires changes of the bootloader config files and that  
does not happen by ReaR.

This means - as far as I can imagine - changing the bootloader  
on the recreated system must be done manually from within  
the still running ReaR recovery system after "rear recover"  
had finished.

I think this can be done basically in the same way  
as I do it in my script for  
"Generic system installation with the plain SUSE installation system"  
in
[https://en.opensuse.org/SDB:Disaster\_Recovery](https://en.opensuse.org/SDB:Disaster_Recovery)

For example after adapting the restored bootloader config files  
the actual bootloader installation could be done via something  
like (replace "/dev/sdXn" as needed):

<pre>
target_system_filesystem_root="/mnt/local"
bootloader_install_device="/dev/sdXn"

# Make /proc /sys /dev from the installation system
# or from the ReaR recovery system
# available in the target system:
for mountpoint_directory in proc sys dev
do mkdir $target_system_filesystem_root/$mountpoint_directory
done
mount -t proc none $target_system_filesystem_root/proc
mount -t sysfs sys $target_system_filesystem_root/sys
mount -o bind /dev $target_system_filesystem_root/dev

# Make initrd verbosely in the target system:
chroot $target_system_filesystem_root /bin/bash --login -c "/sbin/mkinitrd -v"

# Install bootloader in the target system:
# Make bootloader configuration in the target system:
chroot $target_system_filesystem_root /bin/bash --login -c "/usr/sbin/grub2-mkconfig -o /boot/grub2/grub.cfg"
# Install bootloader in the target system:
chroot $target_system_filesystem_root /usr/sbin/grub2-install --force $bootloader_install_device
</pre>

That has worked for me on SLES12 on a simple virtual machine.  
On SLES11 things are probably a bit different and  
on HP ProLiant hardware things are perhaps even more different.

As far as I know the only part of a system migration where  
ReaR has some (limited) support is disk layout migration.  
In particular migrating from a single disk to a bigger single disk  
should usually work (except some exceptions ;-)

But I think one cannot expect that e.g. migrating from  
one single 600 GiB traditional spinning harddisk  
to two 400 GiB SSDs will "just work" automatically  
or the other way round migrating a LVM setup  
that uses several traditional spinning harddisks  
to a single big virtual disk on a virtual machine.

#### <img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50">[jsmeix](https://github.com/jsmeix) commented at [2017-05-17 12:05](https://github.com/rear/rear/issues/1335#issuecomment-302069770):

I tested my above  
[https://github.com/rear/rear/issues/1335\#issuecomment-302032824](https://github.com/rear/rear/issues/1335#issuecomment-302032824)  
and adapted it so that it now works for me one SLES12-SP2  
because I found out that I need some adaptions,  
mainly I need sometimes a bash login shell for 'chroot' i.e.

<pre>
chroot $target_system_filesystem_root /bin/bash --login -c "..."
</pre>

cf.
[https://github.com/rear/rear/issues/862](https://github.com/rear/rear/issues/862)  
and
[https://github.com/rear/rear/pull/1171](https://github.com/rear/rear/pull/1171)  
and the resulting problems and bad consequences  
[https://github.com/rear/rear/issues/862\#issuecomment-274068914](https://github.com/rear/rear/issues/862#issuecomment-274068914)  
[https://github.com/rear/rear/issues/862\#issuecomment-282039428](https://github.com/rear/rear/issues/862#issuecomment-282039428)  
[https://github.com/rear/rear/pull/1345\#issuecomment-299798204](https://github.com/rear/rear/pull/1345#issuecomment-299798204)

Furthermore I tried to avoid that "rear recover" installs  
a bootloader at all but it seems that is not easily possible  
because setting in the recovery system in local.conf

<pre>
NOBOOTLOADER=1
</pre>

and also in the recovery system

<pre>
# mv /var/lib/rear/recovery/bootloader /var/lib/rear/recovery/bootloader.orig
</pre>

did not avoid that "rear recover" installs a bootloader  
GRUB2 in my case via finalize/Linux-i386/620\_install\_grub2.sh

#### <img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50">[gdha](https://github.com/gdha) commented at [2017-08-16 09:21](https://github.com/rear/rear/issues/1335#issuecomment-322714721):

@sko341 is your question answered sufficiently or do you still have
other concerns at this point in time?

#### <img src="https://avatars.githubusercontent.com/u/1309004?v=4" width="50">[Hardcore-fs](https://github.com/Hardcore-fs) commented at [2018-01-18 09:22](https://github.com/rear/rear/issues/1335#issuecomment-358586539):

lets close it for now

------------------------------------------------------------------------

\[Export of Github issue for
[rear/rear](https://github.com/rear/rear).\]
