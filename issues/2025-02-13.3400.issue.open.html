<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <meta property="og:title" content="Relax-and-Recover (ReaR) User Guide Documentation"/>
    <meta property="og:description" content="This is an umbrella documentation project for all Relax-and-Recover (ReaR) kind of documentation ans starting with a good User Guide."/>
    <meta property="og:locale" content="en_US"/>
    <meta property="og:url" content="https://relax-and-recover.org/rear-user-guide/"/>
    <meta property="og:type" content="website"/>
    <meta property="og:image" content="https://relax-and-recover.org/rear-user-guide/img/rear_logo_50.png"/>
    <meta property="og:image:width" content="50"/>
    <meta property="og:image:height" content="50"/>
    
    <title>#3400 Issue open: Falsely "automatically excluding disk /dev/nvme4n1 (not used by any mounted filesystem)" - Relax-and-Recover (ReaR) User Guide Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../css/rear.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "#3400 Issue open: Falsely \"automatically excluding disk /dev/nvme4n1 (not used by any mounted filesystem)\"";
        var mkdocs_page_input_path = "issues/2025-02-13.3400.issue.open.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/rust.min.js"></script>
      <script>hljs.highlightAll();</script> 
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', "366986045", "auto");
        ga('send', 'pageview');
      </script>
    
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../index.html" class="icon icon-home"> Relax-and-Recover (ReaR) User Guide Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">WELCOME</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../welcome/index.html">Get started!</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">BASICS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/introduction.html">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/history.html">Bit of History</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/getting-started.html">Getting started with ReaR</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/configuration.html">Basic configuration</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/backup_netfs.html">Example of BACKUP=NETFS</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">SCENARIOS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/index.html">Scenarios Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/netfs_nas.html">Internal Backup with tar to NFS server</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/netfs_rsync.html">Internal Backup with rsync to NFS server</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/rbme.html">External Backup using RBME</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/restic.html">External Backup using restic</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">DEVELOPMENT</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../development/github-pr.html">Make a pull request with GitHub</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../development/squash-git-log-commments.html">How to squash git log comments into one line</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/index.html">Release Notes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear29.html">Release Notes ReaR 2.9</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear28.html">Release Notes ReaR 2.8</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear27.html">Release Notes ReaR 2.7</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear26.html">Release Notes ReaR 2.6</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/knownproblems.html">Known Problems and Workarounds</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">ISSUES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="index.html">Issues History</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">LEGAL</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/contributing/index.html">Contributing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/license/index.html">License</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html" class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">#3400 Issue open: Falsely "automatically excluding disk /dev/nvme4n1 (not used by any mounted filesystem)"</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="3400_issue_open_falsely_automatically_excluding_disk_devnvme4n1_not_used_by_any_mounted_filesystem"><a href="https://github.com/rear/rear/issues/3400">#3400 Issue</a> <code>open</code>: Falsely "automatically excluding disk /dev/nvme4n1 (not used by any mounted filesystem)"<a class="headerlink" href="#3400_issue_open_falsely_automatically_excluding_disk_devnvme4n1_not_used_by_any_mounted_filesystem" title="Permanent link">&para;</a></h1>
<p><strong>Labels</strong>: <code>bug</code>, <code>fixed / solved / done</code></p>
<h4 id="gdha_opened_issue_at_2025-02-13_1433"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> opened issue at <a href="https://github.com/rear/rear/issues/3400">2025-02-13 14:33</a>:<a class="headerlink" href="#gdha_opened_issue_at_2025-02-13_1433" title="Permanent link">&para;</a></h4>
<h3 id="rear_version">ReaR version<a class="headerlink" href="#rear_version" title="Permanent link">&para;</a></h3>
<p>2.9</p>
<h3 id="describe_the_rear_bug_in_detail">Describe the ReaR bug in detail<a class="headerlink" href="#describe_the_rear_bug_in_detail" title="Permanent link">&para;</a></h3>
<p>Some real mount points listed in the <code>/etc/fstab</code> are commented out in
the <code>disklayout.conf</code> file, e.g.<br />
line:
<code>UUID=89142993-8500-42fe-8458-e8ccda4a7113 /var/lib/rancher xfs defaults 0 0</code>
in <code>/etc/fstab</code> is<br />
<code>/dev/nvme4n1                     167731200  78233564         89497636  47% /var/lib/rancher</code>
in the <code>df</code> output.</p>
<p>However, in the <code>disklayout.conf</code> file this line is commented:<br />
<code>#fs /dev/nvme4n1 /var/lib/rancher xfs uuid=89142993-8500-42fe-8458-e8ccda4a7113 label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota</code></p>
<h3 id="platform">Platform<a class="headerlink" href="#platform" title="Permanent link">&para;</a></h3>
<p>Linux x64</p>
<h3 id="os_version">OS version<a class="headerlink" href="#os_version" title="Permanent link">&para;</a></h3>
<p>RHEL 9.5</p>
<h3 id="backup">Backup<a class="headerlink" href="#backup" title="Permanent link">&para;</a></h3>
<p><em>No response</em></p>
<h3 id="storage_layout">Storage layout<a class="headerlink" href="#storage_layout" title="Permanent link">&para;</a></h3>
<pre><code>#-&gt; lsblk -ipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT
NAME             KNAME          PKNAME       TRAN   TYPE FSTYPE      LABEL     SIZE MOUNTPOINT
/dev/sda         /dev/sda                    iscsi  disk ext4                   60G /var/lib/kubelet/pods/2c4faad8-2f2b-45f3-bb83-229059f1ec84/volumes/kubernetes.io~csi/pvc-d2566b87-3cad-4458-9175-72076d342aee/
/dev/sdb         /dev/sdb                    iscsi  disk                        50G /var/lib/kubelet/pods/64153360-6afb-4f1d-8854-db7ca58d9326/volumes/kubernetes.io~csi/pvc-89ba1477-4a18-4af1-8534-e67fb916c187/
/dev/sdc         /dev/sdc                    iscsi  disk                         1G /var/log
/dev/sdd         /dev/sdd                    iscsi  disk                         5G /var/lib/kubelet/pods/d086b3b4-dadb-4da7-8db1-f672f5d3b4b8/volumes/kubernetes.io~csi/pvc-e53f8225-6e04-4d24-b9db-e8fc7dea3f51/
/dev/nvme1n1     /dev/nvme1n1                nvme   disk xfs                   550G /app/elasticsearch
/dev/nvme0n1     /dev/nvme0n1                nvme   disk                        30G
|-/dev/nvme0n1p1 /dev/nvme0n1p1 /dev/nvme0n1 nvme   part                         1M
`-/dev/nvme0n1p2 /dev/nvme0n1p2 /dev/nvme0n1 nvme   part xfs                    30G /
/dev/nvme2n1     /dev/nvme2n1                nvme   disk LVM2_member            20G
`-/dev/mapper/vg_app-lg_app
                 /dev/dm-0      /dev/nvme2n1        lvm  xfs         lg_app     20G /app
/dev/nvme4n1     /dev/nvme4n1                nvme   disk xfs                   160G /var/lib/rancher
/dev/nvme3n1     /dev/nvme3n1                nvme   disk                         4G
/dev/nvme6n1     /dev/nvme6n1                nvme   disk xfs                   200G /app/data/longhorn
/dev/nvme5n1     /dev/nvme5n1                nvme   disk xfs                    20G /var/log
/dev/nvme7n1     /dev/nvme7n1                nvme   disk                        10G
|-/dev/nvme7n1p1 /dev/nvme7n1p1 /dev/nvme7n1 nvme   part vfat        REAR-EFI    1G
`-/dev/nvme7n1p2 /dev/nvme7n1p2 /dev/nvme7n1 nvme   part ext3        REAR-000    9G
</code></pre>
<p>The <code>/etc/fstab</code> file contains:</p>
<pre><code>UUID=c9aa25ee-e65c-4818-9b2f-fa411d89f585 /                       xfs     defaults        0 0
/dev/vg_app/lg_app       /app    xfs     auto,nofail,defaults    1 2
UUID=6281fd1f-d107-427a-a22c-2f575fb7a58c /app/elasticsearch xfs defaults 0 0
UUID=0f12a909-7cbf-487d-8bcb-663eeaabf3c2 /var/log xfs defaults,nodev,nosuid,noexec 0 0
UUID=89142993-8500-42fe-8458-e8ccda4a7113 /var/lib/rancher xfs defaults 0 0
UUID=5a2a74b7-9c6f-4af6-bbc6-9e2ecd52a314 /app/data/longhorn xfs defaults 0 0
</code></pre>
<h3 id="what_steps_will_reproduce_the_bug">What steps will reproduce the bug?<a class="headerlink" href="#what_steps_will_reproduce_the_bug" title="Permanent link">&para;</a></h3>
<pre><code>#-&gt; sbin/rear -D savelayout
Relax-and-Recover 2.9 / 2025-01-31
Running rear savelayout (PID 1032097 date 2025-02-13 15:23:10)
Command line options: sbin/rear -D savelayout
Using log file: /home/gdhaese1/projects/rear/var/log/rear/rear-AWSABLIRLL000K.log
Using build area: /var/tmp/rear.9rUmpk3qW9R3ff1
Setting TMPDIR to ReaR's '/var/tmp/rear.9rUmpk3qW9R3ff1/tmp' (was unset when ReaR was launched)
Running 'init' stage ======================
Running workflow savelayout on the normal/original system
Running 'layout/save' stage ======================
Creating disk layout
Overwriting existing disk layout file /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Automatically excluding disk /dev/nvme3n1 (not used by any mounted filesystem)
Marking component '/dev/nvme3n1' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Automatically excluding disk /dev/nvme4n1 (not used by any mounted filesystem)
Marking component '/dev/nvme4n1' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Dependent component fs:/var/lib/rancher is a child of component /dev/nvme4n1
Marking component 'fs:/var/lib/rancher' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Automatically excluding disk /dev/nvme5n1 (not used by any mounted filesystem)
Marking component '/dev/nvme5n1' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Dependent component fs:/var/log is a child of component /dev/nvme5n1
Marking component 'fs:/var/log' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Automatically excluding disk /dev/nvme7n1 (not used by any mounted filesystem)
Marking component '/dev/nvme7n1' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Dependent component /dev/nvme7n1p1 is a child of component /dev/nvme7n1
Marking component '/dev/nvme7n1p1' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Dependent component /dev/nvme7n1p2 is a child of component /dev/nvme7n1
Marking component '/dev/nvme7n1p2' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Automatically excluding disk /dev/sda (not used by any mounted filesystem)
Marking component '/dev/sda' as done in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Automatically excluding disk /dev/nvme3n1 (not used by any mounted filesystem)
Component '/dev/nvme3n1' is marked as 'done /dev/nvme3n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Automatically excluding disk /dev/nvme5n1 (not used by any mounted filesystem)
Component '/dev/nvme5n1' is marked as 'done /dev/nvme5n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Dependent component fs:/var/log is a child of component /dev/nvme5n1
Component 'fs:/var/log' is marked as 'done fs:/var/log' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Automatically excluding disk /dev/nvme4n1 (not used by any mounted filesystem)
Component '/dev/nvme4n1' is marked as 'done /dev/nvme4n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Dependent component fs:/var/lib/rancher is a child of component /dev/nvme4n1
Component 'fs:/var/lib/rancher' is marked as 'done fs:/var/lib/rancher' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
Disabling excluded components in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'disk /dev/nvme3n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'disk /dev/nvme4n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'disk /dev/nvme5n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'disk /dev/nvme7n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'part /dev/nvme7n1' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Component 'part /dev/nvme7n1' is disabled in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'disk /dev/sda' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Component 'disk /dev/nvme3n1' is disabled in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Component 'disk /dev/nvme5n1' is disabled in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Component 'disk /dev/nvme4n1' is disabled in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'fs ... /var/lib/rancher' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
Disabling component 'fs ... /var/log' in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
GRUB found in first bytes on /dev/nvme0n1 and GRUB 2 is installed, using GRUB2 as a guessed bootloader for 'rear recover'
Skip saving storage layout as 'barrel' devicegraph (no 'barrel' command)
Verifying that the entries in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf are correct
Created disk layout (check the results in /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf)
Exiting rear savelayout (PID 1032097) and its descendant processes ...
Running exit tasks
To remove the build area you may use (with caution): rm -Rf --one-file-system /var/tmp/rear.9rUmpk3qW9R3ff1

#-&gt; grep -v \# ../var/lib/rear/layout/disklayout.conf
disk /dev/nvme0n1 32212254720 gpt
part /dev/nvme0n1 1048576 1048576 rear-noname bios_grub /dev/nvme0n1p1
part /dev/nvme0n1 32210140672 2097152 rear-noname none /dev/nvme0n1p2
disk /dev/nvme1n1 590558003200 loop
disk /dev/nvme2n1 21474836480 unknown
disk /dev/nvme6n1 214748364800 loop
lvmdev /dev/vg_app /dev/nvme2n1 5jSbmk-ooLT-rpTk-A3nB-cum8-FF1v-fmCRG6 21470642176
lvmgrp /dev/vg_app 4096 5119 20967424
lvmvol /dev/vg_app lg_app 21470642176b linear
fs /dev/longhorn/pvc-89ba1477-4a18-4af1-8534-e67fb916c187 /var/lib/kubelet/plugins/kubernetes.io/csi/driver.longhorn.io/5f9dffb77504aaa81768b25cdfc050f65d7128106e43a32e3576b6a80068957a/globalmount ext4 uuid=8d878d19-ffe5-46e2-ad10-00c68af1a855 label= blocksize=4096 reserved_blocks=0% max_mounts=-1 check_interval=0d bytes_per_inode=16384 default_mount_options=user_xattr,acl options=rw,relatime
fs /dev/longhorn/pvc-d2566b87-3cad-4458-9175-72076d342aee /var/lib/kubelet/plugins/kubernetes.io/csi/driver.longhorn.io/3fa3d3d63dba018d962e3388b8ea4f64eba99189f524247debac6f414f1e4b09/globalmount ext4 uuid=f5f54428-765b-42e3-a20f-cfa5e476de36 label= blocksize=4096 reserved_blocks=0% max_mounts=-1 check_interval=0d bytes_per_inode=16384 default_mount_options=user_xattr,acl options=rw,relatime
fs /dev/longhorn/pvc-e53f8225-6e04-4d24-b9db-e8fc7dea3f51 /var/lib/kubelet/plugins/kubernetes.io/csi/driver.longhorn.io/23150dd0f272a1b4923866721c5800414602ece2645428d106e7a8cdfb8ff657/globalmount ext4 uuid=6110a429-e28f-4288-a7b7-285e4958827d label= blocksize=4096 reserved_blocks=0% max_mounts=-1 check_interval=0d bytes_per_inode=16384 default_mount_options=user_xattr,acl options=rw,relatime
fs /dev/mapper/vg_app-lg_app /app xfs uuid=beb48049-5b75-46c2-8e75-a6f8d3881d0e label=lg_app  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme0n1p2 / xfs uuid=c9aa25ee-e65c-4818-9b2f-fa411d89f585 label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme1n1 /app/elasticsearch xfs uuid=6281fd1f-d107-427a-a22c-2f575fb7a58c label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme6n1 /app/data/longhorn xfs uuid=5a2a74b7-9c6f-4af6-bbc6-9e2ecd52a314 label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
</code></pre>
<h3 id="workaround_if_any">Workaround, if any<a class="headerlink" href="#workaround_if_any" title="Permanent link">&para;</a></h3>
<p>Not yet found.</p>
<h3 id="additional_information">Additional information<a class="headerlink" href="#additional_information" title="Permanent link">&para;</a></h3>
<p>The debug log file of the <code>savelayout</code> run:<br />
<a href="https://github.com/user-attachments/files/18785276/rear-AWSABLIRLL000K.log">rear-AWSABLIRLL000K.log</a></p>
<h4 id="jsmeix_commented_at_2025-02-13_1556"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2657043550">2025-02-13 15:56</a>:<a class="headerlink" href="#jsmeix_commented_at_2025-02-13_1556" title="Permanent link">&para;</a></h4>
<p>@gdha<br />
only a first vague analysis (I could be easily wrong here<br />
because of a "too deeply nested things" mental overflow):</p>
<p>I think it happens in<br />
layout/save/default/320_autoexclude.sh<br />
in this code part</p>
<pre><code># looking for parent in disk AND multipath device for a given fs:mountpoint
disks=$(find_disk_and_multipath fs:$mountpoint)
for disk in $disks ; do
    if ! IsInArray "$disk" "${used_disks[@]}" ; then
        used_disks+=( "$disk" )
    fi
done
</code></pre>
<p>therein inparticular what the call</p>
<pre><code>find_disk_and_multipath fs:/var/lib/rancher
</code></pre>
<p>results because in your rear-AWSABLIRLL000K.log</p>
<pre><code># cat rear-AWSABLIRLL000K.log \
 | sed -n '/ source .*320_autoexclude.sh/,/ source /p' \
 | sed -n '/find_disk_and_multipath fs:\/var\/lib\/rancher/,/find_disk_and_multipath fs/p'
</code></pre>
<p>shows (excerpts)</p>
<pre><code>+++ find_disk_and_multipath fs:/var/lib/rancher
+++ find_disk fs:/var/lib/rancher
+++ get_parent_components fs:/var/lib/rancher disk
...
+++ echo /dev/nvme0n1
...
++ disks=/dev/nvme0n1
++ for disk in $disks
++ IsInArray /dev/nvme0n1 /dev/nvme0n1 /dev/nvme2n1 /dev/nvme1n1
</code></pre>
<p>so it seems the call</p>
<pre><code>get_parent_components fs:/var/lib/rancher disk
</code></pre>
<p>falsely results '/dev/nvme0n1'<br />
as parent 'disk' component of 'fs:/var/lib/rancher'<br />
(and that disk is already in the used_disks array)<br />
so the true parent 'disk' component of 'fs:/var/lib/rancher'<br />
which is '/dev/nvme4n1' gets never added to the used_disks array<br />
so that in the end the subsequent code in<br />
layout/save/default/320_autoexclude.sh</p>
<pre><code>while read disk name junk ; do
    if ! IsInArray "$name" "${used_disks[@]}" ; then
        DebugPrint "Automatically excluding disk $name (not used by any mounted filesystem)"
</code></pre>
<p>does</p>
<pre><code>++ read disk name junk
++ IsInArray /dev/nvme4n1 /dev/nvme0n1 /dev/nvme2n1 /dev/nvme1n1 /dev/nvme6n1
++ return 1
++ DebugPrint 'Automatically excluding disk /dev/nvme4n1 (not used by any mounted filesystem)'
</code></pre>
<h4 id="gdha_commented_at_2025-02-14_0834"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2658600491">2025-02-14 08:34</a>:<a class="headerlink" href="#gdha_commented_at_2025-02-14_0834" title="Permanent link">&para;</a></h4>
<p>The message:</p>
<pre><code>2025-02-14 09:16:26.707378591 No partitions found on /dev/nvme4n1
</code></pre>
<p>In script <code>200_partition_layout.sh</code> function <code>extract_partitions</code>
doesn't find any partition for device nvme4n1:</p>
<pre><code>#-&gt; ls /sys/block/nvme4n1/nvme*
ls: cannot access '/sys/block/nvme4n1/nvme*': No such file or directory
</code></pre>
<p>However, there is one partition available:</p>
<pre><code>#-&gt; parted /dev/nvme4n1 print
Model: Amazon Elastic Block Store (nvme)
Disk /dev/nvme4n1: 172GB
Sector size (logical/physical): 512B/4096B
Partition Table: loop
Disk Flags:

Number  Start  End    Size   File system  Flags
 1      0.00B  172GB  172GB  xfs
</code></pre>
<p>On the other hand <code>fdisk</code> sees nothing, but we are not relying anymore
on <code>fdisk</code>,</p>
<pre><code>#-&gt; fdisk -l /dev/nvme4n1
Disk /dev/nvme4n1: 160 GiB, 171798691840 bytes, 335544320 sectors
Disk model: Amazon Elastic Block Store
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
</code></pre>
<p>Which is correct? Could it be that our function <code>extract_partitions</code> is
incomplete?</p>
<h4 id="gdha_commented_at_2025-02-14_0919"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2658707482">2025-02-14 09:19</a>:<a class="headerlink" href="#gdha_commented_at_2025-02-14_0919" title="Permanent link">&para;</a></h4>
<p>The reason is most likely that the file system is mounted on the device
itself and not on a partition:</p>
<pre><code>#-&gt; lsblk /dev/nvme4n1
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
nvme4n1 259:5    0  160G  0 disk /var/lib/rancher

#-&gt; blkid -s UUID -o value /dev/nvme4n1
89142993-8500-42fe-8458-e8ccda4a7113

#-&gt; blkid -s UUID -o value /dev/nvme4n1p1
</code></pre>
<p>In the <code>/etc/fstab</code> file we have:</p>
<pre><code>UUID=89142993-8500-42fe-8458-e8ccda4a7113 /var/lib/rancher xfs defaults 0 0
</code></pre>
<p>Search goes on...</p>
<h4 id="gdha_commented_at_2025-02-14_1107"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2659006729">2025-02-14 11:07</a>:<a class="headerlink" href="#gdha_commented_at_2025-02-14_1107" title="Permanent link">&para;</a></h4>
<pre><code>#-&gt; cat /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
todo /dev/nvme0n1 disk
todo /dev/nvme0n1p1 part
todo /dev/nvme0n1p2 part
todo /dev/nvme1n1 disk
todo /dev/nvme2n1 disk
todo /dev/nvme3n1 disk
todo /dev/nvme4n1 disk
todo /dev/nvme5n1 disk
todo /dev/nvme6n1 disk
todo /dev/nvme7n1 disk
todo /dev/nvme7n1p1 part
todo /dev/nvme7n1p2 part
todo /dev/sda disk
todo /dev/nvme3n1 disk
todo /dev/nvme5n1 disk
todo /dev/nvme4n1 disk
todo pv:/dev/nvme2n1 lvmdev
todo /dev/vg_app lvmgrp
todo /dev/mapper/vg_app-lg_app lvmvol
todo fs:/app fs
todo fs:/ fs
todo fs:/app/elasticsearch fs
todo fs:/var/lib/rancher fs
todo fs:/var/log fs
todo fs:/app/data/longhorn fs
</code></pre>
<p>We noticed that disks are mentioned twice, and therefore, function
<code>get_component_type</code></p>
<pre><code>get_component_type() {
    grep -E "^[^ ]+ $1 " $LAYOUT_TODO | cut -d " " -f 3
}
</code></pre>
<p>returns twice "disk"</p>
<pre><code>++++ get_component_type /dev/nvme4n1
++++ grep -E '^[^ ]+ /dev/nvme4n1 ' /home/gdhaese1/projects/rear/var/lib/rear/layout/disktodo.conf
++++ cut -d ' ' -f 3
+++ type='disk
disk'
+++ [[ disk
disk != \d\i\s\k ]]
+++ continue
</code></pre>
<p>To fix this: we could append <code>uniq</code> to the fucntion:
<code>grep -E "^[^ ]+ $1 " $LAYOUT_TODO | cut -d " " -f 3 | uniq</code></p>
<h4 id="jsmeix_commented_at_2025-02-14_1228"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2659212175">2025-02-14 12:28</a>:<a class="headerlink" href="#jsmeix_commented_at_2025-02-14_1228" title="Permanent link">&para;</a></h4>
<p>Plain 'uniq' needs sorted input e.g.</p>
<pre><code># echo -e 'one\ntwo\nthree\nthree\ntwo\none'
one
two
three
three
two
one

# echo -e 'one\ntwo\nthree\nthree\ntwo\none' | uniq
one
two
three
two
one

# echo -e 'one\ntwo\nthree\nthree\ntwo\none' | sort | uniq
one
three
two
</code></pre>
<p>But sorting disktodo.conf may break how that code is meant to work<br />
when the entries in disktodo.conf need to be in the given order.</p>
<p>It seems the entries in disktodo.conf need to be in the given order<br />
i.e. in the order how things must be recreated (first partitions<br />
on disks, then higher level volumes like LVM, finally filesystems).</p>
<p>To help with such issues I made the function 'unique_unsorted'<br />
see usr/share/rear/lib/global-functions.sh<br />
<a href="https://github.com/rear/rear/blob/rear-2.9/usr/share/rear/lib/global-functions.sh#L37">https://github.com/rear/rear/blob/rear-2.9/usr/share/rear/lib/global-functions.sh#L37</a></p>
<h4 id="gdha_commented_at_2025-02-14_1244"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2659246149">2025-02-14 12:44</a>:<a class="headerlink" href="#gdha_commented_at_2025-02-14_1244" title="Permanent link">&para;</a></h4>
<p>@jsmeix Thank you for a golden tip, I removed the <code>uniq</code> from the
function <code>get_component_type</code><br />
and created a small script to do what you proposed:</p>
<pre><code>#-&gt; cat save/default/305_uniq_disktodo.sh
# make LAYOUT_TODO file uniq but not changing the order in any way
unique_unsorted  $LAYOUT_TODO &gt;${LAYOUT_TODO}.new
mv -f ${LAYOUT_TODO}.new $LAYOUT_TODO
</code></pre>
<p>By doing this the problem is not yet fixed, but at least the input files
are better without duplicates.</p>
<h4 id="jsmeix_commented_at_2025-02-14_1250"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2659261782">2025-02-14 12:50</a>:<a class="headerlink" href="#jsmeix_commented_at_2025-02-14_1250" title="Permanent link">&para;</a></h4>
<p>Hmmm...</p>
<p>I think when</p>
<pre><code># Get the type of a layout component
get_component_type() {
    grep -E "^[^ ]+ $1 " $LAYOUT_TODO | cut -d " " -f 3
}
</code></pre>
<p>results more than one word (i.e. more than one line)<br />
and those results are not all identical,<br />
then it is a BugError in ReaR because then<br />
one same layout component is stored with several<br />
different component types in disktodo.conf</p>
<p>On the other hand when all results are identical<br />
things are probably OK because then one same layout component<br />
is stored one or more times with one same component type<br />
in disktodo.conf</p>
<p>So plain 'uniq' could be the exact right thing here<br />
to distinguish the OK case from the BugError case<br />
for example something like (untested code proposal):</p>
<pre><code># Get the type of a layout component:
# It is OK when one same layout component is stored in disktodo.conf
# several times with one same component type (then 'uniq' results one value)
# but it is a Bug in ReaR when one same layout component is stored
# in disktodo.conf several times with different component types
# (then 'uniq' results more than one value).
get_component_type() {
    local component="$1"
    local component_types=()
    component_types=( $( grep -E "^[^ ]+ $component " $LAYOUT_TODO | cut -d " " -f 3 | uniq ) )
    test ${#component_types[@]} -lt 1 &amp;&amp; return 1
    test ${#component_types[@]} -gt 1 &amp;&amp; BugError "Layout component '$component' has more than one type in $LAYOUT_TODO"
    echo "${component_types[0]}"
}
</code></pre>
<h4 id="gdha_commented_at_2025-02-14_1255"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2659273625">2025-02-14 12:55</a>:<a class="headerlink" href="#gdha_commented_at_2025-02-14_1255" title="Permanent link">&para;</a></h4>
<p>It does work with the new script <code>save/default/305_uniq_disktodo.sh</code> (I
had an exit to test so I couldn't tell):</p>
<pre><code>#-&gt; grep -v \# /home/gdhaese1/projects/rear/var/lib/rear/layout/disklayout.conf
disk /dev/nvme0n1 32212254720 gpt
part /dev/nvme0n1 1048576 1048576 rear-noname bios_grub /dev/nvme0n1p1
part /dev/nvme0n1 32210140672 2097152 rear-noname none /dev/nvme0n1p2
disk /dev/nvme1n1 590558003200 loop
disk /dev/nvme2n1 21474836480 unknown
disk /dev/nvme4n1 171798691840 loop
disk /dev/nvme5n1 21474836480 loop
disk /dev/nvme6n1 214748364800 loop
disk /dev/nvme5n1 21474836480 loop
disk /dev/nvme4n1 171798691840 loop
lvmdev /dev/vg_app /dev/nvme2n1 5jSbmk-ooLT-rpTk-A3nB-cum8-FF1v-fmCRG6 21470642176
lvmgrp /dev/vg_app 4096 5119 20967424
lvmvol /dev/vg_app lg_app 21470642176b linear
fs /dev/mapper/vg_app-lg_app /app xfs uuid=beb48049-5b75-46c2-8e75-a6f8d3881d0e label=lg_app  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme0n1p2 / xfs uuid=c9aa25ee-e65c-4818-9b2f-fa411d89f585 label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme1n1 /app/elasticsearch xfs uuid=6281fd1f-d107-427a-a22c-2f575fb7a58c label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme4n1 /var/lib/rancher xfs uuid=89142993-8500-42fe-8458-e8ccda4a7113 label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme5n1 /var/log xfs uuid=0f12a909-7cbf-487d-8bcb-663eeaabf3c2 label=  options=rw,nosuid,nodev,noexec,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
fs /dev/nvme6n1 /app/data/longhorn xfs uuid=5a2a74b7-9c6f-4af6-bbc6-9e2ecd52a314 label=  options=rw,relatime,attr2,inode64,logbufs=8,logbsize=32k,noquota
</code></pre>
<p>However, your proposal in function <code>get_component_type</code> looks promising
too. I can test it...with and with the new script!<br />
The updates in function <code>get_component_type</code> work both ways = excellent
news.<br />
However, without my new script <code>save/default/305_uniq_disktodo.sh</code> the
duplicate entries stay, therefore, I would propose to keep both updates.</p>
<h4 id="jsmeix_commented_at_2025-02-14_1331"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/3400#issuecomment-2659348725">2025-02-14 13:31</a>:<a class="headerlink" href="#jsmeix_commented_at_2025-02-14_1331" title="Permanent link">&para;</a></h4>
<p>The whole layout related code is often very hard for me<br />
to understand it, in particular I often fail to see<br />
how all those layout related code parts work together.<br />
I basically fail to see how all the layout related<br />
code parts are meant / intended to work together.<br />
So usually I don't dare to touch layout related code<br />
because I fail to imagine / foresee what will actually<br />
happen when I change something.</p>
<p>I assume this is because the layout related code is rather<br />
old code from times when 'lsblk' was not yet available<br />
or not available with nowadays functionality.<br />
I mean:<br />
I think nowadays 'lsblk' could be sufficient to handle<br />
all needed layout components and their dependencies<br />
i.e. parent(s) &lt;-&gt; child(ren) dependencies, e.g.<br />
one disk with several partitions (parent &lt;-&gt; children)<br />
versus two disks for one RAID1 (parents &lt;-&gt; child).</p>
<p>In the end what I like to tell is:<br />
For layout related code changes I fail to make my own<br />
proper opinion if some change looks OK to me or not<br />
because I don't have sufficient overview in this area :-(</p>
<hr />
<p>[Export of Github issue for
<a href="https://github.com/rear/rear">rear/rear</a>.]</p>
              
            </div>
          </div>

<footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
    <p>Copyright 2025 - CC0 1.0 Universal<br />Give <a href="https://github.com/rear/rear-user-guide/issues/new?title=issues/2025-02-13.3400.issue.open.html">feedback</a> on this page.</p>
    
  </div>
</footer>

        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/rear/rear-user-guide" class="fa fa-code-fork" style="color: #fcfcfc"> rear/rear-user-guide</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
