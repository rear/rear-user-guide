<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <meta property="og:title" content="Relax-and-Recover (ReaR) User Guide Documentation"/>
    <meta property="og:description" content="This is an umbrella documentation project for all Relax-and-Recover (ReaR) kind of documentation ans starting with a good User Guide."/>
    <meta property="og:locale" content="en_US"/>
    <meta property="og:url" content="https://relax-and-recover.org/rear-user-guide/"/>
    <meta property="og:type" content="website"/>
    <meta property="og:image" content="https://relax-and-recover.org/rear-user-guide/img/rear_logo_50.png"/>
    <meta property="og:image:width" content="50"/>
    <meta property="og:image:height" content="50"/>
    
    <title>#2917 Issue closed: EL 9 after "rear recover" to different HW reboot hangs at "A Start Job is running for /dev/mapper/vg01-..." - Relax-and-Recover (ReaR) User Guide Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../css/rear.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "#2917 Issue closed: EL 9 after \"rear recover\" to different HW reboot hangs at \"A Start Job is running for /dev/mapper/vg01-...\"";
        var mkdocs_page_input_path = "issues/2023-01-30.2917.issue.closed.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/rust.min.js"></script>
      <script>hljs.highlightAll();</script> 
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', "366986045", "auto");
        ga('send', 'pageview');
      </script>
    
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../index.html" class="icon icon-home"> Relax-and-Recover (ReaR) User Guide Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">WELCOME</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../welcome/index.html">Get started!</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">BASICS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/introduction.html">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/history.html">Bit of History</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/getting-started.html">Getting started with ReaR</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/configuration.html">Basic configuration</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/backup_netfs.html">Example of BACKUP=NETFS</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">SCENARIOS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/index.html">Scenarios Overview</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">DEVELOPMENT</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../development/github-pr.html">Make a pull request with GitHub</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/index.html">Release Notes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear28.html">Release Notes ReaR 2.8</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear27.html">Release Notes ReaR 2.7</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear26.html">Release Notes ReaR 2.6</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/knownproblems.html">Known Problems and Workarounds</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">ISSUES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="index.html">Issues History</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">LEGAL</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/contributing/index.html">Contributing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/license/index.html">License</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html" class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">#2917 Issue closed: EL 9 after "rear recover" to different HW reboot hangs at "A Start Job is running for /dev/mapper/vg01-..."</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="2917_issue_closed_el_9_after_rear_recover_to_different_hw_reboot_hangs_at_a_start_job_is_running_for_devmappervg01-"><a href="https://github.com/rear/rear/issues/2917">#2917 Issue</a> <code>closed</code>: EL 9 after "rear recover" to different HW reboot hangs at "A Start Job is running for /dev/mapper/vg01-..."<a class="headerlink" href="#2917_issue_closed_el_9_after_rear_recover_to_different_hw_reboot_hangs_at_a_start_job_is_running_for_devmappervg01-" title="Permanent link">&para;</a></h1>
<p><strong>Labels</strong>: <code>bug</code>, <code>fixed / solved / done</code></p>
<h4 id="steinefels_opened_issue_at_2023-01-30_1150"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> opened issue at <a href="https://github.com/rear/rear/issues/2917">2023-01-30 11:50</a>:<a class="headerlink" href="#steinefels_opened_issue_at_2023-01-30_1150" title="Permanent link">&para;</a></h4>
<p>Hello there,</p>
<p>I'm trying to do a test bare-metal-recovery of an HP DL360G9 with Oracle
Linux 9.0 and LVM 2.03.16 installed. The ReaR version is 2.7 ( tried 2.6
as well). All goes well during the 'mkbackup' phase with only a few
settings in local.conf:</p>
<p>OUTPUT=ISO<br />
BACKUP=NETFS<br />
OUTPUT_URL=null<br />
BACKUP_URL=iso:///backup<br />
ISO_DIR=/mnt/usb/rescue_system<br />
USER_INPUT_BACKUP_URL_ISO_PROCEED_MKRESCUE=y<br />
BACKUP_PROG_EXCLUDE=("${BACKUP_PROG_EXCLUDE[@]}" '/media'
'/var/tmp' '/var/crash' '/mnt')<br />
ISO_FILE_SIZE_LIMIT=8589934592<br />
USE_SERIAL_CONSOLE='no'</p>
<p>The generated iso file ist booting flawlessly on new and identicaly
equipped HP DL360G9 hardware to this point:<br />
<img alt="image" src="https://user-images.githubusercontent.com/123949246/215466085-88191b44-09b4-4332-a1a7-77dc87ea8736.png" /><br />
a clouple of 'red' follow-up errors are thrown and the recovery image
gets stuck and won't boot up to a login-prompt.</p>
<p>Is this a bug? I tried to install the image to different hardware as
well but the behavíour is still the same. Both machines got a HP 'Smart
Array P440ar Controller' and a configured RAID1 logical drive. I
switched the target controller to 'HBA' mode prior to recovery but
without visible effect.</p>
<p>Regards, HG</p>
<h4 id="jsmeix_commented_at_2023-01-31_0908"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1410002029">2023-01-31 09:08</a>:<a class="headerlink" href="#jsmeix_commented_at_2023-01-31_0908" title="Permanent link">&para;</a></h4>
<p>I assume this issue is because of special server hardware.<br />
In particular bare-metal-recovery with specific server hardware<br />
relatively often has such kind of hardware specific issues.<br />
I cannot actually help in this specific case<br />
because I am neither an Oracle Linux user<br />
nor do I have experience with HPE ProLiant servers<br />
and/or HP Smart Array Controllers.</p>
<p>Only a blind guess because your ISO is huge<br />
(with up to 8GiB big files):<br />
Can you boot when you make a small ISO via</p>
<pre><code># rear mkrescue
</code></pre>
<p>that contains only the ReaR recovery system but no backup.tar.gz<br />
only as a test if the ISO size or the big backup causes trouble.<br />
I assume it will also fail in the same way but in the past<br />
we have had weird booting issues when something was "too big"<br />
(without a boot error message that something was "too big").</p>
<p>I assume the real cause is that something is missing in the<br />
ReaR recovery system to properly put the storage into operation.<br />
Perhaps some specific kernel modules for the storage must be<br />
specified to be loaded when they do not load automatically,<br />
see MODULES_LOAD in usr/share/rear/conf/default.conf<br />
online at<br />
<a href="https://github.com/rear/rear/blob/rear-2.7/usr/share/rear/conf/default.conf#L1598">https://github.com/rear/rear/blob/rear-2.7/usr/share/rear/conf/default.conf#L1598</a><br />
and for an example see<br />
<a href="https://github.com/rear/rear/blob/rear-2.7/usr/share/rear/conf/examples/SLE12-SP2-btrfs-example.conf#L38">https://github.com/rear/rear/blob/rear-2.7/usr/share/rear/conf/examples/SLE12-SP2-btrfs-example.conf#L38</a><br />
which also mentiones<br />
<a href="https://github.com/rear/rear/issues/626">https://github.com/rear/rear/issues/626</a></p>
<h4 id="steinefels_commented_at_2023-01-31_1405"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1410414185">2023-01-31 14:05</a>:<a class="headerlink" href="#steinefels_commented_at_2023-01-31_1405" title="Permanent link">&para;</a></h4>
<p>Thanks for the investigation. The actual size of the boot image under
test ist 4.2 G. The first boot with this image on an empty target system
goes straight to the ReaR rescue prompt (after mapping the four NICs of
the source system).</p>
<p>The boot parameters were</p>
<p><code>kernel initrd=initrd.cgz root/dev/ram0 vga=normal rw selinux=0 console=ttyS0,9600 console=tty0</code></p>
<pre><code>Relax-and-Recover 2.7 / 2022-07-13
Relax-and-recover comes with ABSOLUTELY NO WARRANTY; for details see
the GNU General Public License at http://www.gnu.org/licenses/gpl.html
Host myhost.mydomain.com using Backup NETFS and Output ISO
Build date: Mon, 30 Jan 2023 10:30:02 +00:00

Oracle Linux Server 9.1
Kernel 5.15.0-6.80.3.1.el9uek.x86_64 on an x86_64

SSH fingerprint:

myhost login: root

Welcome to Relax-and Recover. Run "rear recover" to restore your system !

RESCUE myhost:~#
</code></pre>
<p>After</p>
<p><code># rear -v recover</code></p>
<p>at the rescue prompt and doing and confirming the HD/LVM mappings the
system is restored.<br />
The recovery process seems to execute smooth, everything is restored to
the mounted /mnt/local/....:</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/123949246/215775365-10744f4a-dae4-4715-83c4-a5b051f1170d.png" /><br />
The restore message log file in /var/log/rear/ looks clean.</p>
<p>After resetting and POST, the machine boots into grub2s boot menue&gt;</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/123949246/215778097-461ea0c6-bf33-43a5-970d-df3139426220.png" /></p>
<p>The problem finally pops up when trying to reboot the recovered system
5.15.0-6 (or any other):<br />
<img alt="image" src="https://user-images.githubusercontent.com/123949246/215778628-b9c000de-f974-4635-b098-e22c4bf92e01.png" /></p>
<p>and after a couple of minutes</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/123949246/215779061-90be2ca2-818f-499b-96bc-c71c32426125.png" /></p>
<p>and then the system reboots again. And of course fails again to start
the storage subsystem, even when started in rescue-mode.</p>
<p>after annother reboot the picture slightly changes:<br />
<img alt="image" src="https://user-images.githubusercontent.com/123949246/215780472-900dfc12-de65-4baf-91d8-6311dc41fb35.png" /></p>
<p>and<br />
<img alt="image" src="https://user-images.githubusercontent.com/123949246/215780631-d2f7aaa3-38d1-4bc7-a13c-c74cef367c89.png" /></p>
<h4 id="jsmeix_commented_at_2023-01-31_1530"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1410588668">2023-01-31 15:30</a>:<a class="headerlink" href="#jsmeix_commented_at_2023-01-31_1530" title="Permanent link">&para;</a></h4>
<p>Now it looks like an issue with SELinux<br />
and/or the Oracle Linux security audit system<br />
because the from scratch recreated system is<br />
somewhat different compared to the original system<br />
(at least the hardware is not exactly the same).</p>
<p>Again I cannot actually help in this area<br />
because I have no experience with SELinux<br />
and/or the Oracle or RHEL security audit system.</p>
<p>In this special case I would recommend to also<br />
get in contact with Oracle and ask them what is needed<br />
regarding SELinux and the Oracle security audit system<br />
when an Oracle Linux system is recreated from scratch<br />
on replacement hardware.</p>
<p>Additionally because of the message</p>
<pre><code>[ TIME ] Timed out waiting for device /dev/mapper/vg01-var.
</code></pre>
<p>verify that the recreated storage layout<br />
matches the storage layout on the original system.</p>
<p>To do that run a command like</p>
<pre><code># lsblk -ipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN
</code></pre>
<p>and if needed also to get byte precise size values like</p>
<pre><code># lsblk -bipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN
</code></pre>
<p>on the original system and also<br />
after "rear recover" finished (before reboot)<br />
in the still running ReaR recovery system.</p>
<p>In the latter case the mountpoints will be below '/mnt/local'<br />
because that is where the recreated target system filesystems<br />
are mounted within the running ReaR recovery system.</p>
<p>Compare both in particular whether or not<br />
the structure of the storage objects is the same.</p>
<p>The output of such an 'lsblk' command on the original system<br />
gets stored during "rear mkrecue/mkbackup" as comment in<br />
/var/lib/rear/layout/disklayout.conf<br />
but not with size values in bytes (i.e. it is without <code>-b</code>).</p>
<h4 id="steinefels_commented_at_2023-02-06_1226"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1419001593">2023-02-06 12:26</a>:<a class="headerlink" href="#steinefels_commented_at_2023-02-06_1226" title="Permanent link">&para;</a></h4>
<p>I just made the recommended comparison of disk layouts. The source
system shows:</p>
<pre><code>[root@gd-radius2 ~]# lsblk -bipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN
NAME                      KNAME     PKNAME    TRAN TYPE FSTYPE      LABEL          SIZE MOUNTPOINT UUID                                   WWN
/dev/sda                  /dev/sda            sas  disk                   1000171331584                                                   0x600508b1001cfc5fa0c4057066a338c2
|-/dev/sda1               /dev/sda1 /dev/sda       part xfs                  1073741824 /boot      6a5d4c28-53ed-49da-9dd7-8482bbd8d42f   0x600508b1001cfc5fa0c4057066a338c2
`-/dev/sda2               /dev/sda2 /dev/sda       part LVM2_member         97718894592            UGfXyF-ET0V-qs1q-pZn2-v8yW-vDKt-gopoMj 0x600508b1001cfc5fa0c4057066a338c2
  |-/dev/mapper/vg01-root /dev/dm-0 /dev/sda2      lvm  xfs                 10737418240 /          e0903104-278f-45e5-96b5-4a57cb5a2e2e
  |-/dev/mapper/vg01-swap /dev/dm-1 /dev/sda2      lvm  swap                17179869184 [SWAP]     782f5d5a-d25c-4004-baf2-85b64114b805
  |-/dev/mapper/vg01-usr  /dev/dm-2 /dev/sda2      lvm  xfs                 10737418240 /usr       ce9c35e5-f99c-4a90-ac81-dd13662f1842
  |-/dev/mapper/vg01-opt  /dev/dm-3 /dev/sda2      lvm  xfs                 16106127360 /opt       01ba316f-a095-47e3-8291-4b65590372f7
  |-/dev/mapper/vg01-home /dev/dm-4 /dev/sda2      lvm  xfs                 21474836480 /home      c1ce5c9e-6e0a-4e63-9e39-c49811881df7
  |-/dev/mapper/vg01-tmp  /dev/dm-5 /dev/sda2      lvm  xfs                 10737418240 /tmp       62e0abf1-5a8d-4a1e-a55e-df202b3672d1
  `-/dev/mapper/vg01-var  /dev/dm-6 /dev/sda2      lvm  xfs                 10737418240 /var       c6ce48bc-aa75-40b1-8347-4886b6a56d73
/dev/sdb                  /dev/sdb            usb  disk                   4000787027968
|-/dev/sdb1               /dev/sdb1 /dev/sdb       part                       134217728
`-/dev/sdb2               /dev/sdb2 /dev/sdb       part xfs               4000650887168            914a753a-e3af-4a92-9b0c-577b99a53b29
</code></pre>
<p>and the target system shows after doing 'rear recover' on this box but
prior to rebooting the restored image:</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/123949246/216966289-ddfc1f69-032d-4b6f-9cec-584bba951e49.png" /></p>
<h4 id="jsmeix_commented_at_2023-02-06_1503"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1419225147">2023-02-06 15:03</a>:<a class="headerlink" href="#jsmeix_commented_at_2023-02-06_1503" title="Permanent link">&para;</a></h4>
<p>@Steinefels<br />
the values of the 'lsblk' columns in your screenshot<br />
look truncated - e.g. 'LVM2_m' instead of 'LVM2_member'<br />
so the MOUNTPOINT value '/mnt/local' of the filesystems<br />
that are on LVM /dev/mapper/vg01-* could be truncated.</p>
<p>Could you try to get the lsblk output<br />
in the running ReaR recovery system<br />
with non-truncated values on non-wrapped lines?</p>
<p>E.g. login via 'ssh' into the running ReaR recovery system<br />
and run the 'lsblk' command in a sufficiently wide terminal<br />
or have the output in a file like</p>
<pre><code>lsblk -bipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN &gt;/tmp/lsblk.out
</code></pre>
<p>to get non-truncated values on non-wrapped lines<br />
or try to use the '-w' option because "man lsblk" reads<br />
(on my openSUSE Leap 15.4 system with lsblk from util-linux 2.37.2):</p>
<pre><code>-w, --width number
Specifies output width as a number of characters.
The default is the number of the terminal columns,
and if not executed on a terminal, then output width
is not restricted at all by default.
This option also forces lsblk to assume that terminal
control characters and unsafe characters are not allowed.
</code></pre>
<p>FYI:<br />
Related to that you may have a look at the part</p>
<pre><code>You can run "rear recover" from remote via ssh as follows
...
</code></pre>
<p>at the end of the section</p>
<pre><code>First steps with Relax-and-Recover
</code></pre>
<p>in<br />
<a href="https://en.opensuse.org/SDB:Disaster_Recovery">https://en.opensuse.org/SDB:Disaster_Recovery</a></p>
<p>Personally I always run "rear recover" from remote via ssh<br />
because this way I can run "rear recover" in a terminal window<br />
within my familiar working environment on my usual workstation<br />
instead of the unfamiliar ReaR recovery system environment.</p>
<h4 id="jsmeix_commented_at_2023-02-07_1512"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1420939273">2023-02-07 15:12</a>:<a class="headerlink" href="#jsmeix_commented_at_2023-02-07_1512" title="Permanent link">&para;</a></h4>
<p>FYI for comparison<br />
how it works and looks for me with LVM on a KVM/QEMU test VM<br />
with plain SLES 15 SP4 (i.e. without AppArmor or SELinux):</p>
<p>On my original VM:</p>
<pre><code># lsblk -bipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN
NAME                        KNAME     PKNAME    TRAN   TYPE FSTYPE      LABEL        SIZE MOUNTPOINT UUID                                   WWN
/dev/sr0                    /dev/sr0            sata   rom                     1073741312                                                   
/dev/vda                    /dev/vda                   disk                   12884901888                                                   
|-/dev/vda1                 /dev/vda1 /dev/vda         part                       8388608                                                   
`-/dev/vda2                 /dev/vda2 /dev/vda         part LVM2_member       12875447808            KIixRJ-1CUu-qTMS-ttW8-v0eq-2pO8-tVnXH4 
  |-/dev/mapper/system-swap /dev/dm-0 /dev/vda2        lvm  swap               2147483648 [SWAP]     a871f72e-13d7-4d5e-a136-ee461a141120   
  |-/dev/mapper/system-root /dev/dm-1 /dev/vda2        lvm  ext4               4504682496 /          8a699d02-b3e0-412c-a153-9b1c1210d012   
  `-/dev/mapper/system-home /dev/dm-2 /dev/vda2        lvm  xfs                6220152832 /home      2cb44622-9c97-437e-8e09-cdf195e9579a
</code></pre>
<p>On my replacement VM with virtual disk size of also exactly 12 GiB<br />
inside the ReaR recovery system after "rear recover" finished:</p>
<pre><code>RESCUE localhost:~ # lsblk -bipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN
NAME                        KNAME     PKNAME    TRAN   TYPE FSTYPE      LABEL           SIZE MOUNTPOINT      UUID                                   WWN
/dev/sr0                    /dev/sr0            sata   rom  iso9660     REAR-ISO    77733888                 2023-02-07-15-48-44-43                 
/dev/vda                    /dev/vda                   disk                      12884901888                                                        
|-/dev/vda1                 /dev/vda1 /dev/vda         part                          8388608                                                        
`-/dev/vda2                 /dev/vda2 /dev/vda         part LVM2_member          12875447808                 KIixRJ-1CUu-qTMS-ttW8-v0eq-2pO8-tVnXH4 
  |-/dev/mapper/system-swap /dev/dm-0 /dev/vda2        lvm  swap                  2147483648                 a871f72e-13d7-4d5e-a136-ee461a141120   
  |-/dev/mapper/system-home /dev/dm-1 /dev/vda2        lvm  xfs                   6220152832 /mnt/local/home 2cb44622-9c97-437e-8e09-cdf195e9579a   
  `-/dev/mapper/system-root /dev/dm-2 /dev/vda2        lvm  ext4                  4504682496 /mnt/local      8a699d02-b3e0-412c-a153-9b1c1210d012
</code></pre>
<h4 id="steinefels_commented_at_2023-02-08_1737"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1422997017">2023-02-08 17:37</a>:<a class="headerlink" href="#steinefels_commented_at_2023-02-08_1737" title="Permanent link">&para;</a></h4>
<p>Thanks for the enduring support ;-) I finally made it to the ssh-prompt:</p>
<p>First and again the structure of the source system:</p>
<pre><code>[root@myhost ~]# lsblk -bipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN
NAME                      KNAME     PKNAME    TRAN TYPE FSTYPE      LABEL          SIZE MOUNTPOINT UUID                                   WWN
/dev/sda                  /dev/sda            sas  disk                   1000171331584                                                   0x600508b1001cfc5fa0c4057066a338c2
|-/dev/sda1               /dev/sda1 /dev/sda       part xfs                  1073741824 /boot      6a5d4c28-53ed-49da-9dd7-8482bbd8d42f   0x600508b1001cfc5fa0c4057066a338c2
`-/dev/sda2               /dev/sda2 /dev/sda       part LVM2_member         97718894592            UGfXyF-ET0V-qs1q-pZn2-v8yW-vDKt-gopoMj 0x600508b1001cfc5fa0c4057066a338c2
  |-/dev/mapper/vg01-root /dev/dm-0 /dev/sda2      lvm  xfs                 10737418240 /          e0903104-278f-45e5-96b5-4a57cb5a2e2e
  |-/dev/mapper/vg01-swap /dev/dm-1 /dev/sda2      lvm  swap                17179869184 [SWAP]     782f5d5a-d25c-4004-baf2-85b64114b805
  |-/dev/mapper/vg01-usr  /dev/dm-2 /dev/sda2      lvm  xfs                 10737418240 /usr       ce9c35e5-f99c-4a90-ac81-dd13662f1842
  |-/dev/mapper/vg01-opt  /dev/dm-3 /dev/sda2      lvm  xfs                 16106127360 /opt       01ba316f-a095-47e3-8291-4b65590372f7
  |-/dev/mapper/vg01-home /dev/dm-4 /dev/sda2      lvm  xfs                 21474836480 /home      c1ce5c9e-6e0a-4e63-9e39-c49811881df7
  |-/dev/mapper/vg01-tmp  /dev/dm-5 /dev/sda2      lvm  xfs                 10737418240 /tmp       62e0abf1-5a8d-4a1e-a55e-df202b3672d1
  `-/dev/mapper/vg01-var  /dev/dm-6 /dev/sda2      lvm  xfs                 10737418240 /var       c6ce48bc-aa75-40b1-8347-4886b6a56d73
/dev/sdb                  /dev/sdb            usb  disk                   4000787027968
|-/dev/sdb1               /dev/sdb1 /dev/sdb       part                       134217728
`-/dev/sdb2               /dev/sdb2 /dev/sdb       part xfs               4000650887168            914a753a-e3af-4a92-9b0c-577b99a53b29
[root@myhost ~]#
</code></pre>
<p>and here the matching output from the rescue shell on the target system:</p>
<pre><code>RESCUE myhost:~ #  lsblk -bipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,LABEL,SIZE,MOUNTPOINT,UUID,WWN
NAME                      KNAME     PKNAME    TRAN TYPE FSTYPE      LABEL             SIZE MOUNTPOINT      UUID                                   WWN
/dev/sda                  /dev/sda            sas  disk                      1000171331584                                                        0x600508b1001c4611de46533678cdf56c
|-/dev/sda1               /dev/sda1 /dev/sda       part xfs                     1073741824 /mnt/local/boot 6a5d4c28-53ed-49da-9dd7-8482bbd8d42f   0x600508b1001c4611de46533678cdf56c
`-/dev/sda2               /dev/sda2 /dev/sda       part LVM2_member            97718894592                 UGfXyF-ET0V-qs1q-pZn2-v8yW-vDKt-gopoMj 0x600508b1001c4611de46533678cdf56c
  |-/dev/mapper/vg01-usr  /dev/dm-0 /dev/sda2      lvm  xfs                    10737418240 /mnt/local/usr  ce9c35e5-f99c-4a90-ac81-dd13662f1842
  |-/dev/mapper/vg01-opt  /dev/dm-1 /dev/sda2      lvm  xfs                    16106127360 /mnt/local/opt  01ba316f-a095-47e3-8291-4b65590372f7
  |-/dev/mapper/vg01-root /dev/dm-2 /dev/sda2      lvm  xfs                    10737418240 /mnt/local      e0903104-278f-45e5-96b5-4a57cb5a2e2e
  |-/dev/mapper/vg01-home /dev/dm-3 /dev/sda2      lvm  xfs                    21474836480 /mnt/local/home c1ce5c9e-6e0a-4e63-9e39-c49811881df7
  |-/dev/mapper/vg01-swap /dev/dm-4 /dev/sda2      lvm  swap                   17179869184                 782f5d5a-d25c-4004-baf2-85b64114b805
  |-/dev/mapper/vg01-tmp  /dev/dm-5 /dev/sda2      lvm  xfs                    10737418240 /mnt/local/tmp  62e0abf1-5a8d-4a1e-a55e-df202b3672d1
  `-/dev/mapper/vg01-var  /dev/dm-6 /dev/sda2      lvm  xfs                    10737418240 /mnt/local/var  c6ce48bc-aa75-40b1-8347-4886b6a56d73
/dev/sr0                  /dev/sr0            usb  rom  iso9660     REAR-ISO    4358033408                 2023-02-08-15-19-57-00
RESCUE myhost:~ #
</code></pre>
<h4 id="steinefels_commented_at_2023-02-08_1738"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1422998852">2023-02-08 17:38</a>:<a class="headerlink" href="#steinefels_commented_at_2023-02-08_1738" title="Permanent link">&para;</a></h4>
<p>false click to 'closure', sorry ;-)</p>
<h4 id="jsmeix_commented_at_2023-02-09_1033"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1423967071">2023-02-09 10:33</a>:<a class="headerlink" href="#jsmeix_commented_at_2023-02-09_1033" title="Permanent link">&para;</a></h4>
<p>I don't see a relevant difference<br />
so from my current point of view<br />
your disk layout was perfectly well recreated.<br />
The only things that differ are expected:<br />
The /dev/dm-N kernel device node numbers and<br />
the WWN of the original and replacement /dev/sda disks.</p>
<p>@Steinefels<br />
because you can access the ReaR recovery system from remote via ssh<br />
you can now get a full debug log file of a "rear -D recover" run<br />
and other relevant files out of the ReaR recovery system<br />
which we need for further analysis what might have went wrong<br />
in your specific case during "rear recover".<br />
For what files we need and how to do that see the section<br />
"Debugging issues with Relax-and-Recover" in<br />
<a href="https://en.opensuse.org/SDB:Disaster_Recovery">https://en.opensuse.org/SDB:Disaster_Recovery</a></p>
<p>To avoid false expectations:<br />
There is no guarantee that we can see the root cause of your issue<br />
from those files of your recovery system but we will have a look.</p>
<p>Caution with possible secrets in a full debug log file:<br />
When 'rear' is run via '-D' in debugscript mode<br />
it logs executed commands via the bash command 'set -x'<br />
that print commands and their arguments as they are executed<br />
so in particular when arguments contain secret values<br />
(e.g. something like a password or whatever else)<br />
such secret values may appear in the log file.<br />
Also secrets may be stored in some other files<br />
like /var/lib/rear/layout/disklayout.conf<br />
or /var/lib/rear/layout/diskrestore.sh<br />
cf. <code>[password=&lt;password&gt;]</code> in the section<br />
"Disk layout file syntax" in<br />
doc/user-guide/06-layout-configuration.adoc<br />
online at<br />
<a href="https://github.com/rear/rear/blob/rear-2.7/doc/user-guide/06-layout-configuration.adoc">https://github.com/rear/rear/blob/rear-2.7/doc/user-guide/06-layout-configuration.adoc</a><br />
So before you attach your full debug log file and other files<br />
here (GitHub is a public accessible place) inspect your files<br />
and verify that they do not accidentally contain secrets.</p>
<h4 id="steinefels_commented_at_2023-02-09_1654"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1424507329">2023-02-09 16:54</a>:<a class="headerlink" href="#steinefels_commented_at_2023-02-09_1654" title="Permanent link">&para;</a></h4>
<p>Just made the recommended trial with 'rear -d -D mkbackup' on the source
side and 'rear -d -D recover' on the target machine, for your further
investigations Please find the attached logs and the
'/etc/rear/local.conf' related to this test. If you'd like to see
anything else from the source or target system please let me know...<br />
<a href="https://github.com/rear/rear/files/10699581/rear-myhost-recovery.zip">rear-myhost-recovery.zip</a></p>
<h4 id="jsmeix_commented_at_2023-02-10_1357"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1425846830">2023-02-10 13:57</a>:<a class="headerlink" href="#jsmeix_commented_at_2023-02-10_1357" title="Permanent link">&para;</a></h4>
<p>@Steinefels<br />
I had a first look at your rear-myhost-target.log</p>
<p>As far as I see the diskrestore.sh script</p>
<pre><code>+ source /usr/share/rear/layout/recreate/default/200_run_layout_code.sh
...
++ source /var/lib/rear/layout/diskrestore.sh
...
2023-02-09 15:13:36.340941206 Start system layout restoration.
...
2023-02-09 15:14:04.800434951 Disk layout created.
</code></pre>
<p>did run without issues which matches that I didn't see<br />
a relevant difference in the 'lsblk' outputs so again<br />
it seems your disk layout was perfectly well recreated.</p>
<p>I.e. curently I have no idea what could cause the</p>
<pre><code>Timed out waiting for device /dev/mapper/vg01-var
</code></pre>
<p>because all filesystems on LVs can be mounted<br />
without issues within the ReaR recovery system</p>
<pre><code>++ source /var/lib/rear/layout/diskrestore.sh
...
+++ mount -o rw,relatime,attr2,inode64,logbufs=8,logbsize=256k,sunit=512,swidth=512,noquota /dev/mapper/vg01-root /mnt/local/
...
+++ mount -o rw,relatime,attr2,inode64,logbufs=8,logbsize=256k,sunit=512,swidth=512,noquota /dev/mapper/vg01-home /mnt/local/home
...
+++ mount -o rw,relatime,attr2,inode64,logbufs=8,logbsize=256k,sunit=512,swidth=512,noquota /dev/mapper/vg01-opt /mnt/local/opt
...
+++ mount -o rw,relatime,attr2,inode64,logbufs=8,logbsize=256k,sunit=512,swidth=512,noquota /dev/mapper/vg01-tmp /mnt/local/tmp
...
+++ mount -o rw,relatime,attr2,inode64,logbufs=8,logbsize=256k,sunit=512,swidth=512,noquota /dev/mapper/vg01-usr /mnt/local/usr
...
+++ mount -o rw,relatime,attr2,inode64,logbufs=8,logbsize=256k,sunit=512,swidth=512,noquota /dev/mapper/vg01-var /mnt/local/var
</code></pre>
<p>After the backup was restored I spotted two possible issues:</p>
<ol>
<li></li>
</ol>
<p>The root login shell may not work sufficiently well:</p>
<pre><code>+ source /usr/share/rear/restore/default/900_create_missing_directories.sh
...
++ chroot /mnt/local /bin/bash --login -c 'chown -v root:root media'
basename: missing operand
...
++ chroot /mnt/local /bin/bash --login -c 'chown -v root:root mnt'
basename: missing operand
...
++ chroot /mnt/local /bin/bash --login -c 'chown -v root:root var/tmp'
basename: missing operand
</code></pre>
<p>I wonder where that 'basename: missing operand'<br />
comes from when the called command is 'chown'.<br />
Because a root login shell is run in 'chroot /mnt/local'<br />
I guess there is some bash profile or other stuff that<br />
calls 'basename' which does not work.<br />
In general a root login shell should work reliably<br />
and fail safe in any case.<br />
In the past we had some weird issues with ReaR when<br />
a root login shell did not work within 'chroot /mnt/local'.</p>
<ol>
<li></li>
</ol>
<p>It failed to create an initrd<br />
for kernel version 5.14.0-70.13.1.0.3.el9_0.x86_64:</p>
<pre><code>+ source /usr/share/rear/finalize/Fedora/i386/550_rebuild_initramfs.sh
...
++ for INITRD_IMG in $( ls $TARGET_FS_ROOT/boot/initramfs-*.img $TARGET_FS_ROOT/boot/initrd-*.img | egrep -v '(kdump|rescue|plymouth)' )
...
++ INITRD=/boot/initramfs-5.14.0-162.12.1.el9_1.x86_64.img
++ LogPrint 'Running dracut...'
...
++ LogPrint 'Updated initrd with new drivers for kernel 5.14.0-162.12.1.el9_1.x86_64.'
...
++ INITRD=/boot/initramfs-5.14.0-162.6.1.el9_1.x86_64.img
++ LogPrint 'Running dracut...'
...
++ LogPrint 'Updated initrd with new drivers for kernel 5.14.0-162.6.1.el9_1.x86_64.'
...
++ INITRD=/boot/initramfs-5.14.0-70.13.1.0.3.el9_0.x86_64.img
++ LogPrint 'Running dracut...'
...
++ LogPrint 'WARNING:
Failed to create initrd for kernel version '\''5.14.0-70.13.1.0.3.el9_0.x86_64'\''.
Check '\''/var/log/rear/rear-myhost.log'\'' to see the error messages in detail
and decide yourself, whether the system will boot or not.
...
++ INITRD=/boot/initramfs-5.15.0-0.30.19.el9uek.x86_64.img
++ LogPrint 'Running dracut...'
...
++ LogPrint 'Updated initrd with new drivers for kernel 5.15.0-0.30.19.el9uek.x86_64.'
...
++ INITRD=/boot/initramfs-5.15.0-5.76.5.1.el9uek.x86_64.img
++ LogPrint 'Running dracut...'
...
++ LogPrint 'Updated initrd with new drivers for kernel 5.15.0-5.76.5.1.el9uek.x86_64.'
...
++ INITRD=/boot/initramfs-5.15.0-6.80.3.1.el9uek.x86_64.img
++ LogPrint 'Running dracut...'
...
++ LogPrint 'Updated initrd with new drivers for kernel 5.15.0-6.80.3.1.el9uek.x86_64.'
</code></pre>
<p>Both issues don't look really serious<br />
but I cannot tell if one could really ignore them.</p>
<p>Again:<br />
I recommend to also get in contact with Oracle<br />
and ask them what is needed regarding SELinux<br />
together with the Oracle security audit system<br />
when an Oracle Linux system is recreated<br />
from scratch on replacement hardware.</p>
<h4 id="github-actions_commented_at_2023-04-12_0218"><img src="https://avatars.githubusercontent.com/in/15368?v=4" width="50"><a href="https://github.com/apps/github-actions">github-actions</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1504445574">2023-04-12 02:18</a>:<a class="headerlink" href="#github-actions_commented_at_2023-04-12_0218" title="Permanent link">&para;</a></h4>
<p>Stale issue message</p>
<h4 id="pcahyna_commented_at_2023-04-25_0928"><img src="https://avatars.githubusercontent.com/u/26300485?u=9105d243bc9f7ade463a3e52e8dd13fa67837158&v=4" width="50"><a href="https://github.com/pcahyna">pcahyna</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1521468946">2023-04-25 09:28</a>:<a class="headerlink" href="#pcahyna_commented_at_2023-04-25_0928" title="Permanent link">&para;</a></h4>
<p>Hi @Steinefels , sorry for the late reply - if you still have the system
in question, can you try to remove <code>/etc/lvm/devices/system.devices</code> in
the restored system? (If doing it from the ReaR rescue system after
backup restoration, the restored system is mounted under <code>/mnt/local</code> .)</p>
<h4 id="steinefels_commented_at_2023-04-26_1438"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1523537076">2023-04-26 14:38</a>:<a class="headerlink" href="#steinefels_commented_at_2023-04-26_1438" title="Permanent link">&para;</a></h4>
<p>Hi @pcahyna thanks for getting back to me and this weird issue. I'll
give your advice a chance this evening :-)</p>
<h4 id="steinefels_commented_at_2023-04-26_1440"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1523538876">2023-04-26 14:40</a>:<a class="headerlink" href="#steinefels_commented_at_2023-04-26_1440" title="Permanent link">&para;</a></h4>
<p>Btw: I tried to get some feedback on this from Oracle, but no reply so
far.</p>
<h4 id="steinefels_commented_at_2023-04-26_1620"><img src="https://avatars.githubusercontent.com/u/123949246?v=4" width="50"><a href="https://github.com/Steinefels">Steinefels</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1523700021">2023-04-26 16:20</a>:<a class="headerlink" href="#steinefels_commented_at_2023-04-26_1620" title="Permanent link">&para;</a></h4>
<p>Hi @pcahyna, congratulations!! This was definetly the advice to make the
backup system running!! No more error-messages during boot-up after
removing 'system.devices'.</p>
<p>cheers and many thanks again!<br />
:-)</p>
<h4 id="pcahyna_commented_at_2023-04-26_1712"><img src="https://avatars.githubusercontent.com/u/26300485?u=9105d243bc9f7ade463a3e52e8dd13fa67837158&v=4" width="50"><a href="https://github.com/pcahyna">pcahyna</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1523779273">2023-04-26 17:12</a>:<a class="headerlink" href="#pcahyna_commented_at_2023-04-26_1712" title="Permanent link">&para;</a></h4>
<p>@Steinefels thanks for testing and glad that it helped!</p>
<p>Reopening the issue because it is a quite serious problem when
recovering to different hardware.</p>
<h4 id="github-actions_commented_at_2023-06-27_0249"><img src="https://avatars.githubusercontent.com/in/15368?v=4" width="50"><a href="https://github.com/apps/github-actions">github-actions</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1608654220">2023-06-27 02:49</a>:<a class="headerlink" href="#github-actions_commented_at_2023-06-27_0249" title="Permanent link">&para;</a></h4>
<p>Stale issue message</p>
<h4 id="github-actions_commented_at_2023-08-27_0203"><img src="https://avatars.githubusercontent.com/in/15368?v=4" width="50"><a href="https://github.com/apps/github-actions">github-actions</a> commented at <a href="https://github.com/rear/rear/issues/2917#issuecomment-1694546992">2023-08-27 02:03</a>:<a class="headerlink" href="#github-actions_commented_at_2023-08-27_0203" title="Permanent link">&para;</a></h4>
<p>Stale issue message</p>
<hr />
<p>[Export of Github issue for
<a href="https://github.com/rear/rear">rear/rear</a>.]</p>
              
            </div>
          </div>

<footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
    <p>Copyright 2024 - CC0 1.0 Universal<br />Give <a href="https://github.com/rear/rear-user-guide/issues/new?title=issues/2023-01-30.2917.issue.closed.html">feedback</a> on this page.</p>
    
  </div>
</footer>

        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/rear/rear-user-guide" class="fa fa-code-fork" style="color: #fcfcfc"> rear/rear-user-guide</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
