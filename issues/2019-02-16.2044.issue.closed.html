<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <meta property="og:title" content="Relax-and-Recover (ReaR) User Guide Documentation"/>
    <meta property="og:description" content="This is an umbrella documentation project for all Relax-and-Recover (ReaR) kind of documentation ans starting with a good User Guide."/>
    <meta property="og:locale" content="en_US"/>
    <meta property="og:url" content="https://relax-and-recover.org/rear-user-guide/"/>
    <meta property="og:type" content="website"/>
    <meta property="og:image" content="https://relax-and-recover.org/rear-user-guide/img/rear_logo_50.png"/>
    <meta property="og:image:width" content="50"/>
    <meta property="og:image:height" content="50"/>
    
    <title>#2044 Issue closed: WARNING: Failed to connect to lvmetad. Falling back to device scanning - Relax-and-Recover (ReaR) User Guide Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../css/rear.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "#2044 Issue closed: WARNING: Failed to connect to lvmetad. Falling back to device scanning";
        var mkdocs_page_input_path = "issues/2019-02-16.2044.issue.closed.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/rust.min.js"></script>
      <script>hljs.highlightAll();</script> 
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', "366986045", "auto");
        ga('send', 'pageview');
      </script>
    
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../index.html" class="icon icon-home"> Relax-and-Recover (ReaR) User Guide Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">WELCOME</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../welcome/index.html">Get started!</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">BASICS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/introduction.html">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/history.html">Bit of History</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/getting-started.html">Getting started with ReaR</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/configuration.html">Basic configuration</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">SCENARIOS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/index.html">Scenarios Overview</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">DEVELOPMENT</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../development/github-pr.html">Make a pull request with GitHub</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/index.html">Release Notes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear27.html">Release Notes ReaR 2.7</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear26.html">Release Notes ReaR 2.6</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/knownproblems.html">Known Problems and Workarounds</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">ISSUES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="index.html">Issues History</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">LEGAL</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/contributing/index.html">Contributing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/license/index.html">License</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html" class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">#2044 Issue closed: WARNING: Failed to connect to lvmetad. Falling back to device scanning</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="2044_issue_closed_warning_failed_to_connect_to_lvmetad_falling_back_to_device_scanning"><a href="https://github.com/rear/rear/issues/2044">#2044 Issue</a> <code>closed</code>: WARNING: Failed to connect to lvmetad. Falling back to device scanning<a class="headerlink" href="#2044_issue_closed_warning_failed_to_connect_to_lvmetad_falling_back_to_device_scanning" title="Permanent link">&para;</a></h1>
<p><strong>Labels</strong>: <code>enhancement</code>, <code>fixed / solved / done</code></p>
<h4 id="gdha_opened_issue_at_2019-02-16_1243"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> opened issue at <a href="https://github.com/rear/rear/issues/2044">2019-02-16 12:43</a>:<a class="headerlink" href="#gdha_opened_issue_at_2019-02-16_1243" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>ReaR version ("/usr/sbin/rear -V"): any</p>
</li>
<li>
<p>OS version ("cat /etc/rear/os.conf" or "lsb_release -a" or "cat
    /etc/os-release"): centos/rhel</p>
</li>
<li>
<p>System architecture (x86 compatible or PPC64/PPC64LE or what exact
    ARM device): x86_64</p>
</li>
<li>
<p>Description of the issue (ideally so that others can reproduce it):
    when using lvm we see lots of these warnings "<em>WARNING: Failed to
    connect to lvmetad. Falling back to device scanning</em>" in the log
    file</p>
</li>
<li>
<p>Workaround, if any: see
    <a href="https://unix.stackexchange.com/questions/332556/arch-linux-installation-grub-problem">https://unix.stackexchange.com/questions/332556/arch-linux-installation-grub-problem</a> -
    Edit your <strong>/etc/lvm/lvm.conf</strong> and set <strong>use_lvmetad = 0</strong> - still
    need to verify this</p>
</li>
</ul>
<h4 id="gozora_commented_at_2019-02-16_1511"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464354380">2019-02-16 15:11</a>:<a class="headerlink" href="#gozora_commented_at_2019-02-16_1511" title="Permanent link">&para;</a></h4>
<p>MIght this be related to
<a href="https://github.com/rear/rear/issues/2035">https://github.com/rear/rear/issues/2035</a>
?</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2019-02-18_0852"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464641932">2019-02-18 08:52</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-02-18_0852" title="Permanent link">&para;</a></h4>
<p>@gdha<br />
I also noticed those warnings and got worried about what might be
wrong<br />
but those warnings are nothing but a perfect example of a useless<br />
"WARNING is a waste of my time" cf.<br />
<a href="https://blog.schlomo.schapiro.org/2015/04/warning-is-waste-of-my-time.html">https://blog.schlomo.schapiro.org/2015/04/warning-is-waste-of-my-time.html</a></p>
<p>At least for me (using SLES) LVM "just worked" without lvmetad.<br />
I would appreciate it if we could silence this useless warnings.</p>
<p>@gozora<br />
I think @gdha means here etc/lvm/lvm.conf in the recovery system.</p>
<p>In contrast - as far as I understand it -
<a href="https://github.com/rear/rear/issues/2035">https://github.com/rear/rear/issues/2035</a><br />
is about LVM in the recreated system because there things fail (hang
up)<br />
within a <code>chroot $TARGET_FS_ROOT</code> so that one would have to edit<br />
$TARGET_FS_ROOT/etc/lvm/lvm.conf to make a difference there.<br />
But we cannot "just change" files in the recreated system because<br />
in general the restored files from the user's backup are sacrosanct.</p>
<h4 id="gozora_commented_at_2019-02-18_0902"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464645389">2019-02-18 09:02</a>:<a class="headerlink" href="#gozora_commented_at_2019-02-18_0902" title="Permanent link">&para;</a></h4>
<p>@jsmeix<br />
My
<a href="https://github.com/rear/rear/issues/2044#issuecomment-464354380">https://github.com/rear/rear/issues/2044#issuecomment-464354380</a>
was a reaction to
<a href="https://unix.stackexchange.com/questions/332556/arch-linux-installation-grub-problem">https://unix.stackexchange.com/questions/332556/arch-linux-installation-grub-problem</a>
(provided by @gdha) which says excerpt:</p>
<blockquote>
<p>...<br />
/run/lvm/lvmetad.socket: connect failed: No such file or directory<br />
or<br />
WARNING: failed to connect to lvmetad: No such file or directory.
Falling back to internal scanning.</p>
<p><strong>This is because /run is not available inside the chroot</strong>. These
warnings will not prevent the system from booting, provided that
everything has been done correctly, so you may continue with the
installation.</p>
</blockquote>
<p>So at the end of the day, we might not need to modify anything in
recovered system (<em>$TARGET_FS_ROOT/etc/lvm/lvm.conf</em>), but just plain
mounting <em>/run</em> might help. I guess it is at least wroth trying ...</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2019-02-18_0930"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464655293">2019-02-18 09:30</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-02-18_0930" title="Permanent link">&para;</a></h4>
<p>Yes,<br />
if LVM can no longer work without lvmetad or certain things in /run<br />
we should bind-mount /run at $TARGET_FS_ROOT/run.</p>
<p>My point was that for me (on SLES) LVM "just worked"<br />
without lvmetad or certain things in /run - same as in<br />
<a href="https://unix.stackexchange.com/questions/332556/arch-linux-installation-grub-problem">https://unix.stackexchange.com/questions/332556/arch-linux-installation-grub-problem</a><br />
<code>These warnings will not prevent the system from booting</code><br />
so that these warnings are useless and can be silenced.</p>
<p>But the behaviour in issue
<a href="https://github.com/rear/rear/issues/2035">https://github.com/rear/rear/issues/2035</a><br />
is different because there things do not work and then<br />
the LVM programs should error out (instead of endless waiting)<br />
when they can no longer work without lvmetad or certain things in /run.</p>
<h4 id="gozora_commented_at_2019-02-18_0941"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464659310">2019-02-18 09:41</a>:<a class="headerlink" href="#gozora_commented_at_2019-02-18_0941" title="Permanent link">&para;</a></h4>
<p>@jsmeix<br />
Things might "just work" for you because of older/different version of
LVM ;-).</p>
<blockquote>
<p>But the behaviour in issue #2035<br />
is different because there things do not work and then<br />
the LVM programs should error out (instead of endless waiting)<br />
when they can no longer work without lvmetad or certain things in
/run.</p>
</blockquote>
<p>I don't think there is some kind of endless waiting. There is just too
many block devices LVM would like to scan and timing out after 10
seconds on each of them, might just appear to be endless ...</p>
<p>@gdha, @jsmeix just for comparing, can you post here what versions of
LVM are you using you your particular systems ?</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2019-02-18_1127"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464695871">2019-02-18 11:27</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-02-18_1127" title="Permanent link">&para;</a></h4>
<p>SLES15 and openSUSE Leap 15.0:</p>
<pre><code># lvm  version
  LVM version:     2.02.177(2) (2017-12-18)
  Library version: 1.03.01 (2017-12-18)
  Driver version:  4.37.0
</code></pre>
<p>SLES12-SP4</p>
<pre><code># lvm  version
  LVM version:     2.02.180(2) (2018-07-19)
  Library version: 1.03.01 (2018-07-19)
  Driver version:  4.37.0
</code></pre>
<p>SLES11-SP4</p>
<pre><code># lvm  version
  LVM version:     2.02.98(2) (2012-10-15)
  Library version: 1.03.01 (2011-10-15)
  Driver version:  4.25.0
</code></pre>
<h4 id="gozora_commented_at_2019-02-18_1129"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464696712">2019-02-18 11:29</a>:<a class="headerlink" href="#gozora_commented_at_2019-02-18_1129" title="Permanent link">&para;</a></h4>
<p>Wow SLES12-SP4 runs newer version of LVM than SLES15 ...</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2019-02-18_1132"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-464697612">2019-02-18 11:32</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-02-18_1132" title="Permanent link">&para;</a></h4>
<p>Seems so - I saw it and double checked it - that's what <code>lvm version</code>
outputs<br />
(which does not take possible SUSE specific patches into account)...</p>
<h4 id="jsmeix_commented_at_2019-02-22_1133"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-466367503">2019-02-22 11:33</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-02-22_1133" title="Permanent link">&para;</a></h4>
<p>With
<a href="https://github.com/rear/rear/pull/2047">https://github.com/rear/rear/pull/2047</a>
merged<br />
/proc/ /sys/ /dev/ and /run/ are only bind-mounted into
TARGET_FS_ROOT<br />
at the beginning of the finalize stage during <code>rear recover</code><br />
so that this won't help for all what happens during <code>rear recover</code><br />
before its finalize stage - in particular
<a href="https://github.com/rear/rear/pull/2047">https://github.com/rear/rear/pull/2047</a><br />
cannot help when the disk layout gets recreated during <code>rear recover</code>.</p>
<h4 id="gdha_commented_at_2019-03-27_1311"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-477146470">2019-03-27 13:11</a>:<a class="headerlink" href="#gdha_commented_at_2019-03-27_1311" title="Permanent link">&para;</a></h4>
<p>on Ubuntu 18.04:</p>
<pre><code>ESCUE client:~ # lvm version
  LVM version:     2.02.176(2) (2017-11-03)
  Library version: 1.02.145 (2017-11-03)
  Driver version:  4.37.0
  Configuration:   ./configure --build=x86_64-linux-gnu --prefix=/usr --includedir=${prefix}/include --mandir=${prefix}/share/man --infodir=${prefix}/share/info --sysconfdir=/etc --localstatedir=/var --disable-silent-rules --libdir=${prefix}/lib/x86_64-linux-gnu --libexecdir=${prefix}/lib/x86_64-linux-gnu --runstatedir=/run --disable-maintainer-mode --disable-dependency-tracking --exec-prefix= --bindir=/bin --libdir=/lib/x86_64-linux-gnu --sbindir=/sbin --with-usrlibdir=/usr/lib/x86_64-linux-gnu --with-optimisation=-O2 --with-cache=internal --with-clvmd=corosync --with-cluster=internal --with-device-uid=0 --with-device-gid=6 --with-device-mode=0660 --with-default-pid-dir=/run --with-default-run-dir=/run/lvm --with-default-locking-dir=/run/lock/lvm --with-thin=internal --with-thin-check=/usr/sbin/thin_check --with-thin-dump=/usr/sbin/thin_dump --with-thin-repair=/usr/sbin/thin_repair --enable-applib --enable-blkid_wiping --enable-cmdlib --enable-cmirrord --enable-dmeventd --enable-dbus-service --enable-lvmetad --enable-lvmlockd-dlm --enable-lvmlockd-sanlock --enable-lvmpolld --enable-notify-dbus --enable-pkgconfig --enable-readline --enable-udev_rules --enable-udev_sync
</code></pre>
<p>And, I can confirm that by defining in <code>/etc/lvm/lvm.conf</code> the following
: <strong>use_lvmetad = 0</strong> the problem disappears.<br />
We can create a script
<code>/usr/share/rear/build/GNU/Linux/640_verify_lvm_conf.sh</code> to modify this
setting</p>
<h4 id="jsmeix_commented_at_2019-03-28_1014"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-477532482">2019-03-28 10:14</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-03-28_1014" title="Permanent link">&para;</a></h4>
<p>@gdha<br />
I would appreciate such a<br />
usr/share/rear/build/GNU/Linux/640_verify_lvm_conf.sh<br />
script.</p>
<p>On SLES10 and SLES11 <code>lvm version</code> does not show its <code>Configuration:</code><br />
in contrast to SLES12:</p>
<pre><code># lvm version
  LVM version:     2.02.180(2) (2018-07-19)
  Library version: 1.03.01 (2018-07-19)
  Driver version:  4.37.0
  Configuration:   ./configure --host=x86_64-suse-linux-gnu --build=x86_64-suse-linux-gnu --program-prefix= --disable-dependency-tracking --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include --libdir=/usr/lib64 --libexecdir=/usr/lib --localstatedir=/var --sharedstatedir=/usr/com --mandir=/usr/share/man --infodir=/usr/share/info --disable-dependency-tracking --prefix=/ --libdir=/lib64 --with-usrlibdir=/usr/lib64 --with-usrsbindir=/usr/sbin --sbindir=/sbin --enable-dmeventd --enable-udev_sync --enable-udev_rules --enable-cmdlib --enable-applib --enable-dmeventd --enable-realtime --enable-pkgconfig --enable-selinux --with-clvmd=corosync --with-cluster=internal --datarootdir=/usr/share --with-default-locking-dir=/run/lock/lvm --enable-cmirrord --enable-lvmetad --with-default-pid-dir=/run --with-default-dm-run-dir=/run --with-default-run-dir=/run/lvm --with-tmpfilesdir=/usr/lib/tmpfiles.d --with-thin=internal --with-device-gid=6 --with-device-mode=0640 --with-device-uid=0 --with-dmeventd-path=/sbin/dmeventd --with-thin-check=/usr/sbin/thin_check --with-thin-dump=/usr/sbin/thin_dump --with-thin-repair=/usr/sbin/thin_repair --with-udev-prefix=/usr/ --enable-blkid-wiping --enable-lvmpolld
</code></pre>
<p>and openSUSE Leap 15.0:</p>
<pre><code># lvm version
  LVM version:     2.02.177(2) (2017-12-18)
  Library version: 1.03.01 (2017-12-18)
  Driver version:  4.37.0
  Configuration:   ./configure --host=x86_64-suse-linux-gnu --build=x86_64-suse-linux-gnu --program-prefix= --disable-dependency-tracking --prefix=/usr --exec-prefix=/usr --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include --libdir=/usr/lib64 --libexecdir=/usr/lib --localstatedir=/var --sharedstatedir=/var/lib --mandir=/usr/share/man --infodir=/usr/share/info --disable-dependency-tracking --enable-dmeventd --enable-cmdlib --enable-udev_rules --enable-udev_sync --with-udev-prefix=/usr/ --enable-selinux --enable-pkgconfig --with-usrlibdir=/usr/lib64 --with-usrsbindir=/usr/sbin --with-default-dm-run-dir=/run --with-tmpfilesdir=/usr/lib/tmpfiles.d --with-thin=internal --with-device-gid=6 --with-device-mode=0640 --with-device-uid=0 --with-dmeventd-path=/usr/sbin/dmeventd --with-thin-check=/usr/sbin/thin_check --with-thin-dump=/usr/sbin/thin_dump --with-thin-repair=/usr/sbin/thin_repair --enable-applib --enable-blkid_wiping --enable-cmdlib --enable-lvmetad --enable-lvmpolld --enable-realtime --with-cache=internal --with-default-locking-dir=/run/lock/lvm --with-default-pid-dir=/run --with-default-run-dir=/run/lvm
</code></pre>
<p>that contain <code>Configuration: ... --enable-lvmetad ...</code>.</p>
<p>On SLES10 and SLES11 /etc/lvm/lvm.conf does not contain <code>lvmetad</code><br />
in contrast to SLES12 and openSUSE Leap 15.0 that contain</p>
<pre><code># find /etc/lvm/ | xargs grep -i lvmetad
/etc/lvm/lvm.conf:      debug_classes = [ "memory", "devices", "activation", "allocation", "lvmetad", "metadata", "cache", "locking", "lvmpolld", "dbus" ]
...
/etc/lvm/lvm.conf:      use_lvmetad = 1
</code></pre>
<p>On SLES10 and SLES11 there is no <code>lvmetad</code> process running<br />
in contrast to SLES12 and openSUSE Leap 15.0</p>
<pre><code># ps auxw | grep lvmetad
root  ... /usr/sbin/lvmetad -f
</code></pre>
<h4 id="viper1986_commented_at_2019-04-03_1026"><img src="https://avatars.githubusercontent.com/u/19300597?v=4" width="50"><a href="https://github.com/viper1986">viper1986</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-479431552">2019-04-03 10:26</a>:<a class="headerlink" href="#viper1986_commented_at_2019-04-03_1026" title="Permanent link">&para;</a></h4>
<p>Hello,<br />
I have similar error in my rear recover.<br />
I perform restore to another LPAR on PowerVM. OS SLES 12 PPC64LE.<br />
I try to modify /etc/lvm/lvm.conf and set use_lvmetad = 0 but it not
working.</p>
<p><a href="https://github.com/rear/rear/files/3038178/lvmetad.socket.txt">lvmetad.socket.txt</a><br />
<a href="https://github.com/rear/rear/files/3038179/use_lvmetad.txt">use_lvmetad.txt</a></p>
<h4 id="gdha_commented_at_2019-04-03_1034"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-479434057">2019-04-03 10:34</a>:<a class="headerlink" href="#gdha_commented_at_2019-04-03_1034" title="Permanent link">&para;</a></h4>
<p>@viper1986 the issue has nothing to do with the lvmetab warning -
duplicate UUID for a PV detected</p>
<pre><code>+++ lvm pvcreate -ff --yes -v --uuid 2qVfcO-mTQp-NzPW-Xphj-ezrY-HMNy-OJN7Fi --norestorefile /dev/mapper/mpathp
  Found duplicate PV 7DGexv5mGb83xwSTdIaKDHzahPeHZ87u: using /dev/disk/by-id/dm-name-mpathp-part2 not /dev/disk/by-id/dm-name-mpathi-part2
  Using duplicate PV /dev/disk/by-id/dm-name-mpathp-part2 which is last seen, replacing /dev/disk/by-id/dm-name-mpathi-part2
  Device /dev/mapper/mpathp not found (or ignored by filtering). Please run with -vvv option for more details
</code></pre>
<h4 id="viper1986_commented_at_2019-04-03_1129"><img src="https://avatars.githubusercontent.com/u/19300597?v=4" width="50"><a href="https://github.com/viper1986">viper1986</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-479449884">2019-04-03 11:29</a>:<a class="headerlink" href="#viper1986_commented_at_2019-04-03_1129" title="Permanent link">&para;</a></h4>
<p>I deleted all VG, LV and PV from rescue system.<br />
But I got:</p>
<pre><code>Device /dev/mapper/mpathp not found (or ignored by filtering). Please run with -vvv option for more details
</code></pre>
<p>Run fdisk and see that there are some partition exist:</p>
<pre><code>RESCUE dwrdev01:~ # fdisk /dev/mapper/mpathp
Welcome to fdisk (util-linux 2.28).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Command (m for help): p
Disk /dev/mapper/mpathp: 100 GiB, 107374182400 bytes, 209715200 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 32768 bytes / 32768 bytes
Disklabel type: dos
Disk identifier: 0x5bc10d00

Device                   Boot  Start      End  Sectors  Size Id Type
/dev/mapper/mpathp-part1 *      4096   419839   415744  203M  6 FAT16
/dev/mapper/mpathp-part2      419848 41943039 41523192 19.8G 8e Linux LVM

Partition 2 does not start on physical sector boundary.

Command (m for help): d
Partition number (1,2, default 2): 1

Partition 1 has been deleted.

Command (m for help): d
Selected partition 2
Partition 2 has been deleted.

Command (m for help): p

Disk /dev/mapper/mpathp: 100 GiB, 107374182400 bytes, 209715200 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 32768 bytes / 32768 bytes
Disklabel type: dos
Disk identifier: 0x5bc10d00

Command (m for help): w
The partition table has been altered.
Calling ioctl() to re-read partition table.
Re-reading the partition table failed.: Invalid argument

The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8).

RESCUE dwrdev01:~ # fdisk -l /dev/mapper/mpathp
Disk /dev/mapper/mpathp: 100 GiB, 107374182400 bytes, 209715200 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 32768 bytes / 32768 bytes
Disklabel type: dos
Disk identifier: 0x5bc10d00
</code></pre>
<p>Now recover works.</p>
<p>But my question is why REAR does not delete existing partitions on
disks?</p>
<h4 id="jsmeix_commented_at_2019-04-03_1434"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-479516599">2019-04-03 14:34</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-04-03_1434" title="Permanent link">&para;</a></h4>
<p>@viper1986<br />
according to<br />
<a href="https://github.com/rear/rear/issues/2044#issuecomment-479434057">https://github.com/rear/rear/issues/2044#issuecomment-479434057</a><br />
your issue has nothing to do with this issue here<br />
so that you would need to report your issue as a new separtated issue<br />
via the [New issue] button at
<a href="https://github.com/rear/rear/issues">https://github.com/rear/rear/issues</a></p>
<p>When you <code>restore to another LPAR on PowerVM</code><br />
that other LPAR must have fully clean storage and be fully<br />
compatible to the LPAR of your original system, cf. the sections<br />
"Fully compatible replacement hardware is needed" and<br />
"Prepare replacement hardware for disaster recovery" in<br />
<a href="https://en.opensuse.org/SDB:Disaster_Recovery">https://en.opensuse.org/SDB:Disaster_Recovery</a></p>
<p>Because of<br />
<a href="https://github.com/rear/rear/issues/2044#issuecomment-479449884">https://github.com/rear/rear/issues/2044#issuecomment-479449884</a><br />
it seems what was missing in this case was to<br />
"Prepare replacement hardware for disaster recovery".</p>
<p>ReaR does delete existing partitions on disks via <code>parted mklabel</code><br />
but that does only delete the plain partitioning data but not any
other<br />
kind of remainder data on an already used disk which <code>wipefs</code> is<br />
supposed to do when <code>wipefs</code> is run in reverse ordering on each<br />
storage object (listed by <code>lsblk</code> as KNAME) starting from higher-level<br />
storage objects (like partitions) down to lower-level storage objects<br />
(like whole disks) - except exceptions where only <code>dd</code> helps (see
below).</p>
<p>As long as we do not have a "cleanupdisk" script in ReaR,<br />
cf.
<a href="https://github.com/rear/rear/issues/799">https://github.com/rear/rear/issues/799</a><br />
you should clear out your target disk if it had been ever used before<br />
to be in general on the safe side against unexpected weird issues<br />
because of whatever kind of remainder data on an already used disk.</p>
<p>Cf.<br />
<a href="https://github.com/rear/rear/issues/2019#issuecomment-476598723">https://github.com/rear/rear/issues/2019#issuecomment-476598723</a><br />
and the subsequent comments therein.<br />
The interesting result in that case was that the only really reliable<br />
working way was to completely zero out the replacement storage<br />
via a "dumb brute force" command like</p>
<pre><code>dd if=/dev/zero of=/dev/whole_disk
</code></pre>
<p>i.e. <code>wipefs</code> alone was not sufficient - and only deleting plain
partitions<br />
is in general not at all sufficient to remove any kind of remainder
data<br />
on an already used disk (for example remainders of RAID<br />
or partition-table signatures and other kind of "magic strings"<br />
like LVM metadata and whatever else)...</p>
<h4 id="jsmeix_commented_at_2019-04-05_1246"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2044#issuecomment-480262428">2019-04-05 12:46</a>:<a class="headerlink" href="#jsmeix_commented_at_2019-04-05_1246" title="Permanent link">&para;</a></h4>
<p>With
<a href="https://github.com/rear/rear/pull/2107">https://github.com/rear/rear/pull/2107</a>
merged<br />
this issue here as described in<br />
<a href="https://github.com/rear/rear/issues/2044#issue-411069484">https://github.com/rear/rear/issues/2044#issue-411069484</a><br />
should be fixed.</p>
<hr />
<p>[Export of Github issue for
<a href="https://github.com/rear/rear">rear/rear</a>.]</p>
              
            </div>
          </div>

<footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
    <p>Copyright 2023 - CC0 1.0 Universal<br />Give <a href="https://github.com/rear/rear-user-guide/issues/new?title=issues/2019-02-16.2044.issue.closed.html">feedback</a> on this page.</p>
    
  </div>
</footer>

        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
