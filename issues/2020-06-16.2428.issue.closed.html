<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <meta property="og:title" content="Relax-and-Recover (ReaR) User Guide Documentation"/>
    <meta property="og:description" content="This is an umbrella documentation project for all Relax-and-Recover (ReaR) kind of documentation ans starting with a good User Guide."/>
    <meta property="og:locale" content="en_US"/>
    <meta property="og:url" content="https://relax-and-recover.org/rear-user-guide/"/>
    <meta property="og:type" content="website"/>
    <meta property="og:image" content="https://relax-and-recover.org/rear-user-guide/img/rear_logo_50.png"/>
    <meta property="og:image:width" content="50"/>
    <meta property="og:image:height" content="50"/>
    
    <title>#2428 Issue closed: MIGRATION_MODE: Autodetect when required disk mappings are missing - Relax-and-Recover (ReaR) User Guide Documentation</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../css/rear.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "#2428 Issue closed: MIGRATION_MODE: Autodetect when required disk mappings are missing";
        var mkdocs_page_input_path = "issues/2020-06-16.2428.issue.closed.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/rust.min.js"></script>
      <script>hljs.highlightAll();</script> 
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', "366986045", "auto");
        ga('send', 'pageview');
      </script>
    
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../index.html" class="icon icon-home"> Relax-and-Recover (ReaR) User Guide Documentation
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">WELCOME</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../welcome/index.html">Get started!</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">BASICS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/introduction.html">Introduction</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/history.html">Bit of History</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/getting-started.html">Getting started with ReaR</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/configuration.html">Basic configuration</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../basics/backup_netfs.html">Example of BACKUP=NETFS</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">SCENARIOS</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/index.html">Scenarios Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/netfs_nas.html">Internal Backup with tar to NFS server</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../scenarios/netfs_rsync.md">Internal Backup with rsync to NFS server</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/rbme.html">External Backup using RBME</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../scenarios/restic.html">External Backup using restic</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">DEVELOPMENT</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../development/github-pr.html">Make a pull request with GitHub</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../development/squash-git-log-commments.html">How to squash git log comments into one line</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">RELEASE NOTES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/index.html">Release Notes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear29.html">Release Notes ReaR 2.9</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear28.html">Release Notes ReaR 2.8</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear27.html">Release Notes ReaR 2.7</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/rear26.html">Release Notes ReaR 2.6</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../releasenotes/knownproblems.html">Known Problems and Workarounds</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">ISSUES</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="index.html">Issues History</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">LEGAL</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/contributing/index.html">Contributing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../legal/license/index.html">License</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Relax-and-Recover (ReaR) User Guide Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html" class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">#2428 Issue closed: MIGRATION_MODE: Autodetect when required disk mappings are missing</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="2428_issue_closed_migration_mode_autodetect_when_required_disk_mappings_are_missing"><a href="https://github.com/rear/rear/issues/2428">#2428 Issue</a> <code>closed</code>: MIGRATION_MODE: Autodetect when required disk mappings are missing<a class="headerlink" href="#2428_issue_closed_migration_mode_autodetect_when_required_disk_mappings_are_missing" title="Permanent link">&para;</a></h1>
<p><strong>Labels</strong>: <code>enhancement</code>, <code>minor bug</code>, <code>no-issue-activity</code></p>
<h4 id="gozora_opened_issue_at_2020-06-16_2120"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> opened issue at <a href="https://github.com/rear/rear/issues/2428">2020-06-16 21:20</a>:<a class="headerlink" href="#gozora_opened_issue_at_2020-06-16_2120" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>ReaR version ("/usr/sbin/rear
    -V"):<a href="https://github.com/rear/rear/commit/fb23c5d711af9ee505a9b03ea7324a098f90891d">https://github.com/rear/rear/commit/fb23c5d711af9ee505a9b03ea7324a098f90891d</a></p>
</li>
<li>
<p>OS version ("cat /etc/os-release" or "lsb_release -a" or "cat
    /etc/rear/os.conf"): <strong>Centos 7</strong></p>
</li>
<li>
<p>ReaR configuration files ("cat /etc/rear/site.conf" and/or "cat
    /etc/rear/local.conf"):</p>
</li>
</ul>
<!-- -->

<pre><code>BACKUP=NETFS
BACKUP_OPTIONS="nfsvers=3,nolock"
OUTPUT=ISO

BACKUP_URL=nfs://backup/mnt/rear
OUTPUT_URL=nfs://backup/mnt/rear/iso

SSH_FILES="yes"
SSH_UNPROTECTED_PRIVATE_KEYS="yes"

PROGS+=( /usr/libexec/openssh/sftp-server )
COPY_AS_IS+=( /usr/libexec/openssh/sftp-server )

USE_RESOLV_CONF="no"
USE_DHCLIENT="no"

NETWORKING_PREPARATION_COMMANDS=( 'ip addr add 192.168.56.200/24 dev enp0s8' 'ip link set dev enp0s8 up' 'return' )

EXCLUDE_RECREATE+=( /dev/mapper/data )

BOOT_OVER_SAN="yes"
AUTOEXCLUDE_MULTIPATH="no"
</code></pre>
<ul>
<li>
<p>Hardware (PC or PowerNV BareMetal or ARM) or virtual machine (KVM
    guest or PoverVM LPAR): <strong>VirtualBox</strong></p>
</li>
<li>
<p>System architecture (x86 compatible or PPC64/PPC64LE or what exact
    ARM device): <strong>x86_64</strong></p>
</li>
<li>
<p>Firmware (BIOS or UEFI or Open Firmware) and bootloader (GRUB or
    ELILO or Petitboot):<strong>UEFI</strong></p>
</li>
<li>
<p>Storage (local disk or SSD) and/or SAN (FC or iSCSI or FCoE) and/or
    multipath (DM or NVMe): <strong>local disk</strong></p>
</li>
<li>
<p>Storage layout ("lsblk -ipo
    NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,SIZE,MOUNTPOINT" or "lsblk" as
    makeshift):</p>
</li>
</ul>
<!-- -->

<pre><code>NAME                        KNAME     PKNAME    TRAN   TYPE  FSTYPE             SIZE MOUNTPOINT
/dev/sda                    /dev/sda            sata   disk                       8G 
|-/dev/sda1                 /dev/sda1 /dev/sda         part  vfat               200M /boot/efi
|-/dev/sda2                 /dev/sda2 /dev/sda         part  xfs                  1G /boot
`-/dev/sda3                 /dev/sda3 /dev/sda         part  LVM2_member        6.8G 
  |-/dev/mapper/centos-root /dev/dm-0 /dev/sda3        lvm   xfs                  6G /
  `-/dev/mapper/centos-swap /dev/dm-1 /dev/sda3        lvm   swap               820M [SWAP]
/dev/sdb                    /dev/sdb            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_2        /dev/dm-3 /dev/sdb         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-3        raid1 xfs                  8G /data
/dev/sdc                    /dev/sdc            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_1        /dev/dm-2 /dev/sdc         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-2        raid1 xfs                  8G /data
</code></pre>
<ul>
<li>Description of the issue (ideally so that others can reproduce
    it):<br />
    When I try to recover to slightly different (different disk sizes)
    VM, right after following disk mapping confirmation</li>
</ul>
<!-- -->

<pre><code>Current disk mapping table (source =&gt; target):
  /dev/sda =&gt; /dev/sdc
  /dev/mapper/disk_2 =&gt; /dev/mapper/mpatha
  /dev/mapper/disk_1 =&gt; /dev/mapper/mpathb
</code></pre>
<p>I got following error:</p>
<pre><code>Failed to apply layout mappings to /var/lib/rear/layout/disklayout.conf for /dev/sdc (probably no mapping for /dev/sdc in /var/lib/rear/layout/disk_mappings)
Failed to apply disk layout mappings to /var/lib/rear/layout/disklayout.conf
Applied disk layout mappings to /var/lib/rear/layout/config/df.txt
Applied disk layout mappings to /etc/rear/rescue.conf
ERROR: Failed to apply disk layout mappings
Some latest log messages since the last called script 320_apply_mappings.sh:
  2020-06-16 22:53:36.110912048 Including layout/prepare/default/320_apply_mappings.sh
  2020-06-16 22:53:36.111942350 Entering debugscript mode via 'set -x'.
  2020-06-16 22:53:36.164819410 Failed to apply layout mappings to /var/lib/rear/layout/disklayout.conf for /dev/sdc (probably no mapping for /dev/sdc in /var/lib/rear/layout/disk_mappings)
  2020-06-16 22:53:36.170025168 Failed to apply disk layout mappings to /var/lib/rear/layout/disklayout.conf
  2020-06-16 22:53:36.224116028 Applied disk layout mappings to /var/lib/rear/layout/config/df.txt
  2020-06-16 22:53:36.281945958 Applied disk layout mappings to /etc/rear/rescue.conf
Aborting due to an error, check /var/log/rear/rear-centos7.log for details
Exiting rear recover (PID 503) and its descendant processes ...
Running exit tasks
You should also rm -Rf /tmp/rear.lFXgLlXD5BQgp7w
</code></pre>
<p>The problem is probably with multipath slaves (sdb, sdc) in
<em>disklayout.conf</em></p>
<pre><code>multipath /dev/mapper/disk_2 8589934592 unknown /dev/sdb
multipath /dev/mapper/disk_1 8589934592 unknown /dev/sdc
</code></pre>
<p>These slaves are not listed in <em>disk_mappings</em> (hence are not
considered full-featured disks) but ReaR still tries to replace them
with apply_layout_mappings() which results to disklayout.conf like
this:</p>
<pre><code>multipath /dev/mapper/mpatha 8589934592 unknown /dev/sdb
multipath /dev/mapper/mpathb 8589934592 unknown _REAR1_
</code></pre>
<p>and the above error.</p>
<ul>
<li>Workaround, if any:<br />
    Remove slaves from <em>disklayout.conf</em> before starting
    <code>rear recover</code><br />
    e.g.</li>
</ul>
<!-- -->

<pre><code>multipath /dev/mapper/mpatha 8589934592 unknown
multipath /dev/mapper/mpathb 8589934592 unknown
</code></pre>
<ul>
<li>Attachments, as applicable ("rear -D mkrescue/mkbackup/recover"
    debug log files):<br />
<a href="https://github.com/rear/rear/files/4789134/rear-centos7.log">rear-centos7.log</a></li>
</ul>
<h4 id="jsmeix_commented_at_2020-06-17_0635"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645181468">2020-06-17 06:35</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_0635" title="Permanent link">&para;</a></h4>
<p>This is a result of how the current <code>apply_layout_mappings</code> function<br />
in usr/share/rear/lib/layout-functions.sh<br />
works and in particular the behaviour that leads to this issue here<br />
is described in the comments of the <code>apply_layout_mappings</code> function<br />
excerpts:</p>
<pre><code>    # Step 0:
    # For each original device in the mapping file generate a unique word (the "replacement").
    # E.g. when the mapping file content is
    #   /dev/sda /dev/sdb
    #   /dev/sdb /dev/sda
    #   /dev/sdd /dev/sdc
    # the replacement file will contain
    #   /dev/sda _REAR0_
    #   /dev/sdb _REAR1_
    #   /dev/sdd _REAR2_
    #   /dev/sdc _REAR3_
...
    # Step 1:
    # Replace all original devices with their replacements.
    # E.g. when the file_to_migrate content is
    #   disk /dev/sda
    #   disk /dev/sdb
    #   disk /dev/sdc
    #   disk /dev/sdd
    # it will get temporarily replaced (with the replacement file content in step 0 above) by
    #   disk _REAR0_
    #   disk _REAR1_
    #   disk _REAR3_
    #   disk _REAR2_
...
    # Step 2:
    # Replace all unique replacement words with the matching target device of the source device in the mapping file.
    # E.g. when the file_to_migrate content was in step 1 above temporarily changed to
    #   disk _REAR0_
    #   disk _REAR1_
    #   disk _REAR3_
    #   disk _REAR2_
    # it will now get finally replaced (with the replacement file and mapping file contents in step 0 above) by
    #   disk /dev/sdb
    #   disk /dev/sda
    #   disk _REAR3_
    #   disk /dev/sdc
    # where the temporary replacement "disk _REAR3_" from step 1 above is left because
    # there is (erroneously) no mapping for /dev/sdc (as source device) in the mapping file (in step 0 above).
...
    # Step 3:
    # Verify that there are none of those temporary replacement words from step 1 left in file_to_migrate
    # to ensure the replacement was done correctly and completely (cf. the above example where '_REAR3_' is left).
</code></pre>
<p>So the root cause of this issue here is in the<br />
disk mapping table (source =&gt; target)</p>
<pre><code>/dev/sda =&gt; /dev/sdc
/dev/mapper/disk_2 =&gt; /dev/mapper/mpatha
/dev/mapper/disk_1 =&gt; /dev/mapper/mpathb
</code></pre>
<p>where all counterpart mappings are missing, i.e.<br />
/dev/sda is mapped to /dev/sdc<br />
but there is no counterpart mapping for /dev/sdc<br />
/dev/mapper/disk_2 is mapped to /dev/mapper/mpatha<br />
but there is no counterpart mapping for /dev/mapper/mpatha<br />
/dev/mapper/disk_1 is mapped to /dev/mapper/mpathb<br />
but there is no counterpart mapping for /dev/mapper/mpathb</p>
<p>Simply put:<br />
The current disk mapping code only works<br />
when all mapping targets are also specified as a mapping source.</p>
<p>The mapping file is created by<br />
usr/share/rear/layout/prepare/default/300_map_disks.sh<br />
so I think there could be an issue therein when it creates<br />
a mapping file with missing counterpart mappings.</p>
<p>According to the comments in<br />
usr/share/rear/layout/prepare/default/300_map_disks.sh<br />
I think it should create a mapping file with counterpart mappings<br />
but from what I see in your<br />
<a href="https://github.com/rear/rear/files/4789134/rear-centos7.log">https://github.com/rear/rear/files/4789134/rear-centos7.log</a><br />
it seems it creates an incomplete mapping<br />
because it seems you got only this user dialogs (excerpts):</p>
<pre><code>Using user provided mapping file disk_mappings
Using /dev/sdc (same size) for recreating /dev/sda
Original disk /dev/mapper/disk_2 does not exist (with same size) in the target system
/dev/sdc excluded from device mapping choices (is already used as mapping target)
sr0 excluded from device mapping choices (is a removable device)
UserInput: called in /usr/share/rear/layout/prepare/default/300_map_disks.sh line 238
UserInput: Default input not in choices
UserInput -I LAYOUT_MIGRATION_REPLACEMENT_DISK2 needed in /usr/share/rear/layout/prepare/default/300_map_disks.sh line 238
Choose an appropriate replacement for /dev/mapper/disk_2
1) /dev/mapper/mpatha
2) /dev/mapper/mpathb
3) /dev/sda
4) /dev/sdb
5) Do not map /dev/mapper/disk_2
6) Use Relax-and-Recover shell and return back to here
(default '1' timeout 300 seconds)
UserInput: 'read' got as user input '1'
UserInput: Valid choice number result '/dev/mapper/mpatha'
Using /dev/mapper/mpatha (chosen by user) for recreating /dev/mapper/disk_2
...
Original disk /dev/mapper/disk_1 does not exist (with same size) in the target system
/dev/mapper/mpatha excluded from device mapping choices (is already used as mapping target)
/dev/sdc excluded from device mapping choices (is already used as mapping target)
sr0 excluded from device mapping choices (is a removable device)
UserInput: called in /usr/share/rear/layout/prepare/default/300_map_disks.sh line 238
UserInput: Default input not in choices
UserInput -I LAYOUT_MIGRATION_REPLACEMENT_DISK1 needed in /usr/share/rear/layout/prepare/default/300_map_disks.sh line 238
Choose an appropriate replacement for /dev/mapper/disk_1
1) /dev/mapper/mpathb
2) /dev/sda
3) /dev/sdb
4) Do not map /dev/mapper/disk_1
5) Use Relax-and-Recover shell and return back to here
(default '1' timeout 300 seconds)
UserInput: 'read' got as user input '1'
UserInput: Valid choice number result '/dev/mapper/mpathb'
Using /dev/mapper/mpathb (chosen by user) for recreating /dev/mapper/disk_1
</code></pre>
<h4 id="gozora_commented_at_2020-06-17_0709"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645194670">2020-06-17 07:09</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_0709" title="Permanent link">&para;</a></h4>
<p>@jsmeix thanks for your input, I was basically just guessing what is
going on because I did not work whit this part of ReaR code before.<br />
I general I think that missing multipath slaves in <em>disk_mappings</em> is
OK, because mapping sometimes hundreds of disks could be realy
cumbersome and annoying. IMHO it would be enough to avoid
<code>apply_layout_mappings()</code> replacing <code>multipath</code> slaves in
<em>disklaout.conf</em>.</p>
<p>V.</p>
<h4 id="gozora_commented_at_2020-06-17_0712"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645196261">2020-06-17 07:12</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_0712" title="Permanent link">&para;</a></h4>
<p>I've found some code that uses multipath slave entries in
<em>disklaout.conf</em> when running backup, but didn't found any code that
would need multipath slaves during restore. So maybe another approach to
modifying <code>apply_layout_mappings()</code> could be to remove slave entries
entirely when restoring...</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2020-06-17_0758"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645218229">2020-06-17 07:58</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_0758" title="Permanent link">&para;</a></h4>
<p>No, the <code>apply_layout_mappings</code> function must not make decisions<br />
whether or not entries in the disk mapping file are valid or needed.</p>
<p>In contrast what creates the disk mapping file is the right place<br />
to make decisions what valid and needed mappings are and<br />
to create a valid disk mapping file for the needed mappings.</p>
<p>I know basically nothing about multipath (I never used it myself).</p>
<p>I assume to access a single unique disk that is connected via
multipath<br />
one must only use the one single unique high level device node<br />
that matches the single unique disk<br />
but one must never use one of the several lower level device nodes<br />
that match the several hardware paths to the single unique disk.</p>
<p>In your case</p>
<pre><code>/dev/sdb                    /dev/sdb            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_2        /dev/dm-3 /dev/sdb         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-3        raid1 xfs                  8G /data
/dev/sdc                    /dev/sdc            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_1        /dev/dm-2 /dev/sdc         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-2        raid1 xfs                  8G /data
</code></pre>
<p>I assume this shows a single unique disk that is connected via
multipath<br />
where that one disk appears via two paths as /dev/sdb and /dev/sdc<br />
and the one single unique high level device node for that disk<br />
is <code>/dev/md0</code> which is the only device node that should be used<br />
e.g. by parted to create partitions on that disk<br />
but the various lower level device nodes that match the two paths<br />
to the single unique disk must not be used to access that disk.</p>
<p>This would match that you "didn't found any code that would need<br />
multipath slaves during restore".</p>
<p>If my above assumptions are right I would think there should be<br />
not any mapping of any of the several lower level device nodes<br />
that match the several hardware paths to the single unique disk.</p>
<p>Accordingly I would think that in your example<br />
there should be no mapping that contains any of</p>
<pre><code>/dev/mapper/disk_1
/dev/mapper/disk_2
/dev/mapper/mpatha
/dev/mapper/mpathb
</code></pre>
<p>as mapping source or as mapping target.</p>
<p>What puzzles me is your mapping</p>
<pre><code>/dev/sda =&gt; /dev/sdc
</code></pre>
<p>because I would think /dev/sda is a normal single-path disk<br />
while /dev/sdb and /dev/sdc is one same disk via two paths<br />
so a mapping of /dev/sda to /dev/sdb or /dev/sdc looks wrong.</p>
<p>Or what do I misunderstand here?</p>
<p>@gozora<br />
could you describe your disks on your original system<br />
versus what there is on your replacement system in more detail<br />
so that I could better imagine how a mapping could look like.</p>
<h4 id="gozora_commented_at_2020-06-17_0835"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645236747">2020-06-17 08:35</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_0835" title="Permanent link">&para;</a></h4>
<p>Hello @jsmeix,</p>
<blockquote>
<p>I assume to access a single unique disk that is connected via
multipath<br />
one must only use the one single unique high level device node<br />
that matches the single unique disk<br />
but one must never use one of the several lower level device nodes<br />
that match the several hardware paths to the single unique disk.</p>
</blockquote>
<p>This assumption is right!</p>
<p>The other one not ;-). It is partly my fault because setup I've created
is quite doctle to simulate multipath in very simple way. Normally
multipath consists of several slaves. To illustrate, I'll show you how
multipath looks like on my other sever which is running cluster, please
note that following output is not related to this issue and serves just
for multipath output demonstration:</p>
<pre><code>node1:~ # multipath -l
site_A_3 (360000000000000000e00e6b900000003) dm-4 IET,VIRTUAL-DISK
size=512M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 7:0:0:3  sdi  8:128  active undef running
  |- 9:0:0:3  sdm  8:192  active undef running
  `- 8:0:0:3  sdp  8:240  active undef running
site_B_3 (360000000000000000e00e5a500000003) dm-9 IET,VIRTUAL-DISK
size=512M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 13:0:0:3 sdw  65:96  active undef running
  |- 15:0:0:3 sdab 65:176 active undef running
  `- 14:0:0:3 sdae 65:224 active undef running
site_A_2 (360000000000000000e00e6b900000002) dm-3 IET,VIRTUAL-DISK
size=512M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 7:0:0:2  sdh  8:112  active undef running
  |- 9:0:0:2  sdl  8:176  active undef running
  `- 8:0:0:2  sdo  8:224  active undef running
site_B_2 (360000000000000000e00e5a500000002) dm-8 IET,VIRTUAL-DISK
size=512M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 13:0:0:2 sdv  65:80  active undef running
  |- 15:0:0:2 sdaa 65:160 active undef running
  `- 14:0:0:2 sdad 65:208 active undef running
site_A_1 (360000000000000000e00e6b900000001) dm-2 IET,VIRTUAL-DISK
size=5.0G features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 7:0:0:1  sdf  8:80   active undef running
  |- 9:0:0:1  sdk  8:160  active undef running
  `- 8:0:0:1  sdn  8:208  active undef running
site_B_1 (360000000000000000e00e5a500000001) dm-7 IET,VIRTUAL-DISK
size=5.0G features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 13:0:0:1 sdu  65:64  active undef running
  |- 15:0:0:1 sdz  65:144 active undef running
  `- 14:0:0:1 sdac 65:192 active undef running
iscsi1_lun2 (360000000000000000e00e6b900000005) dm-0 IET,VIRTUAL-DISK
size=256M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 5:0:0:2  sdc  8:32   active undef running
  |- 4:0:0:2  sde  8:64   active undef running
  `- 6:0:0:2  sdj  8:144  active undef running
iscsi1_lun1 (360000000000000000e00e6b900000004) dm-1 IET,VIRTUAL-DISK
size=512M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 4:0:0:1  sdd  8:48   active undef running
  |- 5:0:0:1  sdb  8:16   active undef running
  `- 6:0:0:1  sdg  8:96   active undef running
iscsi2_lun2 (360000000000000000e00e5a500000005) dm-6 IET,VIRTUAL-DISK
size=256M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 11:0:0:2 sdr  65:16  active undef running
  |- 10:0:0:2 sdt  65:48  active undef running
  `- 12:0:0:2 sdy  65:128 active undef running
iscsi2_lun1 (360000000000000000e00e5a500000004) dm-5 IET,VIRTUAL-DISK
size=512M features='1 queue_if_no_path' hwhandler='0' wp=rw
`-+- policy='round-robin 0' prio=0 status=active
  |- 11:0:0:1 sdq  65:0   active undef running
  |- 10:0:0:1 sds  65:32  active undef running
  `- 12:0:0:1 sdx  65:112 active undef running
</code></pre>
<p>Here you can see that we have one high device (e.g. site_A_3) with 3
slaves (sdi, sdm, sdp).</p>
<p>Corresponding <code>lsblk</code> output looks something like this:</p>
<pre><code>node1:~ # lsblk -ipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,SIZE,MOUNTPOINT
NAME                      KNAME     PKNAME    TRAN   TYPE  FSTYPE             SIZE MOUNTPOINT
/dev/sda                  /dev/sda            sata   disk                      50G 
|-/dev/sda1               /dev/sda1 /dev/sda         part  swap               995M [SWAP]
`-/dev/sda2               /dev/sda2 /dev/sda         part  btrfs               49G /
/dev/sdb                  /dev/sdb            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/iscsi1_lun1 /dev/dm-1 /dev/sdb         mpath linux_raid_member  512M 
/dev/sdc                  /dev/sdc            iscsi  disk  linux_raid_member  256M 
`-/dev/mapper/iscsi1_lun2 /dev/dm-0 /dev/sdc         mpath linux_raid_member  256M 
/dev/sdd                  /dev/sdd            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/iscsi1_lun1 /dev/dm-1 /dev/sdd         mpath linux_raid_member  512M 
/dev/sde                  /dev/sde            iscsi  disk  linux_raid_member  256M 
`-/dev/mapper/iscsi1_lun2 /dev/dm-0 /dev/sde         mpath linux_raid_member  256M 
/dev/sdf                  /dev/sdf            iscsi  disk  linux_raid_member    5G 
`-/dev/mapper/site_A_1    /dev/dm-2 /dev/sdf         mpath linux_raid_member    5G 
/dev/sdg                  /dev/sdg            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/iscsi1_lun1 /dev/dm-1 /dev/sdg         mpath linux_raid_member  512M 
/dev/sdh                  /dev/sdh            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_A_2    /dev/dm-3 /dev/sdh         mpath linux_raid_member  512M 
/dev/sdi                  /dev/sdi            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_A_3    /dev/dm-4 /dev/sdi         mpath linux_raid_member  512M 
/dev/sdj                  /dev/sdj            iscsi  disk  linux_raid_member  256M 
`-/dev/mapper/iscsi1_lun2 /dev/dm-0 /dev/sdj         mpath linux_raid_member  256M 
/dev/sdk                  /dev/sdk            iscsi  disk  linux_raid_member    5G 
`-/dev/mapper/site_A_1    /dev/dm-2 /dev/sdk         mpath linux_raid_member    5G 
/dev/sdl                  /dev/sdl            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_A_2    /dev/dm-3 /dev/sdl         mpath linux_raid_member  512M 
/dev/sdm                  /dev/sdm            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_A_3    /dev/dm-4 /dev/sdm         mpath linux_raid_member  512M 
/dev/sdn                  /dev/sdn            iscsi  disk  linux_raid_member    5G 
`-/dev/mapper/site_A_1    /dev/dm-2 /dev/sdn         mpath linux_raid_member    5G 
/dev/sdo                  /dev/sdo            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_A_2    /dev/dm-3 /dev/sdo         mpath linux_raid_member  512M 
/dev/sdp                  /dev/sdp            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_A_3    /dev/dm-4 /dev/sdp         mpath linux_raid_member  512M 
/dev/sr0                  /dev/sr0            ata    rom                     1024M 
/dev/sdq                  /dev/sdq            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/iscsi2_lun1 /dev/dm-5 /dev/sdq         mpath linux_raid_member  512M 
/dev/sdr                  /dev/sdr            iscsi  disk  linux_raid_member  256M 
`-/dev/mapper/iscsi2_lun2 /dev/dm-6 /dev/sdr         mpath linux_raid_member  256M 
/dev/sds                  /dev/sds            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/iscsi2_lun1 /dev/dm-5 /dev/sds         mpath linux_raid_member  512M 
/dev/sdt                  /dev/sdt            iscsi  disk  linux_raid_member  256M 
`-/dev/mapper/iscsi2_lun2 /dev/dm-6 /dev/sdt         mpath linux_raid_member  256M 
/dev/sdu                  /dev/sdu            iscsi  disk  linux_raid_member    5G 
`-/dev/mapper/site_B_1    /dev/dm-7 /dev/sdu         mpath linux_raid_member    5G 
/dev/sdv                  /dev/sdv            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_B_2    /dev/dm-8 /dev/sdv         mpath linux_raid_member  512M 
/dev/sdw                  /dev/sdw            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_B_3    /dev/dm-9 /dev/sdw         mpath linux_raid_member  512M 
/dev/sdx                  /dev/sdx            iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/iscsi2_lun1 /dev/dm-5 /dev/sdx         mpath linux_raid_member  512M 
/dev/sdy                  /dev/sdy            iscsi  disk  linux_raid_member  256M 
`-/dev/mapper/iscsi2_lun2 /dev/dm-6 /dev/sdy         mpath linux_raid_member  256M 
/dev/sdz                  /dev/sdz            iscsi  disk  linux_raid_member    5G 
`-/dev/mapper/site_B_1    /dev/dm-7 /dev/sdz         mpath linux_raid_member    5G 
/dev/sdaa                 /dev/sdaa           iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_B_2    /dev/dm-8 /dev/sdaa        mpath linux_raid_member  512M 
/dev/sdab                 /dev/sdab           iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_B_3    /dev/dm-9 /dev/sdab        mpath linux_raid_member  512M 
/dev/sdac                 /dev/sdac           iscsi  disk  linux_raid_member    5G 
`-/dev/mapper/site_B_1    /dev/dm-7 /dev/sdac        mpath linux_raid_member    5G 
/dev/sdad                 /dev/sdad           iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_B_2    /dev/dm-8 /dev/sdad        mpath linux_raid_member  512M 
/dev/sdae                 /dev/sdae           iscsi  disk  linux_raid_member  512M 
`-/dev/mapper/site_B_3    /dev/dm-9 /dev/sdae        mpath linux_raid_member  512M
</code></pre>
<p>in general this setup has 3 layers:</p>
<ol>
<li>/dev/sd* (single block device)</li>
<li>/dev/mapper (multipath device with /dev/sd* as slaves)</li>
<li>/dev/md (software RAID with /dev/mapper/site* as mirror sites)</li>
</ol>
<p>This setup shows how multipath setup might look in reality :-)</p>
<p>But now back to my testing Centos7 ...<br />
My setup is very simmilar to one described in demonstration before, with
one small exception. Multipath devices have only one path (In reality
such setup doesent make any sense, but this is only for testing
purposes).</p>
<p><strong>Source server</strong></p>
<pre><code>[root@centos7 ~]# multipath -l
disk_2 (VBOX_HARDDISK_VB2127148a-83767d0d) dm-2 ATA     ,VBOX HARDDISK   
size=8.0G features='0' hwhandler='0' wp=rw
`-+- policy='service-time 0' prio=0 status=active
  `- 3:0:0:0 sdb 8:16 active undef running
disk_1 (VBOX_HARDDISK_VBaa6af5b7-df6dd760) dm-3 ATA     ,VBOX HARDDISK   
size=8.0G features='0' hwhandler='0' wp=rw
`-+- policy='service-time 0' prio=0 status=active
  `- 4:0:0:0 sdc 8:32 active undef running

[root@centos7 ~]# lsblk -ipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,SIZE,MOUNTPOINT
NAME                        KNAME     PKNAME    TRAN   TYPE  FSTYPE             SIZE MOUNTPOINT
/dev/sda                    /dev/sda            sata   disk                       8G 
|-/dev/sda1                 /dev/sda1 /dev/sda         part  vfat               200M /boot/efi
|-/dev/sda2                 /dev/sda2 /dev/sda         part  xfs                  1G /boot
`-/dev/sda3                 /dev/sda3 /dev/sda         part  LVM2_member        6.8G 
  |-/dev/mapper/centos-root /dev/dm-0 /dev/sda3        lvm   xfs                  6G /
  `-/dev/mapper/centos-swap /dev/dm-1 /dev/sda3        lvm   swap               820M [SWAP]
/dev/sdb                    /dev/sdb            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_2        /dev/dm-2 /dev/sdb         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-2        raid1 xfs                  8G /data
/dev/sdc                    /dev/sdc            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_1        /dev/dm-3 /dev/sdc         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-3        raid1 xfs                  8G /data
/dev/sr0                    /dev/sr0            ata    rom                     1024M
</code></pre>
<p>and there is RAID1 build on top of <em>/dev/mapper/disk_2</em> and
<em>/dev/mapper/disk_1</em></p>
<p><strong>Destination server</strong></p>
<pre><code>RESCUE centos7:~ # multipath -l
RESCUE centos7:~ # multipath -l
mpathc (VBOX_HARDDISK_VB3b781a87-111c1fed) dm-0 ATA     ,VBOX HARDDISK   
size=20G features='0' hwhandler='0' wp=rw
`-+- policy='service-time 0' prio=0 status=active
  `- 3:0:0:0 sda 8:0  active undef running
mpatha (VBOX_HARDDISK_VB10e9f9a8-6b9c578b) dm-1 ATA     ,VBOX HARDDISK   
size=10G features='0' hwhandler='0' wp=rw
`-+- policy='service-time 0' prio=0 status=active
  `- 4:0:0:0 sdb 8:16 active undef running

RESCUE centos7:~ # lsblk -ipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,SIZE,MOUNTPOINT
NAME                 KNAME     PKNAME   TRAN   TYPE  FSTYPE         SIZE MOUNTPOINT
/dev/sda             /dev/sda           sata   disk  mpath_member    20G 
`-/dev/mapper/mpathc /dev/dm-0 /dev/sda        mpath                 20G 
/dev/sdb             /dev/sdb           sata   disk  mpath_member    10G 
`-/dev/mapper/mpatha /dev/dm-1 /dev/sdb        mpath                 10G 
/dev/sdc             /dev/sdc           sata   disk                   8G 
/dev/sr0             /dev/sr0           sata   rom   udf          319.6M
</code></pre>
<p>Note that this <code>lsblk</code> output is short after starting <code>rear recover</code> and
does not contain RAID yet.</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2020-06-17_0851"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645244888">2020-06-17 08:51</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_0851" title="Permanent link">&para;</a></h4>
<p>Correction of my above<br />
<a href="https://github.com/rear/rear/issues/2428#issuecomment-645181468">https://github.com/rear/rear/issues/2428#issuecomment-645181468</a></p>
<pre><code>Simply put:
The current disk mapping code only works
when all mapping targets are also specified as a mapping source.
</code></pre>
<p>As far as I see this is wrong because the following<br />
simple mapping can also work (source =&gt; target)</p>
<pre><code>/dev/sda =&gt; /dev/sdb
</code></pre>
<p>provided the mapping target /dev/sdb does not exist<br />
in a file where that mapping should be applied<br />
in particular provided the mapping target /dev/sdb<br />
does not exist in the disklayout.conf file.</p>
<p>This simple mapping can happen when the ReaR recovery system<br />
was booted from a removable disk (e.g. a USB stick or a USB disk)<br />
where on the replacement hardware the ReaR recovery system<br />
became /dev/sda and the actual target system disk is /dev/sdb<br />
and on the original system there was only one disk /dev/sda<br />
so that disklayout.conf contains /dev/sda but not /dev/sdb.</p>
<p>Then the apply_layout_mappings function generates from<br />
the <code>/dev/sda /dev/sdb</code> mapping file entry<br />
a replacement file that contains</p>
<pre><code>/dev/sda _REAR0_
/dev/sdb _REAR1_
</code></pre>
<p>and replaces e.g. in disklayout.conf<br />
all <code>/dev/sda</code> by <code>_REAR0_</code> and afterwards<br />
all <code>_REAR0_</code> by its matching target <code>/dev/sdb</code>.</p>
<p>So correctly it must be:</p>
<pre><code>Simply put:
The current disk mapping code only works
when those mapping targets are also specified as a mapping source
when the mapping target appears in a file where mappings are applied.
</code></pre>
<h4 id="gdha_commented_at_2020-06-17_0854"><img src="https://avatars.githubusercontent.com/u/888633?u=cdaeb31efcc0048d3619651aa18dd4b76e636b21&v=4" width="50"><a href="https://github.com/gdha">gdha</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645246213">2020-06-17 08:54</a>:<a class="headerlink" href="#gdha_commented_at_2020-06-17_0854" title="Permanent link">&para;</a></h4>
<p>@gozora Your server itself cannot be covered by ReaR because iSCSI is
not (yet) supported...</p>
<h4 id="jsmeix_commented_at_2020-06-17_0906"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645252289">2020-06-17 09:06</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_0906" title="Permanent link">&para;</a></h4>
<p>@gozora<br />
thank you for expaining your disk layout to me!<br />
I was already puzzled by the <code>raid1</code> TYPE entries of your lsblk output<br />
but I coud not make sense of them so I just mixed them up with
multipath.</p>
<h4 id="gozora_commented_at_2020-06-17_0943"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645270845">2020-06-17 09:43</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_0943" title="Permanent link">&para;</a></h4>
<p>@gdha as I've already stated:</p>
<blockquote>
<p>To illustrate, I'll show you how multipath looks like on my other
sever which is running cluster, please not that following output is
not related to this issue and serves just for multipath output
demonstration:</p>
</blockquote>
<p>So the output I've pasted (with iSCSI) is not the problematic/restored
server, It was pasted there only to show @jsmeix how multipath can be
setup.<br />
The real server disk layout is mentioned in
<a href="https://github.com/rear/rear/issues/2428#issue-639979434">https://github.com/rear/rear/issues/2428#issue-639979434</a>
(issue template).</p>
<p>In general I'm guessing that this problem will arise only if one would
restore server that has multipath enabled to different HW. Because when
restoring to original HW you normally don't need to do mapping.</p>
<p>V.</p>
<h4 id="gozora_commented_at_2020-06-17_0957"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645277060">2020-06-17 09:57</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_0957" title="Permanent link">&para;</a></h4>
<p>Just to add some more info, here is complete restore session with
following setup:</p>
<pre><code>RESCUE centos7:~ # lsblk -ipo NAME,KNAME,PKNAME,TRAN,TYPE,FSTYPE,SIZE,MOUNTPOINT
NAME                 KNAME     PKNAME   TRAN   TYPE  FSTYPE   SIZE MOUNTPOINT
/dev/sda             /dev/sda           sata   disk            20G 
`-/dev/mapper/mpatha /dev/dm-0 /dev/sda        mpath           20G 
/dev/sdb             /dev/sdb           sata   disk            10G 
`-/dev/mapper/mpathb /dev/dm-1 /dev/sdb        mpath           10G 
/dev/sdc             /dev/sdc           sata   disk             8G 
/dev/sr0             /dev/sr0           sata   rom   udf    319.6M

RESCUE centos7:~ # multipath -l
mpathb (VBOX_HARDDISK_VB10e9f9a8-6b9c578b) dm-1 ATA     ,VBOX HARDDISK   
size=10G features='0' hwhandler='0' wp=rw
`-+- policy='service-time 0' prio=0 status=active
  `- 4:0:0:0 sdb 8:16 active undef running
mpatha (VBOX_HARDDISK_VB3b781a87-111c1fed) dm-0 ATA     ,VBOX HARDDISK   
size=20G features='0' hwhandler='0' wp=rw
`-+- policy='service-time 0' prio=0 status=active
  `- 3:0:0:0 sda 8:0  active undef running
</code></pre>
<ul>
<li>the session</li>
</ul>
<!-- -->

<pre><code>RESCUE centos7:~ # rear -d -D recover
Relax-and-Recover 2.5 / Git
Running rear recover (PID 478)
Using log file: /var/log/rear/rear-centos7.log
Running workflow recover within the ReaR rescue/recovery system
Starting required daemons for NFS: RPC portmapper (portmap or rpcbind) and rpc.statd if available.
Started RPC portmapper 'rpcbind'.
RPC portmapper 'rpcbind' available.
Started rpc.statd.
RPC status rpc.statd available.
Using backup archive '/tmp/rear.OKkEbdifOMHNZhJ/outputfs/centos7/backup.tar.gz'
Will do driver migration (recreating initramfs/initrd)
Calculating backup archive size
Backup archive size is 1.1G /tmp/rear.OKkEbdifOMHNZhJ/outputfs/centos7/backup.tar.gz (compressed)
Setting up multipathing
Activating multipath
multipath activated
Starting multipath daemon
multipathd started
Listing multipath device found
mpathb (VBOX_HARDDISK_VB10e9f9a8-6b9c578b) dm-1 ATA     ,VBOX HARDDISK    size=10G
mpatha (VBOX_HARDDISK_VB3b781a87-111c1fed) dm-0 ATA     ,VBOX HARDDISK    size=20G
Comparing disks
Ambiguous disk layout needs manual configuration (more than one disk with same size used in '/var/lib/rear/layout/disklayout.conf')
Switching to manual disk layout configuration
Using /dev/sdc (same size) for recreating /dev/sda
Original disk /dev/mapper/disk_2 does not exist (with same size) in the target system
UserInput -I LAYOUT_MIGRATION_REPLACEMENT_DISK2 needed in /usr/share/rear/layout/prepare/default/300_map_disks.sh line 238
Choose an appropriate replacement for /dev/mapper/disk_2
1) /dev/mapper/mpatha
2) /dev/mapper/mpathb
3) /dev/sda
4) /dev/sdb
5) Do not map /dev/mapper/disk_2
6) Use Relax-and-Recover shell and return back to here
(default '1' timeout 300 seconds)
2
UserInput: Valid choice number result '/dev/mapper/mpathb'
Using /dev/mapper/mpathb (chosen by user) for recreating /dev/mapper/disk_2
Original disk /dev/mapper/disk_1 does not exist (with same size) in the target system
UserInput -I LAYOUT_MIGRATION_REPLACEMENT_DISK1 needed in /usr/share/rear/layout/prepare/default/300_map_disks.sh line 238
Choose an appropriate replacement for /dev/mapper/disk_1
1) /dev/mapper/mpatha
2) /dev/sda
3) /dev/sdb
4) Do not map /dev/mapper/disk_1
5) Use Relax-and-Recover shell and return back to here
(default '1' timeout 300 seconds)
1
UserInput: Valid choice number result '/dev/mapper/mpatha'
Using /dev/mapper/mpatha (chosen by user) for recreating /dev/mapper/disk_1
Current disk mapping table (source =&gt; target):
  /dev/sda =&gt; /dev/sdc
  /dev/mapper/disk_2 =&gt; /dev/mapper/mpathb
  /dev/mapper/disk_1 =&gt; /dev/mapper/mpatha

UserInput -I LAYOUT_MIGRATION_CONFIRM_MAPPINGS needed in /usr/share/rear/layout/prepare/default/300_map_disks.sh line 275
Confirm or edit the disk mapping
1) Confirm disk mapping and continue 'rear recover'
2) n/a
3) Edit disk mapping (/var/lib/rear/layout/disk_mappings)
4) Use Relax-and-Recover shell and return back to here
5) Abort 'rear recover'
(default '1' timeout 300 seconds)
1
UserInput: Valid choice number result 'Confirm disk mapping and continue 'rear recover''
User confirmed disk mapping
Failed to apply layout mappings to /var/lib/rear/layout/disklayout.conf for /dev/sdc (probably no mapping for /dev/sdc in /var/lib/rear/layout/disk_mappings)
Failed to apply disk layout mappings to /var/lib/rear/layout/disklayout.conf
Applied disk layout mappings to /var/lib/rear/layout/config/df.txt
Applied disk layout mappings to /etc/rear/rescue.conf
ERROR: Failed to apply disk layout mappings
Some latest log messages since the last called script 320_apply_mappings.sh:
  2020-06-17 11:51:03.680543288 Including layout/prepare/default/320_apply_mappings.sh
  2020-06-17 11:51:03.681513284 Entering debugscript mode via 'set -x'.
  2020-06-17 11:51:03.734287374 Failed to apply layout mappings to /var/lib/rear/layout/disklayout.conf for /dev/sdc (probably no mapping for /dev/sdc in /var/lib/rear/layout/disk_mappings)
  2020-06-17 11:51:03.739325049 Failed to apply disk layout mappings to /var/lib/rear/layout/disklayout.conf
  2020-06-17 11:51:03.793384670 Applied disk layout mappings to /var/lib/rear/layout/config/df.txt
  2020-06-17 11:51:03.848300496 Applied disk layout mappings to /etc/rear/rescue.conf
Aborting due to an error, check /var/log/rear/rear-centos7.log for details
Exiting rear recover (PID 478) and its descendant processes ...
Running exit tasks
You should also rm -Rf /tmp/rear.OKkEbdifOMHNZhJ
Terminated
</code></pre>
<ul>
<li>disk mapping</li>
</ul>
<!-- -->

<pre><code>RESCUE centos7:~ # less /tmp/rear.OKkEbdifOMHNZhJ/tmp/replacement_file 
/dev/sda _REAR0_
/dev/sdc _REAR1_
/dev/mapper/disk_2 _REAR2_
/dev/mapper/mpathb _REAR3_
/dev/mapper/disk_1 _REAR4_
/dev/mapper/mpatha _REAR5_
</code></pre>
<ul>
<li>disklayout.conf BEFORE the error</li>
</ul>
<!-- -->

<pre><code>RESCUE centos7:/var/lib/rear/layout # cat disklayout.conf.20200617115859.recover.489.orig
# Disk layout dated 20200616202902 (YYYYmmddHHMMSS)
# NAME                        KNAME     PKNAME    TRAN   TYPE  FSTYPE             SIZE MOUNTPOINT
# /dev/sda                    /dev/sda            sata   disk                       8G 
# |-/dev/sda1                 /dev/sda1 /dev/sda         part  vfat               200M /boot/efi
# |-/dev/sda2                 /dev/sda2 /dev/sda         part  xfs                  1G /boot
# `-/dev/sda3                 /dev/sda3 /dev/sda         part  LVM2_member        6.8G 
#   |-/dev/mapper/centos-root /dev/dm-0 /dev/sda3        lvm   xfs                  6G /
#   `-/dev/mapper/centos-swap /dev/dm-1 /dev/sda3        lvm   swap               820M [SWAP]
# /dev/sdb                    /dev/sdb            sata   disk  mpath_member         8G 
# `-/dev/mapper/disk_2        /dev/dm-2 /dev/sdb         mpath linux_raid_member    8G 
#   `-/dev/md0                /dev/md0  /dev/dm-2        raid1 xfs                  8G /data
# /dev/sdc                    /dev/sdc            sata   disk  mpath_member         8G 
# `-/dev/mapper/disk_1        /dev/dm-3 /dev/sdc         mpath linux_raid_member    8G 
#   `-/dev/md0                /dev/md0  /dev/dm-3        raid1 xfs                  8G /data
# /dev/sr0                    /dev/sr0            ata    rom                     1024M 
# Disk /dev/sda
# Format: disk &lt;devname&gt; &lt;size(bytes)&gt; &lt;partition label type&gt;
disk /dev/sda 8589934592 gpt
# Partitions on /dev/sda
# Format: part &lt;device&gt; &lt;partition size(bytes)&gt; &lt;partition start(bytes)&gt; &lt;partition type|name&gt; &lt;flags&gt; /dev/&lt;partition&gt;
part /dev/sda 209715200 1048576 EFI%20System%20Partition boot /dev/sda1
part /dev/sda 1073741824 210763776 rear-noname none /dev/sda2
part /dev/sda 7304380416 1284505600 rear-noname lvm /dev/sda3
raid /dev/md0 metadata=1.2 level=raid1 raid-devices=2 uuid=a672fba8:7628a3f7:05753a9f:d9b53313 name=0 devices=/dev/mapper/disk_1,/dev/mapper/disk_2
# Format for LVM PVs
# lvmdev &lt;volume_group&gt; &lt;device&gt; [&lt;uuid&gt;] [&lt;size(bytes)&gt;]
lvmdev /dev/centos /dev/sda3 3mI5ya-szZe-iX2Y-Jh5p-kzGL-3WhB-gZw0RD 14266368
# Format for LVM VGs
# lvmgrp &lt;volume_group&gt; &lt;extentsize&gt; [&lt;size(extents)&gt;] [&lt;size(bytes)&gt;]
lvmgrp /dev/centos 4096 1741 7131136
# Format for LVM LVs
# lvmvol &lt;volume_group&gt; &lt;name&gt; &lt;size(bytes)&gt; &lt;layout&gt; [key:value ...]
lvmvol /dev/centos root 6442450944b linear 
lvmvol /dev/centos swap 859832320b linear 
# Filesystems (only ext2,ext3,ext4,vfat,xfs,reiserfs,btrfs are supported).
# Format: fs &lt;device&gt; &lt;mountpoint&gt; &lt;fstype&gt; [uuid=&lt;uuid&gt;] [label=&lt;label&gt;] [&lt;attributes&gt;]
fs /dev/mapper/centos-root / xfs uuid=b57117c1-a7f0-4d11-84e2-1631ec6e95ae label=  options=rw,relatime,attr2,inode64,noquota
fs /dev/md0 /data xfs uuid=19cba473-2aca-43bd-bb03-77b3c715a1d3 label=  options=rw,relatime,attr2,inode64,noquota
fs /dev/sda1 /boot/efi vfat uuid=892A-2713 label= options=rw,relatime,fmask=0077,dmask=0077,codepage=437,iocharset=ascii,shortname=winnt,errors=remount-ro
fs /dev/sda2 /boot xfs uuid=cc788f46-c117-4b68-bcfb-3aa238f8d6cf label=  options=rw,relatime,attr2,inode64,noquota
# Swap partitions or swap files
# Format: swap &lt;filename&gt; uuid=&lt;uuid&gt; label=&lt;label&gt;
swap /dev/mapper/centos-swap uuid=cafa5a50-4b28-4aad-92c3-879d5727055d label=
multipath /dev/mapper/disk_2 8589934592 unknown /dev/sdb
multipath /dev/mapper/disk_1 8589934592 unknown /dev/sdc
</code></pre>
<p>*disklayout.conf AFTER the error</p>
<pre><code># Disk layout dated 20200616202902 (YYYYmmddHHMMSS)
# NAME                        KNAME     PKNAME    TRAN   TYPE  FSTYPE             SIZE MOUNTPOINT
# /dev/sdc                    /dev/sdc            sata   disk                       8G 
# |-/dev/sdc1                 /dev/sdc1 /dev/sdc         part  vfat               200M /boot/efi
# |-/dev/sdc2                 /dev/sdc2 /dev/sdc         part  xfs                  1G /boot
# `-/dev/sdc3                 /dev/sdc3 /dev/sdc         part  LVM2_member        6.8G 
#   |-/dev/mapper/centos-root /dev/dm-0 /dev/sdc3        lvm   xfs                  6G /
#   `-/dev/mapper/centos-swap /dev/dm-1 /dev/sdc3        lvm   swap               820M [SWAP]
# /dev/sdb                    /dev/sdb            sata   disk  mpath_member         8G 
# `-/dev/mapper/mpathb        /dev/dm-2 /dev/sdb         mpath linux_raid_member    8G 
#   `-/dev/md0                /dev/md0  /dev/dm-2        raid1 xfs                  8G /data
# _REAR1_                    _REAR1_            sata   disk  mpath_member         8G 
# `-/dev/mapper/mpatha        /dev/dm-3 _REAR1_         mpath linux_raid_member    8G 
#   `-/dev/md0                /dev/md0  /dev/dm-3        raid1 xfs                  8G /data
# /dev/sr0                    /dev/sr0            ata    rom                     1024M 
# Disk /dev/sdc
# Format: disk &lt;devname&gt; &lt;size(bytes)&gt; &lt;partition label type&gt;
disk /dev/sdc 8589934592 gpt
# Partitions on /dev/sdc
# Format: part &lt;device&gt; &lt;partition size(bytes)&gt; &lt;partition start(bytes)&gt; &lt;partition type|name&gt; &lt;flags&gt; /dev/&lt;partition&gt;
part /dev/sdc 209715200 1048576 EFI%20System%20Partition boot /dev/sdc1
part /dev/sdc 1073741824 210763776 rear-noname none /dev/sdc2
part /dev/sdc 7304380416 1284505600 rear-noname lvm /dev/sdc3
raid /dev/md0 metadata=1.2 level=raid1 raid-devices=2 uuid=a672fba8:7628a3f7:05753a9f:d9b53313 name=0 devices=/dev/mapper/mpatha,/dev/mapper/mpathb
# Format for LVM PVs
# lvmdev &lt;volume_group&gt; &lt;device&gt; [&lt;uuid&gt;] [&lt;size(bytes)&gt;]
lvmdev /dev/centos /dev/sdc3 3mI5ya-szZe-iX2Y-Jh5p-kzGL-3WhB-gZw0RD 14266368
# Format for LVM VGs
# lvmgrp &lt;volume_group&gt; &lt;extentsize&gt; [&lt;size(extents)&gt;] [&lt;size(bytes)&gt;]
lvmgrp /dev/centos 4096 1741 7131136
# Format for LVM LVs
# lvmvol &lt;volume_group&gt; &lt;name&gt; &lt;size(bytes)&gt; &lt;layout&gt; [key:value ...]
lvmvol /dev/centos root 6442450944b linear 
lvmvol /dev/centos swap 859832320b linear 
# Filesystems (only ext2,ext3,ext4,vfat,xfs,reiserfs,btrfs are supported).
# Format: fs &lt;device&gt; &lt;mountpoint&gt; &lt;fstype&gt; [uuid=&lt;uuid&gt;] [label=&lt;label&gt;] [&lt;attributes&gt;]
fs /dev/mapper/centos-root / xfs uuid=b57117c1-a7f0-4d11-84e2-1631ec6e95ae label=  options=rw,relatime,attr2,inode64,noquota
fs /dev/md0 /data xfs uuid=19cba473-2aca-43bd-bb03-77b3c715a1d3 label=  options=rw,relatime,attr2,inode64,noquota
fs /dev/sdc1 /boot/efi vfat uuid=892A-2713 label= options=rw,relatime,fmask=0077,dmask=0077,codepage=437,iocharset=ascii,shortname=winnt,errors=remount-ro
fs /dev/sdc2 /boot xfs uuid=cc788f46-c117-4b68-bcfb-3aa238f8d6cf label=  options=rw,relatime,attr2,inode64,noquota
# Swap partitions or swap files
# Format: swap &lt;filename&gt; uuid=&lt;uuid&gt; label=&lt;label&gt;
swap /dev/mapper/centos-swap uuid=cafa5a50-4b28-4aad-92c3-879d5727055d label=
multipath /dev/mapper/mpathb 8589934592 unknown /dev/sdb
multipath /dev/mapper/mpatha 8589934592 unknown _REAR1_
</code></pre>
<p>V.</p>
<h4 id="jsmeix_commented_at_2020-06-17_0958"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645277723">2020-06-17 09:58</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_0958" title="Permanent link">&para;</a></h4>
<p>Because of
<a href="https://github.com/rear/rear/issues/2428#issuecomment-645246213">https://github.com/rear/rear/issues/2428#issuecomment-645246213</a><br />
I did
<a href="https://github.com/rear/rear/issues/2429">https://github.com/rear/rear/issues/2429</a></p>
<h4 id="gozora_commented_at_2020-06-17_1007"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645282246">2020-06-17 10:07</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_1007" title="Permanent link">&para;</a></h4>
<p>@gdha is there some really special code in ReaR that would fail for
iSCSI? honestly I've never tried this, but the structure (e.g.
<code>multipath -l</code> output) for iSCSI and Fibre Channel look quite similar to
me.<br />
Maybe it is time for me to try it out ;-)</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2020-06-17_1219"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645339807">2020-06-17 12:19</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_1219" title="Permanent link">&para;</a></h4>
<p>@schabrolles<br />
I dared to also assign this issue to you<br />
because it is primarily about multipath<br />
but also to some extent about iSCSI<br />
cf.
<a href="https://github.com/rear/rear/issues/2429">https://github.com/rear/rear/issues/2429</a></p>
<p>@schabrolles<br />
do you perhaps have personal experience in using ReaR<br />
on systems with iSCSI disks?</p>
<h4 id="jsmeix_commented_at_2020-06-17_1221"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645340673">2020-06-17 12:21</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_1221" title="Permanent link">&para;</a></h4>
<p>@gozora<br />
did you try out if</p>
<pre><code>Edit disk mapping (/var/lib/rear/layout/disk_mappings)
</code></pre>
<p>could help in your case to avoid the useless mapping attempts?</p>
<h4 id="gozora_commented_at_2020-06-17_1236"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645347360">2020-06-17 12:36</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_1236" title="Permanent link">&para;</a></h4>
<p>@jsmeix not sure that I understand your question.<br />
My <em>disk_mappings</em> file looked something like this after error was
thrown:</p>
<pre><code>RESCUE centos7:~ # cat /var/lib/rear/layout/disk_mappings  
/dev/sda /dev/sdc
/dev/mapper/disk_2 /dev/mapper/mpathb
/dev/mapper/disk_1 /dev/mapper/mpatha
</code></pre>
<p>As mentioned in
<a href="https://github.com/rear/rear/issues/2428#issue-639979434">https://github.com/rear/rear/issues/2428#issue-639979434</a>,
I've successfully restored system after slaves of <code>multipath</code> in
<em>disklayout.conf</em> were removed:</p>
<pre><code>multipath /dev/mapper/mpatha 8589934592 unknown
multipath /dev/mapper/mpathb 8589934592 unknown
</code></pre>
<h4 id="gozora_commented_at_2020-06-17_1238"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645348227">2020-06-17 12:38</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_1238" title="Permanent link">&para;</a></h4>
<p>Small correction of my
<a href="https://github.com/rear/rear/issues/2428#issuecomment-645347360">https://github.com/rear/rear/issues/2428#issuecomment-645347360</a>
where I've pasted <em>disklayout.conf</em> after replacement<br />
This one is the original one:</p>
<pre><code>multipath /dev/mapper/disk_2 8589934592 unknown
multipath /dev/mapper/disk_1 8589934592 unknown
</code></pre>
<h4 id="schabrolles_commented_at_2020-06-17_1250"><img src="https://avatars.githubusercontent.com/u/19491077?u=0021b16ab426902cbe676f6831f41607bbe4d441&v=4" width="50"><a href="https://github.com/schabrolles">schabrolles</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645353959">2020-06-17 12:50</a>:<a class="headerlink" href="#schabrolles_commented_at_2020-06-17_1250" title="Permanent link">&para;</a></h4>
<p>@jsmeix<br />
I never really play with iSCSI ... only real SAN disk.</p>
<h4 id="gozora_commented_at_2020-06-17_1254"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645355423">2020-06-17 12:54</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_1254" title="Permanent link">&para;</a></h4>
<p>@schabrolles iSCSI is real SAN disk too ;-)</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2020-06-17_1353"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645387427">2020-06-17 13:53</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_1353" title="Permanent link">&para;</a></h4>
<p>@gozora<br />
sorry I confused things (too many device name indirections drive me
nuts)<br />
so that my "avoid the useless mapping attempts" in<br />
<a href="https://github.com/rear/rear/issues/2428#issuecomment-645340673">https://github.com/rear/rear/issues/2428#issuecomment-645340673</a><br />
was plain wrong and misleading.</p>
<p>But manually <code>Edit disk mapping</code> should help:</p>
<p>Now I had a closer look and as far as I understand it now<br />
you like to migrate the original system</p>
<pre><code>NAME                        KNAME     PKNAME    TRAN   TYPE  FSTYPE             SIZE MOUNTPOINT
/dev/sda                    /dev/sda            sata   disk                       8G 
|-/dev/sda1                 /dev/sda1 /dev/sda         part  vfat               200M /boot/efi
|-/dev/sda2                 /dev/sda2 /dev/sda         part  xfs                  1G /boot
`-/dev/sda3                 /dev/sda3 /dev/sda         part  LVM2_member        6.8G 
  |-/dev/mapper/centos-root /dev/dm-0 /dev/sda3        lvm   xfs                  6G /
  `-/dev/mapper/centos-swap /dev/dm-1 /dev/sda3        lvm   swap               820M [SWAP]
/dev/sdb                    /dev/sdb            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_2        /dev/dm-3 /dev/sdb         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-3        raid1 xfs                  8G /data
/dev/sdc                    /dev/sdc            sata   disk  mpath_member         8G 
`-/dev/mapper/disk_1        /dev/dm-2 /dev/sdc         mpath linux_raid_member    8G 
  `-/dev/md0                /dev/md0  /dev/dm-2        raid1 xfs                  8G /data
</code></pre>
<p>to the replacement system</p>
<pre><code>NAME                 KNAME     PKNAME   TRAN   TYPE  FSTYPE   SIZE MOUNTPOINT
/dev/sda             /dev/sda           sata   disk            20G 
`-/dev/mapper/mpatha /dev/dm-0 /dev/sda        mpath           20G 
/dev/sdb             /dev/sdb           sata   disk            10G 
`-/dev/mapper/mpathb /dev/dm-1 /dev/sdb        mpath           10G 
/dev/sdc             /dev/sdc           sata   disk             8G
</code></pre>
<p>Because of your disk mapping file</p>
<pre><code>/dev/sda /dev/sdc
/dev/mapper/disk_2 /dev/mapper/mpathb
/dev/mapper/disk_1 /dev/mapper/mpatha
</code></pre>
<p>I think the intended migration is:</p>
<p>original /dev/sda should<br />
become /dev/sdc on replacement hardware</p>
<p>original /dev/sdb /dev/mapper/disk_2 should<br />
become /dev/sdb /dev/mapper/mpathb on replacement hardware</p>
<p>original /dev/sdc /dev/mapper/disk_1 should<br />
become /dev/sda /dev/mapper/mpatha on replacement hardware</p>
<p>Your unchanged disklayout.conf contains the following device names:</p>
<pre><code>/dev/centos
/dev/mapper/centos-root
/dev/mapper/centos-swap
/dev/mapper/disk_1
/dev/mapper/disk_2
/dev/md0
/dev/sda
/dev/sda1
/dev/sda2
/dev/sda3
/dev/sdb
/dev/sdc
</code></pre>
<p>According to<br />
<a href="https://github.com/rear/rear/issues/2428#issuecomment-645244888">https://github.com/rear/rear/issues/2428#issuecomment-645244888</a></p>
<pre><code>Simply put:
The current disk mapping code only works
when those mapping targets are also specified as a mapping source
when the mapping target appears in a file where mappings are applied.
</code></pre>
<p>it means for your disk mapping targets</p>
<pre><code>/dev/sdc
/dev/mapper/mpathb
/dev/mapper/mpatha
</code></pre>
<p>that those that already exist in your unchanged disklayout.conf<br />
must be also specified as a mapping source.<br />
In your case <code>/dev/sdc</code> is the only one of your disk mapping targets<br />
that already exist in your unchanged disklayout.conf.</p>
<p>So - as far as I understand it - what seems to be missing is<br />
to manually add an additional disk mapping target for <code>/dev/sdc</code><br />
in your disk mapping file like</p>
<pre><code>/dev/sda /dev/sdc
/dev/mapper/disk_2 /dev/mapper/mpathb
/dev/mapper/disk_1 /dev/mapper/mpatha
/dev/sdc /dev/sda
</code></pre>
<p>according to what "I think the intended migration is" (see above).</p>
<p>@gozora<br />
could you try out if it helps to manually add<br />
an additional disk mapping target for <code>/dev/sdc</code><br />
in your disk mapping file so that in the end it looks like</p>
<pre><code>/dev/sda /dev/sdc
/dev/mapper/disk_2 /dev/mapper/mpathb
/dev/mapper/disk_1 /dev/mapper/mpatha
/dev/sdc /dev/sda
</code></pre>
<p>This way the problematic disklayout.conf line</p>
<pre><code>multipath /dev/mapper/disk_1 8589934592 unknown /dev/sdc
</code></pre>
<p>should become changed to</p>
<pre><code>multipath /dev/mapper/mpatha 8589934592 unknown /dev/sda
</code></pre>
<p>i.e. now also the multipath slave gets adapted to match
/dev/mapper/mpatha<br />
(regardless that the multipath slave value is not really needed here)<br />
but I like to understand what exactly goes wrong here<br />
with ReaR's semi-automated disk mapping functionality.</p>
<h4 id="jsmeix_commented_at_2020-06-17_1404"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645394584">2020-06-17 14:04</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_1404" title="Permanent link">&para;</a></h4>
<p>FYI<br />
how to manually derive the disk mapping file contents<br />
from an intended disk migration:</p>
<p>When the intended migration is</p>
<p>(I)<br />
original /dev/sda should<br />
become /dev/sdc on replacement hardware</p>
<p>(II)<br />
original /dev/sdb /dev/mapper/disk_2 should<br />
become /dev/sdb /dev/mapper/mpathb on replacement hardware</p>
<p>(III)<br />
original /dev/sdc /dev/mapper/disk_1 should<br />
become /dev/sda /dev/mapper/mpatha on replacement hardware</p>
<p>then (I) results this disk mapping entry</p>
<pre><code>/dev/sda /dev/sdc
</code></pre>
<p>and (II) results this disk mapping entries</p>
<pre><code>/dev/sdb /dev/sdb
/dev/mapper/disk_2 /dev/mapper/mpathb
</code></pre>
<p>and (III) results this disk mapping entries</p>
<pre><code>/dev/sdc /dev/sda
/dev/mapper/disk_1 /dev/mapper/mpatha
</code></pre>
<p>so (I) and (II) and (III) result this disk mapping entries</p>
<pre><code>/dev/sda /dev/sdc
/dev/sdb /dev/sdb
/dev/mapper/disk_2 /dev/mapper/mpathb
/dev/sdc /dev/sda
/dev/mapper/disk_1 /dev/mapper/mpatha
</code></pre>
<p>where the <code>/dev/sdb /dev/sdb</code> is an identical mapping that can be
omitted<br />
so in the end the relevant disk mapping entries are</p>
<pre><code>/dev/sda /dev/sdc
/dev/mapper/disk_2 /dev/mapper/mpathb
/dev/sdc /dev/sda
/dev/mapper/disk_1 /dev/mapper/mpatha
</code></pre>
<h4 id="gozora_commented_at_2020-06-17_1450"><img src="https://avatars.githubusercontent.com/u/12116358?u=1c5ba9dcee5ca3082f03029a7fbe647efd30eb49&v=4" width="50"><a href="https://github.com/gozora">gozora</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645422443">2020-06-17 14:50</a>:<a class="headerlink" href="#gozora_commented_at_2020-06-17_1450" title="Permanent link">&para;</a></h4>
<p>@jsmeix<br />
Once I've manually added <code>/dev/sdc /dev/sda</code> into <em>disk_mappings</em> all
works fine!</p>
<p>Final <em>/var/lib/rear/layout/disk_mappings</em> looks like:</p>
<pre><code>RESCUE centos7:/var/lib/rear/layout # cat disk_mappings 
/dev/sda /dev/sdc
/dev/mapper/disk_2 /dev/mapper/mpathb
/dev/mapper/disk_1 /dev/mapper/mpatha
/dev/sdc /dev/sda
</code></pre>
<p>Corresponding <em>/var/lib/rear/layout/disklayout.conf</em>:</p>
<pre><code>RESCUE centos7:/var/lib/rear/layout # cat /var/lib/rear/layout/disklayout.conf
# Disk layout dated 20200616202902 (YYYYmmddHHMMSS)
# NAME                        KNAME     PKNAME    TRAN   TYPE  FSTYPE             SIZE MOUNTPOINT
# /dev/sdc                    /dev/sdc            sata   disk                       8G 
# |-/dev/sdc1                 /dev/sdc1 /dev/sdc         part  vfat               200M /boot/efi
# |-/dev/sdc2                 /dev/sdc2 /dev/sdc         part  xfs                  1G /boot
# `-/dev/sdc3                 /dev/sdc3 /dev/sdc         part  LVM2_member        6.8G 
#   |-/dev/mapper/centos-root /dev/dm-0 /dev/sdc3        lvm   xfs                  6G /
#   `-/dev/mapper/centos-swap /dev/dm-1 /dev/sdc3        lvm   swap               820M [SWAP]
# /dev/sdb                    /dev/sdb            sata   disk  mpath_member         8G 
# `-/dev/mapper/mpathb        /dev/dm-2 /dev/sdb         mpath linux_raid_member    8G 
#   `-/dev/md0                /dev/md0  /dev/dm-2        raid1 xfs                  8G /data
# /dev/sda                    /dev/sda            sata   disk  mpath_member         8G 
# `-/dev/mapper/mpatha        /dev/dm-3 /dev/sda         mpath linux_raid_member    8G 
#   `-/dev/md0                /dev/md0  /dev/dm-3        raid1 xfs                  8G /data
# /dev/sr0                    /dev/sr0            ata    rom                     1024M 
# Disk /dev/sdc
# Format: disk &lt;devname&gt; &lt;size(bytes)&gt; &lt;partition label type&gt;
disk /dev/sdc 8589934592 gpt
# Partitions on /dev/sdc
# Format: part &lt;device&gt; &lt;partition size(bytes)&gt; &lt;partition start(bytes)&gt; &lt;partition type|name&gt; &lt;flags&gt; /dev/&lt;partition&gt;
part /dev/sdc 209715200 1048576 EFI%20System%20Partition boot /dev/sdc1
part /dev/sdc 1073741824 210763776 rear-noname none /dev/sdc2
part /dev/sdc 7304380416 1284505600 rear-noname lvm /dev/sdc3
raid /dev/md0 metadata=1.2 level=raid1 raid-devices=2 uuid=a672fba8:7628a3f7:05753a9f:d9b53313 name=0 devices=/dev/mapper/mpatha,/dev/mapper/mpathb
# Format for LVM PVs
# lvmdev &lt;volume_group&gt; &lt;device&gt; [&lt;uuid&gt;] [&lt;size(bytes)&gt;]
lvmdev /dev/centos /dev/sdc3 3mI5ya-szZe-iX2Y-Jh5p-kzGL-3WhB-gZw0RD 14266368
# Format for LVM VGs
# lvmgrp &lt;volume_group&gt; &lt;extentsize&gt; [&lt;size(extents)&gt;] [&lt;size(bytes)&gt;]
lvmgrp /dev/centos 4096 1741 7131136
# Format for LVM LVs
# lvmvol &lt;volume_group&gt; &lt;name&gt; &lt;size(bytes)&gt; &lt;layout&gt; [key:value ...]
lvmvol /dev/centos root 6442450944b linear 
lvmvol /dev/centos swap 859832320b linear 
# Filesystems (only ext2,ext3,ext4,vfat,xfs,reiserfs,btrfs are supported).
# Format: fs &lt;device&gt; &lt;mountpoint&gt; &lt;fstype&gt; [uuid=&lt;uuid&gt;] [label=&lt;label&gt;] [&lt;attributes&gt;]
fs /dev/mapper/centos-root / xfs uuid=b57117c1-a7f0-4d11-84e2-1631ec6e95ae label=  options=rw,relatime,attr2,inode64,noquota
fs /dev/md0 /data xfs uuid=19cba473-2aca-43bd-bb03-77b3c715a1d3 label=  options=rw,relatime,attr2,inode64,noquota
fs /dev/sdc1 /boot/efi vfat uuid=892A-2713 label= options=rw,relatime,fmask=0077,dmask=0077,codepage=437,iocharset=ascii,shortname=winnt,errors=remount-ro
fs /dev/sdc2 /boot xfs uuid=cc788f46-c117-4b68-bcfb-3aa238f8d6cf label=  options=rw,relatime,attr2,inode64,noquota
# Swap partitions or swap files
# Format: swap &lt;filename&gt; uuid=&lt;uuid&gt; label=&lt;label&gt;
swap /dev/mapper/centos-swap uuid=cafa5a50-4b28-4aad-92c3-879d5727055d label=
multipath /dev/mapper/mpathb 8589934592 unknown /dev/sdb
multipath /dev/mapper/mpatha 8589934592 unknown /dev/sda
</code></pre>
<p>Now I'm not sure if this is a bug or a feature :-)</p>
<p>Thanks for your help!</p>
<p>V.</p>
<h4 id="jsmeix_commented_at_2020-06-17_1559"><img src="https://avatars.githubusercontent.com/u/1788608?u=925fc54e2ce01551392622446ece427f51e2f0ce&v=4" width="50"><a href="https://github.com/jsmeix">jsmeix</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-645463589">2020-06-17 15:59</a>:<a class="headerlink" href="#jsmeix_commented_at_2020-06-17_1559" title="Permanent link">&para;</a></h4>
<p>@gozora<br />
many thanks for your prompt testing and your explanatory feedback!</p>
<p>I think the current issue labels "enhancement" and "minor-bug"<br />
are exactly the right ones.</p>
<p>The "minor-bug" is that the current semi-automated disk mapping
functionality<br />
does not verify that the disk mapping entries are complete i.e. a check
is missing<br />
that verifies that all mapping targets are also specified as a mapping
source<br />
when the mapping target appears in a file where mappings are applied<br />
(where as a first step testing only disklayout.conf would probably
catch<br />
99% of all cases where things would go wrong as in this issue here).<br />
In this case here a check is missing that detects that for /dev/sdc<br />
a mapping target is missing.</p>
<p>The "enhancement" is that the current semi-automated disk mapping
functionality<br />
should ask the user via more such dialogs about what mapping target<br />
the user wants to have for those already specified mapping targets<br />
that appear in a file where mappings are applied.<br />
In this case here a user dialog is missing that asks the user for the<br />
mapping target of /dev/sdc.</p>
<h4 id="github-actions_commented_at_2020-10-14_0149"><img src="https://avatars.githubusercontent.com/in/15368?v=4" width="50"><a href="https://github.com/apps/github-actions">github-actions</a> commented at <a href="https://github.com/rear/rear/issues/2428#issuecomment-708104298">2020-10-14 01:49</a>:<a class="headerlink" href="#github-actions_commented_at_2020-10-14_0149" title="Permanent link">&para;</a></h4>
<p>Stale issue message</p>
<hr />
<p>[Export of Github issue for
<a href="https://github.com/rear/rear">rear/rear</a>.]</p>
              
            </div>
          </div>

<footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
    <p>Copyright 2025 - CC0 1.0 Universal<br />Give <a href="https://github.com/rear/rear-user-guide/issues/new?title=issues/2020-06-16.2428.issue.closed.html">feedback</a> on this page.</p>
    
  </div>
</footer>

        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/rear/rear-user-guide" class="fa fa-code-fork" style="color: #fcfcfc"> rear/rear-user-guide</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
